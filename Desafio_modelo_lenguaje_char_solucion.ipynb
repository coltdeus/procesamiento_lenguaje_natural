{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenizaciÃ³n por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validaciÃ³n.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determÃ­stico y estocÃ¡stico. En este Ãºltimo caso observar el efecto de la temperatura en la generaciÃ³n de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validaciÃ³n para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "# BLOQUE 1\n",
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglÃ©s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7amy6uUaBLVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023e8bb3-84b2-4e41-bfbf-4a71d93b1d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando 'Cien aÃ±os de soledad' de Gabriel GarcÃ­a MÃ¡rquez...\n",
            "Descarga exitosa!\n",
            "Encoding detectado y texto decodificado correctamente\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 2 - Descargar \"Cien aÃ±os de soledad\" de Gabriel GarcÃ­a MÃ¡rquez\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# URL del archivo de texto en GitHub\n",
        "url = \"https://gist.githubusercontent.com/ismaproco/6781d297ee65c6a707cd3c901e87ec56/raw/gabriel_garcia_marquez_cien_annos_soledad.txt\"\n",
        "\n",
        "print(\"Descargando 'Cien aÃ±os de soledad' de Gabriel GarcÃ­a MÃ¡rquez...\")\n",
        "\n",
        "try:\n",
        "    # Descargar el archivo\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Verificar que la descarga fue exitosa\n",
        "\n",
        "    # Decodificar el contenido (manejar posibles problemas de encoding)\n",
        "    try:\n",
        "        article_text = response.content.decode('utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            article_text = response.content.decode('latin-1')\n",
        "        except UnicodeDecodeError:\n",
        "            article_text = response.content.decode('iso-8859-1')\n",
        "\n",
        "    print(\"Descarga exitosa!\")\n",
        "    print(f\"Encoding detectado y texto decodificado correctamente\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al descargar: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 2.1 - LIMPIEZA ULTRA AGRESIVA DEL TEXTO DE GARCÃA MÃRQUEZ\n",
        "print(\"=\" * 60)\n",
        "print(\"APLICANDO LIMPIEZA ULTRA AGRESIVA AL CORPUS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import re\n",
        "\n",
        "# Guardar texto original para comparaciÃ³n\n",
        "article_text_original = article_text\n",
        "original_length = len(article_text_original)\n",
        "\n",
        "print(f\"AnÃ¡lisis del texto original:\")\n",
        "print(f\"   Caracteres totales: {original_length:,}\")\n",
        "\n",
        "# Dividir en lÃ­neas para anÃ¡lisis inicial\n",
        "original_lines = article_text.split('\\n')\n",
        "print(f\"   LÃ­neas totales: {len(original_lines):,}\")\n",
        "\n",
        "# Contar lÃ­neas problemÃ¡ticas originales\n",
        "empty_lines = sum(1 for line in original_lines if line == '')\n",
        "only_spaces = sum(1 for line in original_lines if line.strip() == '' and line != '')\n",
        "content_lines = sum(1 for line in original_lines if line.strip())\n",
        "\n",
        "print(f\"   LÃ­neas con contenido: {content_lines:,}\")\n",
        "print(f\"   LÃ­neas completamente vacÃ­as: {empty_lines:,}\")\n",
        "print(f\"   LÃ­neas solo con espacios: {only_spaces:,}\")\n",
        "\n",
        "# APLICAR LIMPIEZA ULTRA AGRESIVA\n",
        "print(f\"\\nAplicando limpieza ultra agresiva...\")\n",
        "\n",
        "# 1. Normalizar espacios mÃºltiples dentro de lÃ­neas\n",
        "print(\"   1. Normalizando espacios mÃºltiples...\")\n",
        "article_text = re.sub(r' +', ' ', article_text)\n",
        "\n",
        "# 2. Eliminar espacios al final e inicio de lÃ­neas\n",
        "print(\"   2. Eliminando espacios al final e inicio de lÃ­neas...\")\n",
        "article_text = re.sub(r' +\\n', '\\n', article_text)\n",
        "article_text = re.sub(r'\\n +', '\\n', article_text)\n",
        "\n",
        "# 3. Eliminar TODAS las lÃ­neas vacÃ­as\n",
        "print(\"   3. Eliminando TODAS las lÃ­neas vacÃ­as...\")\n",
        "lines = article_text.split('\\n')\n",
        "cleaned_lines = []\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip():  # Solo lÃ­neas con contenido real\n",
        "        # Limpiar espacios al inicio y final\n",
        "        cleaned_line = line.strip()\n",
        "        cleaned_lines.append(cleaned_line)\n",
        "    # Ignorar completamente las lÃ­neas vacÃ­as (no agregar nada)\n",
        "\n",
        "# 4. Unir las lÃ­neas con un solo salto de lÃ­nea\n",
        "print(\"   4. Uniendo lÃ­neas con saltos Ãºnicos...\")\n",
        "article_text = '\\n'.join(cleaned_lines)\n",
        "\n",
        "# 5. Limpieza final de cualquier espacio residual\n",
        "print(\"   5. Limpieza final...\")\n",
        "article_text = article_text.strip()\n",
        "\n",
        "final_length = len(article_text)\n",
        "\n",
        "# ESTADÃSTICAS DE LIMPIEZA\n",
        "print(f\"\\nResultados de la limpieza ultra agresiva:\")\n",
        "print(f\"   LÃ­neas originales: {len(original_lines):,}\")\n",
        "print(f\"   LÃ­neas despuÃ©s de limpieza: {len(cleaned_lines):,}\")\n",
        "print(f\"   LÃ­neas removidas: {len(original_lines) - len(cleaned_lines):,}\")\n",
        "print(f\"   ReducciÃ³n de lÃ­neas: {((len(original_lines) - len(cleaned_lines)) / len(original_lines) * 100):.1f}%\")\n",
        "\n",
        "print(f\"\\nCaracteres:\")\n",
        "print(f\"   Originales: {original_length:,}\")\n",
        "print(f\"   DespuÃ©s de limpieza: {final_length:,}\")\n",
        "print(f\"   Caracteres removidos: {original_length - final_length:,}\")\n",
        "print(f\"   ReducciÃ³n: {((original_length - final_length) / original_length * 100):.1f}%\")\n",
        "\n",
        "# VERIFICACIÃ“N DE CALIDAD\n",
        "print(f\"\\nVerificaciÃ³n de calidad del texto limpio:\")\n",
        "\n",
        "# Verificar estructura final\n",
        "final_lines = article_text.split('\\n')\n",
        "final_empty_lines = sum(1 for line in final_lines if line.strip() == '')\n",
        "final_content_lines = len(final_lines) - final_empty_lines\n",
        "\n",
        "print(f\"   LÃ­neas con contenido: {final_content_lines:,}\")\n",
        "print(f\"   LÃ­neas vacÃ­as restantes: {final_empty_lines:,}\")\n",
        "print(f\"   Promedio chars por lÃ­nea: {final_length / len(final_lines):.1f}\")\n",
        "\n",
        "# Verificar que NO hay lÃ­neas vacÃ­as\n",
        "print(f\"   Â¿Sin lÃ­neas vacÃ­as?: {'âœ“ SÃ' if final_empty_lines == 0 else 'âœ— NO'}\")\n",
        "\n",
        "# Verificar continuidad del texto\n",
        "consecutive_newlines = 0\n",
        "max_consecutive_newlines = 0\n",
        "for i, char in enumerate(article_text):\n",
        "    if char == '\\n':\n",
        "        consecutive_newlines += 1\n",
        "        max_consecutive_newlines = max(max_consecutive_newlines, consecutive_newlines)\n",
        "    else:\n",
        "        consecutive_newlines = 0\n",
        "\n",
        "print(f\"   MÃ¡ximo saltos consecutivos: {max_consecutive_newlines}\")\n",
        "\n",
        "# Verificar inicio del texto\n",
        "print(f\"\\nTexto limpio (primeros 200 chars):\")\n",
        "print(f\"'{article_text[:200]}'\")\n",
        "\n",
        "# Verificar que palabras clave se mantienen\n",
        "garcia_marquez_words = ['Macondo', 'BuendÃ­a', 'Aureliano', 'Ãšrsula', 'soledad']\n",
        "print(f\"\\nPalabras clave preservadas:\")\n",
        "all_words_preserved = True\n",
        "for word in garcia_marquez_words:\n",
        "    original_count = article_text_original.count(word)\n",
        "    cleaned_count = article_text.count(word)\n",
        "    status = \"âœ“\" if original_count == cleaned_count else \"âœ—\"\n",
        "    if original_count != cleaned_count:\n",
        "        all_words_preserved = False\n",
        "    print(f\"   '{word}': {original_count} -> {cleaned_count} {status}\")\n",
        "\n",
        "# Verificar caracteres especiales del espaÃ±ol\n",
        "spanish_chars = ['Ã±', 'Ã¡', 'Ã©', 'Ã­', 'Ã³', 'Ãº']\n",
        "print(f\"\\nCaracteres especiales del espaÃ±ol:\")\n",
        "all_chars_preserved = True\n",
        "for char in spanish_chars:\n",
        "    original_count = article_text_original.count(char)\n",
        "    cleaned_count = article_text.count(char)\n",
        "    if original_count != cleaned_count:\n",
        "        all_chars_preserved = False\n",
        "    status = \"âœ“\" if original_count == cleaned_count else \"âœ—\"\n",
        "    print(f\"   '{char}': {original_count} -> {cleaned_count} {status}\")\n",
        "\n",
        "# RESUMEN FINAL\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"LIMPIEZA ULTRA AGRESIVA COMPLETADA\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"âœ“ Eliminadas TODAS las lÃ­neas vacÃ­as\")\n",
        "print(f\"âœ“ Normalizados espacios mÃºltiples\")\n",
        "print(f\"âœ“ Eliminados espacios al final/inicio de lÃ­neas\")\n",
        "print(f\"âœ“ Solo un salto de lÃ­nea entre pÃ¡rrafos\")\n",
        "print(f\"âœ“ Texto continuo sin interrupciones\")\n",
        "print(f\"âœ“ Palabras clave preservadas: {'SÃ­' if all_words_preserved else 'Algunas perdidas'}\")\n",
        "print(f\"âœ“ Caracteres especiales preservados: {'SÃ­' if all_chars_preserved else 'Algunos perdidos'}\")\n",
        "print(f\"âœ“ ReducciÃ³n total: {((original_length - final_length) / original_length * 100):.1f}%\")\n",
        "print(f\"âœ“ {len(original_lines) - len(cleaned_lines):,} lÃ­neas redundantes eliminadas\")\n",
        "\n",
        "print(f\"\\nCorpus ultra limpio listo para tokenizaciÃ³n!\")\n",
        "print(f\"ðŸš€ TEXTO SIN LÃNEAS VACÃAS - COMPLETAMENTE CONTINUO ðŸš€\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvDFU61h6Z04",
        "outputId": "39865fc9-9007-4b06-e674-a584431408c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "APLICANDO LIMPIEZA ULTRA AGRESIVA AL CORPUS\n",
            "============================================================\n",
            "AnÃ¡lisis del texto original:\n",
            "   Caracteres totales: 826,863\n",
            "   LÃ­neas totales: 11,930\n",
            "   LÃ­neas con contenido: 9,503\n",
            "   LÃ­neas completamente vacÃ­as: 2,427\n",
            "   LÃ­neas solo con espacios: 0\n",
            "\n",
            "Aplicando limpieza ultra agresiva...\n",
            "   1. Normalizando espacios mÃºltiples...\n",
            "   2. Eliminando espacios al final e inicio de lÃ­neas...\n",
            "   3. Eliminando TODAS las lÃ­neas vacÃ­as...\n",
            "   4. Uniendo lÃ­neas con saltos Ãºnicos...\n",
            "   5. Limpieza final...\n",
            "\n",
            "Resultados de la limpieza ultra agresiva:\n",
            "   LÃ­neas originales: 11,930\n",
            "   LÃ­neas despuÃ©s de limpieza: 9,503\n",
            "   LÃ­neas removidas: 2,427\n",
            "   ReducciÃ³n de lÃ­neas: 20.3%\n",
            "\n",
            "Caracteres:\n",
            "   Originales: 826,863\n",
            "   DespuÃ©s de limpieza: 814,933\n",
            "   Caracteres removidos: 11,930\n",
            "   ReducciÃ³n: 1.4%\n",
            "\n",
            "VerificaciÃ³n de calidad del texto limpio:\n",
            "   LÃ­neas con contenido: 9,503\n",
            "   LÃ­neas vacÃ­as restantes: 0\n",
            "   Promedio chars por lÃ­nea: 85.8\n",
            "   Â¿Sin lÃ­neas vacÃ­as?: âœ“ SÃ\n",
            "   MÃ¡ximo saltos consecutivos: 1\n",
            "\n",
            "Texto limpio (primeros 200 chars):\n",
            "'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot\n",
            "y MarÃ­a Luisa Elio\n",
            "Cien aÃ±os de soledad\n",
            "Gabriel GarcÃ­a MÃ¡rquez\n",
            "Muchos aÃ±os despuÃ©s, frente al pelot'\n",
            "\n",
            "Palabras clave preservadas:\n",
            "   'Macondo': 180 -> 180 âœ“\n",
            "   'BuendÃ­a': 406 -> 406 âœ“\n",
            "   'Aureliano': 803 -> 803 âœ“\n",
            "   'Ãšrsula': 514 -> 514 âœ“\n",
            "   'soledad': 217 -> 217 âœ“\n",
            "\n",
            "Caracteres especiales del espaÃ±ol:\n",
            "   'Ã±': 1333 -> 1333 âœ“\n",
            "   'Ã¡': 2010 -> 2010 âœ“\n",
            "   'Ã©': 2043 -> 2043 âœ“\n",
            "   'Ã­': 5180 -> 5180 âœ“\n",
            "   'Ã³': 6217 -> 6217 âœ“\n",
            "   'Ãº': 783 -> 783 âœ“\n",
            "\n",
            "============================================================\n",
            "LIMPIEZA ULTRA AGRESIVA COMPLETADA\n",
            "============================================================\n",
            "âœ“ Eliminadas TODAS las lÃ­neas vacÃ­as\n",
            "âœ“ Normalizados espacios mÃºltiples\n",
            "âœ“ Eliminados espacios al final/inicio de lÃ­neas\n",
            "âœ“ Solo un salto de lÃ­nea entre pÃ¡rrafos\n",
            "âœ“ Texto continuo sin interrupciones\n",
            "âœ“ Palabras clave preservadas: SÃ­\n",
            "âœ“ Caracteres especiales preservados: SÃ­\n",
            "âœ“ ReducciÃ³n total: 1.4%\n",
            "âœ“ 2,427 lÃ­neas redundantes eliminadas\n",
            "\n",
            "Corpus ultra limpio listo para tokenizaciÃ³n!\n",
            "ðŸš€ TEXTO SIN LÃNEAS VACÃAS - COMPLETAMENTE CONTINUO ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6v_ickFwBJTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9baa79bf-e35e-4d91-b813-2909c631c530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto de 'Cien aÃ±os de soledad' cargado:\n",
            "   Autor: Gabriel GarcÃ­a MÃ¡rquez\n",
            "   Obra: Cien aÃ±os de soledad\n",
            "   Idioma: EspaÃ±ol\n",
            "   Longitud total: 814,933 caracteres\n",
            "\n",
            "Primeros 300 caracteres:\n",
            "'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot\n",
            "y MarÃ­a Luisa Elio\n",
            "Cien aÃ±os de soledad\n",
            "Gabriel GarcÃ­a MÃ¡rquez\n",
            "Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a habÃ­a de\n",
            "recordar aquella tarde remota en que su pa'\n",
            "\n",
            "Ãšltimos 200 caracteres:\n",
            "'oledad no tenÃ­an una segunda\n",
            "oportunidad sobre la tierra.\n",
            "172\n",
            "I 3\n",
            "II 10\n",
            "III 18\n",
            "IV 27\n",
            "V 35\n",
            "VI 45\n",
            "Vil 52\n",
            "VIII 60\n",
            "IX 68\n",
            "X 76\n",
            "XI 85\n",
            "XII 93\n",
            "XIII 102\n",
            "XIV 111\n",
            "XV 121\n",
            "XVI 130\n",
            "XVII 138\n",
            "XVIII 147\n",
            "XIX 156\n",
            "XX 165'\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 3 - Explorar el texto de GarcÃ­a MÃ¡rquez\n",
        "print(f\"\\nTexto de 'Cien aÃ±os de soledad' cargado:\")\n",
        "print(f\"   Autor: Gabriel GarcÃ­a MÃ¡rquez\")\n",
        "print(f\"   Obra: Cien aÃ±os de soledad\")\n",
        "print(f\"   Idioma: EspaÃ±ol\")\n",
        "print(f\"   Longitud total: {len(article_text):,} caracteres\")\n",
        "\n",
        "# Verificar el inicio del texto\n",
        "print(f\"\\nPrimeros 300 caracteres:\")\n",
        "print(f\"'{article_text[:300]}'\")\n",
        "\n",
        "# Verificar el final del texto\n",
        "print(f\"\\nÃšltimos 200 caracteres:\")\n",
        "print(f\"'{article_text[-200:]}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WBE0sSYuB-E6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b405a163-84e5-4406-a8da-24e9775bd8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EstadÃ­sticas del corpus en espaÃ±ol:\n",
            "   Total de lÃ­neas: 9,503\n",
            "   LÃ­neas no vacÃ­as: 9,503\n",
            "   PÃ¡rrafos aproximados: 1\n",
            "   Caracteres Ãºnicos: 93\n",
            "   Palabras aproximadas: 139,344\n",
            "\n",
            "CaracterÃ­sticas del espaÃ±ol:\n",
            "   Caracteres con tildes y Ã±: 18,135\n",
            "   Presencia de 'Ã±': âœ“\n",
            "   Presencia de tildes: âœ“\n",
            "\n",
            "Palabras caracterÃ­sticas de GarcÃ­a MÃ¡rquez encontradas:\n",
            "   'Macondo': 180 veces\n",
            "   'BuendÃ­a': 406 veces\n",
            "   'Aureliano': 803 veces\n",
            "   'Ãšrsula': 514 veces\n",
            "   'soledad': 217 veces\n",
            "\n",
            "Muestra de pÃ¡rrafos del corpus:\n",
            "   1. 'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot...'\n",
            "\n",
            "Texto guardado localmente como: cien_anos_soledad.txt\n",
            "\n",
            "Corpus de GarcÃ­a MÃ¡rquez listo para tokenizaciÃ³n por caracteres!\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 4 - AnÃ¡lisis del corpus en espaÃ±ol\n",
        "# EstadÃ­sticas bÃ¡sicas del texto en espaÃ±ol\n",
        "lineas = article_text.split('\\n')\n",
        "parrafos = [p.strip() for p in article_text.split('\\n\\n') if p.strip()]\n",
        "\n",
        "print(f\"\\nEstadÃ­sticas del corpus en espaÃ±ol:\")\n",
        "print(f\"   Total de lÃ­neas: {len(lineas):,}\")\n",
        "print(f\"   LÃ­neas no vacÃ­as: {len([l for l in lineas if l.strip()]):,}\")\n",
        "print(f\"   PÃ¡rrafos aproximados: {len(parrafos):,}\")\n",
        "print(f\"   Caracteres Ãºnicos: {len(set(article_text))}\")\n",
        "print(f\"   Palabras aproximadas: {len(article_text.split()):,}\")\n",
        "\n",
        "# AnÃ¡lisis especÃ­fico del espaÃ±ol\n",
        "import re\n",
        "\n",
        "# Contar caracteres especiales del espaÃ±ol\n",
        "chars_especiales_esp = ['Ã±', 'Ã‘', 'Ã¡', 'Ã©', 'Ã­', 'Ã³', 'Ãº', 'Ã', 'Ã‰', 'Ã', 'Ã“', 'Ãš', 'Ã¼', 'Ãœ']\n",
        "count_esp = sum(article_text.count(char) for char in chars_especiales_esp)\n",
        "\n",
        "print(f\"\\nCaracterÃ­sticas del espaÃ±ol:\")\n",
        "print(f\"   Caracteres con tildes y Ã±: {count_esp:,}\")\n",
        "print(f\"   Presencia de 'Ã±': {'âœ“' if 'Ã±' in article_text else 'âœ—'}\")\n",
        "print(f\"   Presencia de tildes: {'âœ“' if any(c in article_text for c in 'Ã¡Ã©Ã­Ã³Ãº') else 'âœ—'}\")\n",
        "\n",
        "# Palabras caracterÃ­sticas de GarcÃ­a MÃ¡rquez\n",
        "palabras_gabo = ['Macondo', 'BuendÃ­a', 'Aureliano', 'Ãšrsula', 'soledad', 'amaranto']\n",
        "print(f\"\\nPalabras caracterÃ­sticas de GarcÃ­a MÃ¡rquez encontradas:\")\n",
        "for palabra in palabras_gabo:\n",
        "    count = article_text.count(palabra)\n",
        "    if count > 0:\n",
        "        print(f\"   '{palabra}': {count} veces\")\n",
        "\n",
        "# Muestra de pÃ¡rrafos del corpus\n",
        "print(f\"\\nMuestra de pÃ¡rrafos del corpus:\")\n",
        "parrafos_muestra = [p for p in parrafos if len(p) > 50][:5]\n",
        "for i, parrafo in enumerate(parrafos_muestra):\n",
        "    # Mostrar solo los primeros 100 caracteres de cada pÃ¡rrafo\n",
        "    preview = parrafo[:100] + \"...\" if len(parrafo) > 100 else parrafo\n",
        "    print(f\"   {i+1}. '{preview}'\")\n",
        "\n",
        "if len(parrafos_muestra) < len(parrafos):\n",
        "    print(f\"   ... y {len(parrafos) - len(parrafos_muestra)} pÃ¡rrafos mÃ¡s\")\n",
        "\n",
        "# Guardar una copia local del texto\n",
        "try:\n",
        "    with open('cien_anos_soledad.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(article_text)\n",
        "    print(f\"\\nTexto guardado localmente como: cien_anos_soledad.txt\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nNo se pudo guardar localmente: {e}\")\n",
        "\n",
        "print(f\"\\nCorpus de GarcÃ­a MÃ¡rquez listo para tokenizaciÃ³n por caracteres!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaÃ±o del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sÃ­ mismo y el tamaÃ±o de contexto\n",
        "puede ser elegido con mÃ¡s libertad en comparaciÃ³n a un modelo de lenguaje tokenizado por palabras y dividido en documentos mÃ¡s acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wumBNwdjJM3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4468a593-eef4-4a50-d7f2-584b195206d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TamaÃ±o mÃ¡ximo de contexto seleccionado: 100 caracteres\n",
            "Este serÃ¡ el tamaÃ±o de las secuencias de entrada para el modelo\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 5 - Seleccionar tamaÃ±o de contexto\n",
        "max_context_size = 100\n",
        "print(f\"TamaÃ±o mÃ¡ximo de contexto seleccionado: {max_context_size} caracteres\")\n",
        "print(f\"Este serÃ¡ el tamaÃ±o de las secuencias de entrada para el modelo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m5FeTaGvbDbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e69777-c88c-45e8-d578-86c2c3b3f75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilidades de Keras importadas para procesamiento de secuencias\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 6 - Importar utilidades de Keras para padding\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "print(\"Utilidades de Keras importadas para procesamiento de secuencias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "573Cg5n7VhWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d75f6b-f442-44b4-83dd-6e1ecaf831c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario de caracteres Ãºnicos extraÃ­do del corpus:\n",
            "   TamaÃ±o del vocabulario: 93\n",
            "   Caracteres especiales del espaÃ±ol: ['Â¡', 'Â¿', 'Ã', 'Ã‰', 'Ã', 'Ã‘', 'Ãš', 'Ã¡', 'Ã©', 'Ã­', 'Ã±', 'Ã³', 'Ãº', 'Ã¼']\n",
            "   Signos de puntuaciÃ³n: ['!', '\"', '(', ')', ',', '-', '.', ':', ';', '?', 'Â¡', 'Â¿']\n",
            "   NÃºmeros: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 7 - Crear vocabulario de caracteres Ãºnicos del corpus espaÃ±ol\n",
        "chars_vocab = set(article_text)\n",
        "print(f\"Vocabulario de caracteres Ãºnicos extraÃ­do del corpus:\")\n",
        "print(f\"   TamaÃ±o del vocabulario: {len(chars_vocab)}\")\n",
        "\n",
        "# Mostrar algunos caracteres especiales del espaÃ±ol\n",
        "chars_sorted = sorted(list(chars_vocab))\n",
        "chars_especiales = [c for c in chars_sorted if c in 'Ã±Ã‘Ã¡Ã©Ã­Ã³ÃºÃÃ‰ÃÃ“ÃšÃ¼ÃœÂ¿Â¡']\n",
        "chars_puntuacion = [c for c in chars_sorted if c in '.,;:!?Â¿Â¡()[]{}\"-']\n",
        "chars_numeros = [c for c in chars_sorted if c.isdigit()]\n",
        "\n",
        "print(f\"   Caracteres especiales del espaÃ±ol: {chars_especiales}\")\n",
        "print(f\"   Signos de puntuaciÃ³n: {chars_puntuacion}\")\n",
        "print(f\"   NÃºmeros: {chars_numeros}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7bdd08-66f3-49f1-d2da-404c1376c7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AnÃ¡lisis detallado del vocabulario de caracteres:\n",
            "Longitud del vocabulario: 93\n",
            "   Letras minÃºsculas: 33\n",
            "   Letras mayÃºsculas: 31\n",
            "   Caracteres especiales espaÃ±ol: 14\n",
            "   Signos de puntuaciÃ³n: 12\n",
            "   NÃºmeros: 10\n",
            "   Espacios y saltos: 2\n",
            "\n",
            "Muestras por categorÃ­a:\n",
            "   MinÃºsculas (primeras 10): ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
            "   MayÃºsculas (primeras 10): ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
            "   Especiales espaÃ±ol: ['Â¡', 'Â¿', 'Ã', 'Ã‰', 'Ã', 'Ã‘', 'Ãš', 'Ã¡', 'Ã©', 'Ã­', 'Ã±', 'Ã³', 'Ãº', 'Ã¼']\n",
            "   NÃºmeros: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 8 - Mostrar anÃ¡lisis detallado del vocabulario\n",
        "print(f\"\\nAnÃ¡lisis detallado del vocabulario de caracteres:\")\n",
        "print(f\"Longitud del vocabulario: {len(chars_vocab)}\")\n",
        "\n",
        "# Categorizar caracteres\n",
        "letras_minusculas = [c for c in chars_sorted if c.islower() and c.isalpha()]\n",
        "letras_mayusculas = [c for c in chars_sorted if c.isupper() and c.isalpha()]\n",
        "espacios_especiales = [c for c in chars_sorted if c in ' \\n\\t\\r']\n",
        "\n",
        "print(f\"   Letras minÃºsculas: {len(letras_minusculas)}\")\n",
        "print(f\"   Letras mayÃºsculas: {len(letras_mayusculas)}\")\n",
        "print(f\"   Caracteres especiales espaÃ±ol: {len(chars_especiales)}\")\n",
        "print(f\"   Signos de puntuaciÃ³n: {len(chars_puntuacion)}\")\n",
        "print(f\"   NÃºmeros: {len(chars_numeros)}\")\n",
        "print(f\"   Espacios y saltos: {len(espacios_especiales)}\")\n",
        "\n",
        "# Mostrar muestra de cada categorÃ­a\n",
        "print(f\"\\nMuestras por categorÃ­a:\")\n",
        "print(f\"   MinÃºsculas (primeras 10): {letras_minusculas[:10]}\")\n",
        "print(f\"   MayÃºsculas (primeras 10): {letras_mayusculas[:10]}\")\n",
        "print(f\"   Especiales espaÃ±ol: {chars_especiales}\")\n",
        "print(f\"   NÃºmeros: {chars_numeros}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2W0AeQjXV1Ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e28328-c865-4db6-ba88-01978f770101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Diccionarios de mapeo creados:\n",
            "   char2idx: convierte caracteres a Ã­ndices (0 a 92)\n",
            "   idx2char: convierte Ã­ndices a caracteres\n",
            "\n",
            "Ejemplos de mapeo char2idx (caracteres importantes):\n",
            "   ''a'' -> 50\n",
            "   ''e'' -> 54\n",
            "   ''o'' -> 64\n",
            "   ''Ã±'' -> 89\n",
            "   ''Ã¡'' -> 86\n",
            "   ''Ã©'' -> 87\n",
            "   '' '' -> 1\n",
            "   ''.'' -> 9\n",
            "   '','' -> 7\n",
            "   ''\\n'' -> 0\n",
            "\n",
            "Ejemplos de mapeo idx2char (primeros 15 Ã­ndices):\n",
            "    0 -> '\\n'\n",
            "    1 -> ' '\n",
            "    2 -> '!'\n",
            "    3 -> '\"'\n",
            "    4 -> '''\n",
            "    5 -> '('\n",
            "    6 -> ')'\n",
            "    7 -> ','\n",
            "    8 -> '-'\n",
            "    9 -> '.'\n",
            "   10 -> '0'\n",
            "   11 -> '1'\n",
            "   12 -> '2'\n",
            "   13 -> '3'\n",
            "   14 -> '4'\n",
            "\n",
            "VerificaciÃ³n de consistencia de mapeos:\n",
            "   'M' -> 36 -> 'M' âœ“\n",
            "   'a' -> 50 -> 'a' âœ“\n",
            "   'c' -> 52 -> 'c' âœ“\n",
            "   'o' -> 64 -> 'o' âœ“\n",
            "   'n' -> 63 -> 'n' âœ“\n",
            "   'd' -> 53 -> 'd' âœ“\n",
            "   'o' -> 64 -> 'o' âœ“\n",
            "   ' ' -> 1 -> ' ' âœ“\n",
            "   'Ã±' -> 89 -> 'Ã±' âœ“\n",
            "   'Ã¡' -> 86 -> 'Ã¡' âœ“\n",
            "\n",
            "Consistencia general: âœ“ Todos los mapeos son consistentes\n",
            "\n",
            "InformaciÃ³n del vocabulario preparada:\n",
            "   vocab_size: 93\n",
            "   Rango de Ã­ndices: 0 a 92\n",
            "   Diccionarios char2idx e idx2char listos para tokenizaciÃ³n\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 9 - Construir diccionarios de mapeo bidireccional\n",
        "# Crear mapeos entre caracteres e Ã­ndices\n",
        "char2idx = {char: idx for idx, char in enumerate(sorted(chars_vocab))}\n",
        "idx2char = {idx: char for char, idx in char2idx.items()}\n",
        "\n",
        "print(f\"\\nDiccionarios de mapeo creados:\")\n",
        "print(f\"   char2idx: convierte caracteres a Ã­ndices (0 a {len(chars_vocab)-1})\")\n",
        "print(f\"   idx2char: convierte Ã­ndices a caracteres\")\n",
        "\n",
        "# Verificar algunos mapeos importantes\n",
        "print(f\"\\nEjemplos de mapeo char2idx (caracteres importantes):\")\n",
        "caracteres_importantes = ['a', 'e', 'o', 'Ã±', 'Ã¡', 'Ã©', ' ', '.', ',', '\\n']\n",
        "for char in caracteres_importantes:\n",
        "    if char in char2idx:\n",
        "        print(f\"   '{repr(char)}' -> {char2idx[char]}\")\n",
        "    else:\n",
        "        print(f\"   '{repr(char)}' -> No encontrado\")\n",
        "\n",
        "print(f\"\\nEjemplos de mapeo idx2char (primeros 15 Ã­ndices):\")\n",
        "for i in range(min(15, len(idx2char))):\n",
        "    char = idx2char[i]\n",
        "    char_display = repr(char) if char in [' ', '\\n', '\\t'] else f\"'{char}'\"\n",
        "    print(f\"   {i:2d} -> {char_display}\")\n",
        "\n",
        "# Verificar consistencia de los mapeos\n",
        "print(f\"\\nVerificaciÃ³n de consistencia de mapeos:\")\n",
        "test_chars = ['M', 'a', 'c', 'o', 'n', 'd', 'o', ' ', 'Ã±', 'Ã¡']\n",
        "all_consistent = True\n",
        "for char in test_chars:\n",
        "    if char in char2idx:\n",
        "        idx = char2idx[char]\n",
        "        char_recovered = idx2char[idx]\n",
        "        is_consistent = char == char_recovered\n",
        "        status = \"âœ“\" if is_consistent else \"âœ—\"\n",
        "        print(f\"   '{char}' -> {idx} -> '{char_recovered}' {status}\")\n",
        "        if not is_consistent:\n",
        "            all_consistent = False\n",
        "    else:\n",
        "        print(f\"   '{char}' no estÃ¡ en vocabulario\")\n",
        "\n",
        "print(f\"\\nConsistencia general: {'âœ“ Todos los mapeos son consistentes' if all_consistent else 'âœ— Hay inconsistencias'}\")\n",
        "\n",
        "# InformaciÃ³n del vocabulario para siguientes bloques\n",
        "vocab_size = len(chars_vocab)\n",
        "print(f\"\\nInformaciÃ³n del vocabulario preparada:\")\n",
        "print(f\"   vocab_size: {vocab_size}\")\n",
        "print(f\"   Rango de Ã­ndices: 0 a {vocab_size-1}\")\n",
        "print(f\"   Diccionarios char2idx e idx2char listos para tokenizaciÃ³n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "h07G3srdJppo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e91da16-131a-4f43-fe6a-3313fc57db44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizando texto completo...\n",
            "TokenizaciÃ³n del texto completada:\n",
            "   Caracteres originales: 814,933\n",
            "   Tokens (Ã­ndices): 814,933\n",
            "   Primeros 50 tokens: [30, 50, 51, 67, 58, 54, 61, 1, 30, 50, 67, 52, 88, 50, 1, 36, 86, 67, 66, 70, 54, 75, 0, 26, 58, 54, 63, 1, 50, 89, 64, 68, 1, 53, 54, 1, 68, 64, 61, 54, 53, 50, 53, 0, 28, 27, 32, 43, 24, 27]\n",
            "\n",
            "VerificaciÃ³n de tokenizaciÃ³n:\n",
            "Texto original (primeros 100 chars):\n",
            "'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot'\n",
            "\n",
            "Tokens correspondientes:\n",
            "[30, 50, 51, 67, 58, 54, 61, 1, 30, 50, 67, 52, 88, 50, 1, 36, 86, 67, 66, 70, 54, 75, 0, 26, 58, 54, 63, 1, 50, 89, 64, 68, 1, 53, 54, 1, 68, 64, 61, 54, 53, 50, 53, 0, 28, 27, 32, 43, 24, 27, 38, 1, 39, 38, 41, 1, 3, 28, 27, 32, 26, 32, 38, 37, 28, 42, 1, 35, 24, 1, 26, 44, 28, 45, 24, 3, 0, 39, 50, 67, 50, 1, 33, 1, 64, 62, 58, 1, 30, 50, 67, 52, 88, 50, 1, 24, 68, 52, 64, 69]\n",
            "\n",
            "ReconstrucciÃ³n desde tokens:\n",
            "'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot'\n",
            "Â¿Coincide? âœ“\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 10 - Tokenizar todo el texto a secuencia de Ã­ndices\n",
        "# Convertir cada carÃ¡cter del texto a su Ã­ndice correspondiente\n",
        "print(\"Tokenizando texto completo...\")\n",
        "text_as_int = [char2idx[c] for c in article_text]\n",
        "\n",
        "print(f\"TokenizaciÃ³n del texto completada:\")\n",
        "print(f\"   Caracteres originales: {len(article_text):,}\")\n",
        "print(f\"   Tokens (Ã­ndices): {len(text_as_int):,}\")\n",
        "print(f\"   Primeros 50 tokens: {text_as_int[:50]}\")\n",
        "\n",
        "# Verificar la tokenizaciÃ³n mostrando algunos ejemplos\n",
        "print(f\"\\nVerificaciÃ³n de tokenizaciÃ³n:\")\n",
        "print(f\"Texto original (primeros 100 chars):\")\n",
        "print(f\"'{article_text[:100]}'\")\n",
        "print(f\"\\nTokens correspondientes:\")\n",
        "print(f\"{text_as_int[:100]}\")\n",
        "print(f\"\\nReconstrucciÃ³n desde tokens:\")\n",
        "reconstructed = ''.join([idx2char[idx] for idx in text_as_int[:100]])\n",
        "print(f\"'{reconstructed}'\")\n",
        "print(f\"Â¿Coincide? {'âœ“' if reconstructed == article_text[:100] else 'âœ—'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PwGVSKOiJ5bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a73769-2f39-4307-e323-8619274b7e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EstadÃ­sticas de tokenizaciÃ³n:\n",
            "   Tokens Ãºnicos: 93\n",
            "   Token mÃ¡s frecuente: (1, 129841) -> ' '\n",
            "   Token menos frecuente: (34, 1) -> 'K'\n",
            "\n",
            "Top 10 caracteres mÃ¡s frecuentes:\n",
            "    1.    ' ' -> 129,841 veces (15.9%)\n",
            "    2.    'a' -> 85,120 veces (10.4%)\n",
            "    3.    'e' -> 80,136 veces (9.8%)\n",
            "    4.    'o' -> 56,083 veces (6.9%)\n",
            "    5.    'n' -> 45,544 veces (5.6%)\n",
            "    6.    's' -> 45,412 veces (5.6%)\n",
            "    7.    'r' -> 45,050 veces (5.5%)\n",
            "    8.    'l' -> 38,744 veces (4.8%)\n",
            "    9.    'i' -> 36,586 veces (4.5%)\n",
            "   10.    'd' -> 34,258 veces (4.2%)\n",
            "\n",
            "ValidaciÃ³n de rango de tokens:\n",
            "   Token mÃ­nimo: 0\n",
            "   Token mÃ¡ximo: 92\n",
            "   TamaÃ±o vocabulario: 93\n",
            "   Rango vÃ¡lido: âœ“\n",
            "\n",
            "InformaciÃ³n del vocabulario preparada para siguientes bloques\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 11 - EstadÃ­sticas de la tokenizaciÃ³n\n",
        "print(f\"\\nEstadÃ­sticas de tokenizaciÃ³n:\")\n",
        "\n",
        "# DistribuciÃ³n de tokens\n",
        "from collections import Counter\n",
        "token_counts = Counter(text_as_int)\n",
        "print(f\"   Tokens Ãºnicos: {len(token_counts)}\")\n",
        "print(f\"   Token mÃ¡s frecuente: {token_counts.most_common(1)[0]} -> '{idx2char[token_counts.most_common(1)[0][0]]}'\")\n",
        "print(f\"   Token menos frecuente: {token_counts.most_common()[-1]} -> '{idx2char[token_counts.most_common()[-1][0]]}'\")\n",
        "\n",
        "# Top 10 caracteres mÃ¡s frecuentes\n",
        "print(f\"\\nTop 10 caracteres mÃ¡s frecuentes:\")\n",
        "for i, (token_idx, count) in enumerate(token_counts.most_common(10)):\n",
        "    char = idx2char[token_idx]\n",
        "    percentage = (count / len(text_as_int)) * 100\n",
        "    char_display = repr(char) if char in [' ', '\\n', '\\t'] else f\"'{char}'\"\n",
        "    print(f\"   {i+1:2d}. {char_display:>6} -> {count:,} veces ({percentage:.1f}%)\")\n",
        "\n",
        "# Verificar que no hay tokens fuera del rango del vocabulario\n",
        "min_token = min(text_as_int)\n",
        "max_token = max(text_as_int)\n",
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "print(f\"\\nValidaciÃ³n de rango de tokens:\")\n",
        "print(f\"   Token mÃ­nimo: {min_token}\")\n",
        "print(f\"   Token mÃ¡ximo: {max_token}\")\n",
        "print(f\"   TamaÃ±o vocabulario: {vocab_size}\")\n",
        "print(f\"   Rango vÃ¡lido: {'âœ“' if min_token >= 0 and max_token < vocab_size else 'âœ—'}\")\n",
        "\n",
        "# Guardamos el vocabulario para uso posterior\n",
        "vocab_info = {\n",
        "    'char2idx': char2idx,\n",
        "    'idx2char': idx2char,\n",
        "    'vocab_size': len(chars_vocab),\n",
        "    'chars_vocab': chars_vocab\n",
        "}\n",
        "print(f\"\\nInformaciÃ³n del vocabulario preparada para siguientes bloques\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WSSmg9jtKP0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b41ac1-f807-41d4-8ab1-55b0952fc1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando secuencias de entrenamiento con longitud: 100\n",
            "Creando secuencias de entrenamiento...\n",
            "   Longitud de secuencia: 100\n",
            "   Texto total: 814,933 caracteres\n",
            "   Procesadas: 100,000 secuencias...\n",
            "   Procesadas: 200,000 secuencias...\n",
            "   Procesadas: 300,000 secuencias...\n",
            "   Procesadas: 400,000 secuencias...\n",
            "   Procesadas: 500,000 secuencias...\n",
            "   Procesadas: 600,000 secuencias...\n",
            "   Procesadas: 700,000 secuencias...\n",
            "   Procesadas: 800,000 secuencias...\n",
            "   Secuencias generadas: 814,833\n",
            "Secuencias creadas exitosamente: 814,833\n",
            "Targets creados: 814,833\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 12 - Preparar secuencias de entrenamiento\n",
        "def create_training_sequences(text_as_int, seq_length):\n",
        "    \"\"\"\n",
        "    Crea secuencias de entrenamiento para modelo de lenguaje por caracteres\n",
        "    Implementando la tÃ©cnica de ventana deslizante de la Clase 4\n",
        "\n",
        "    Args:\n",
        "        text_as_int: texto tokenizado como lista de Ã­ndices\n",
        "        seq_length: longitud de cada secuencia de entrada\n",
        "\n",
        "    Returns:\n",
        "        sequences: secuencias de entrada (X)\n",
        "        targets: caracteres objetivo (y)\n",
        "    \"\"\"\n",
        "    print(f\"Creando secuencias de entrenamiento...\")\n",
        "    print(f\"   Longitud de secuencia: {seq_length}\")\n",
        "    print(f\"   Texto total: {len(text_as_int):,} caracteres\")\n",
        "\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    # Generar secuencias con ventana deslizante (paso = 1 para mÃ¡ximo aprovechamiento)\n",
        "    for i in range(len(text_as_int) - seq_length):\n",
        "        # Secuencia de entrada: seq_length caracteres\n",
        "        seq = text_as_int[i:i + seq_length]\n",
        "        # Target: el siguiente carÃ¡cter\n",
        "        target = text_as_int[i + seq_length]\n",
        "\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "\n",
        "        # Mostrar progreso cada 100K secuencias\n",
        "        if (i + 1) % 100000 == 0:\n",
        "            print(f\"   Procesadas: {i+1:,} secuencias...\")\n",
        "\n",
        "    print(f\"   Secuencias generadas: {len(sequences):,}\")\n",
        "    return sequences, targets\n",
        "\n",
        "# Usar el tamaÃ±o de contexto definido anteriormente\n",
        "seq_length = max_context_size  # 100 caracteres\n",
        "print(f\"Creando secuencias de entrenamiento con longitud: {seq_length}\")\n",
        "\n",
        "sequences, targets = create_training_sequences(text_as_int, seq_length)\n",
        "print(f\"Secuencias creadas exitosamente: {len(sequences):,}\")\n",
        "print(f\"Targets creados: {len(targets):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "b7dCpGrdKll0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a7fd1a-ad6e-4b34-d71f-28456455c53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "VERIFICACIÃ“N DE SECUENCIAS CREADAS\n",
            "============================================================\n",
            "Ejemplo de secuencia 0 (inicio del libro):\n",
            "   Input (primeros 20 Ã­ndices): [30, 50, 51, 67, 58, 54, 61, 1, 30, 50, 67, 52, 88, 50, 1, 36, 86, 67, 66, 70]\n",
            "   Input (Ãºltimos 20 Ã­ndices): [50, 1, 33, 1, 64, 62, 58, 1, 30, 50, 67, 52, 88, 50, 1, 24, 68, 52, 64, 69]\n",
            "   Target (Ã­ndice): 0\n",
            "   Target (carÃ¡cter): '\n",
            "'\n",
            "   Input completo (texto): 'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITAD...O POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot'\n",
            "   PredicciÃ³n esperada: 'Gabriel GarcÃ­a MÃ¡rquez\n",
            "Cien aÃ±os de soledad\n",
            "EDITADO POR \"EDICIONES LA CUEVA\"\n",
            "Para J omi GarcÃ­a Ascot' -> '\n",
            "'\n",
            "\n",
            "Ejemplos adicionales:\n",
            "   Secuencia 1000: '...maravilla de los sabios\n",
            "alquim' -> 'i'\n",
            "   Secuencia 50000: '... su hermano, la tos seca de su' -> ' '\n",
            "   Secuencia 100000: '...o desamparado que la protegÃ­a ' -> 'd'\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 13 - Verificar las secuencias creadas\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"VERIFICACIÃ“N DE SECUENCIAS CREADAS\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "print(f\"Ejemplo de secuencia 0 (inicio del libro):\")\n",
        "print(f\"   Input (primeros 20 Ã­ndices): {sequences[0][:20]}\")\n",
        "print(f\"   Input (Ãºltimos 20 Ã­ndices): {sequences[0][-20:]}\")\n",
        "print(f\"   Target (Ã­ndice): {targets[0]}\")\n",
        "print(f\"   Target (carÃ¡cter): '{idx2char[targets[0]]}'\")\n",
        "\n",
        "# Reconstruir la secuencia para verificar\n",
        "seq_chars = ''.join([idx2char[idx] for idx in sequences[0]])\n",
        "print(f\"   Input completo (texto): '{seq_chars[:50]}...{seq_chars[-50:]}'\")\n",
        "print(f\"   PredicciÃ³n esperada: '{seq_chars}' -> '{idx2char[targets[0]]}'\")\n",
        "\n",
        "# Verificar algunas secuencias mÃ¡s para diversidad\n",
        "print(f\"\\nEjemplos adicionales:\")\n",
        "test_indices = [1000, 50000, 100000] if len(sequences) > 100000 else [100, 500, 1000]\n",
        "\n",
        "for i, seq_idx in enumerate(test_indices):\n",
        "    if seq_idx < len(sequences):\n",
        "        seq_sample = ''.join([idx2char[idx] for idx in sequences[seq_idx]])\n",
        "        target_char = idx2char[targets[seq_idx]]\n",
        "        print(f\"   Secuencia {seq_idx}: '...{seq_sample[-30:]}' -> '{target_char}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NmxQdxl8LRCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16566bf0-868c-45ab-bcc7-b21a692ff22c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONVERSIÃ“N A ARRAYS DE NUMPY\n",
            "============================================================\n",
            "Convirtiendo listas a arrays de NumPy...\n",
            "Arrays de NumPy creados:\n",
            "   X shape: (814833, 100)\n",
            "   y shape: (814833,)\n",
            "   X dtype: int32\n",
            "   y dtype: int32\n",
            "\n",
            "Uso de memoria:\n",
            "   X: 310.8 MB\n",
            "   y: 3.1 MB\n",
            "   Total: 313.9 MB\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 14 - Convertir a arrays de NumPy\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"CONVERSIÃ“N A ARRAYS DE NUMPY\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "print(\"Convirtiendo listas a arrays de NumPy...\")\n",
        "X = np.array(sequences, dtype=np.int32)\n",
        "y = np.array(targets, dtype=np.int32)\n",
        "\n",
        "print(f\"Arrays de NumPy creados:\")\n",
        "print(f\"   X shape: {X.shape}\")\n",
        "print(f\"   y shape: {y.shape}\")\n",
        "print(f\"   X dtype: {X.dtype}\")\n",
        "print(f\"   y dtype: {y.dtype}\")\n",
        "\n",
        "# Calcular memoria utilizada\n",
        "x_memory_mb = X.nbytes / (1024 * 1024)\n",
        "y_memory_mb = y.nbytes / (1024 * 1024)\n",
        "total_memory_mb = x_memory_mb + y_memory_mb\n",
        "\n",
        "print(f\"\\nUso de memoria:\")\n",
        "print(f\"   X: {x_memory_mb:.1f} MB\")\n",
        "print(f\"   y: {y_memory_mb:.1f} MB\")\n",
        "print(f\"   Total: {total_memory_mb:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_gyFT9koLqDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58c48ff-5e4c-42a0-b584-fce5c5ce89fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANÃLISIS DE DISTRIBUCIÃ“N DE TARGETS\n",
            "============================================================\n",
            "DistribuciÃ³n de caracteres objetivo:\n",
            "   Targets Ãºnicos: 92\n",
            "   Vocabulario esperado: 93\n",
            "   Â¿Todos los caracteres presentes? âœ—\n",
            "   Target mÃ¡s frecuente: 1 -> ' ' (129,828 veces)\n",
            "   Target menos frecuente: 34 -> 'K' (1 veces)\n",
            "\n",
            "Top 15 caracteres objetivo mÃ¡s frecuentes en GarcÃ­a MÃ¡rquez:\n",
            "    1.  'espacio' -> 129,828 veces (15.93%)\n",
            "    2.        'a' -> 85,111 veces (10.45%)\n",
            "    3.        'e' -> 80,131 veces (9.83%)\n",
            "    4.        'o' -> 56,079 veces (6.88%)\n",
            "    5.        'n' -> 45,543 veces (5.59%)\n",
            "    6.        's' -> 45,409 veces (5.57%)\n",
            "    7.        'r' -> 45,045 veces (5.53%)\n",
            "    8.        'l' -> 38,742 veces (4.75%)\n",
            "    9.        'i' -> 36,583 veces (4.49%)\n",
            "   10.        'd' -> 34,255 veces (4.20%)\n",
            "   11.        'u' -> 28,082 veces (3.45%)\n",
            "   12.        'c' -> 26,264 veces (3.22%)\n",
            "   13.        't' -> 24,808 veces (3.04%)\n",
            "   14.        'm' -> 16,250 veces (1.99%)\n",
            "   15.        'p' -> 15,810 veces (1.94%)\n",
            "\n",
            "Balance de clases:\n",
            "   Frecuencia mÃ¡xima: 129,828\n",
            "   Frecuencia mÃ­nima: 1\n",
            "   Ratio desbalance: 129828.0x\n",
            "   EvaluaciÃ³n: Muy desbalanceado\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 15 - Verificar distribuciÃ³n de targets\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"ANÃLISIS DE DISTRIBUCIÃ“N DE TARGETS\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "from collections import Counter\n",
        "target_counts = Counter(y)\n",
        "\n",
        "print(f\"DistribuciÃ³n de caracteres objetivo:\")\n",
        "print(f\"   Targets Ãºnicos: {len(target_counts)}\")\n",
        "print(f\"   Vocabulario esperado: {vocab_size}\")\n",
        "print(f\"   Â¿Todos los caracteres presentes? {'âœ“' if len(target_counts) == vocab_size else 'âœ—'}\")\n",
        "\n",
        "# Target mÃ¡s y menos frecuente\n",
        "most_common_target = target_counts.most_common(1)[0]\n",
        "least_common_target = target_counts.most_common()[-1]\n",
        "\n",
        "print(f\"   Target mÃ¡s frecuente: {most_common_target[0]} -> '{idx2char[most_common_target[0]]}' ({most_common_target[1]:,} veces)\")\n",
        "print(f\"   Target menos frecuente: {least_common_target[0]} -> '{idx2char[least_common_target[0]]}' ({least_common_target[1]} veces)\")\n",
        "\n",
        "# Top 15 caracteres target mÃ¡s frecuentes\n",
        "print(f\"\\nTop 15 caracteres objetivo mÃ¡s frecuentes en GarcÃ­a MÃ¡rquez:\")\n",
        "for i, (target_idx, count) in enumerate(target_counts.most_common(15)):\n",
        "    char = idx2char[target_idx]\n",
        "    percentage = (count / len(y)) * 100\n",
        "    char_display = \"'espacio'\" if char == ' ' else \"'salto'\" if char == '\\n' else f\"'{char}'\"\n",
        "    print(f\"   {i+1:2d}. {char_display:>10} -> {count:,} veces ({percentage:.2f}%)\")\n",
        "\n",
        "# Verificar balance de clases\n",
        "max_freq = target_counts.most_common(1)[0][1]\n",
        "min_freq = target_counts.most_common()[-1][1]\n",
        "balance_ratio = max_freq / min_freq\n",
        "\n",
        "print(f\"\\nBalance de clases:\")\n",
        "print(f\"   Frecuencia mÃ¡xima: {max_freq:,}\")\n",
        "print(f\"   Frecuencia mÃ­nima: {min_freq}\")\n",
        "print(f\"   Ratio desbalance: {balance_ratio:.1f}x\")\n",
        "print(f\"   EvaluaciÃ³n: {'Muy desbalanceado' if balance_ratio > 1000 else 'Moderadamente desbalanceado' if balance_ratio > 100 else 'Relativamente balanceado'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oVNqmmLRodT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf5929d-8d5c-4244-9971-3060446aeab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIVISIÃ“N EN TRAIN/VALIDATION\n",
            "============================================================\n",
            "Dividiendo en 80% entrenamiento, 20% validaciÃ³n\n",
            "Usando shuffle=False para preservar orden temporal del texto\n",
            "\n",
            "DivisiÃ³n completada:\n",
            "   Entrenamiento: X_train (651866, 100), y_train (651866,)\n",
            "   ValidaciÃ³n: X_val (162967, 100), y_val (162967,)\n",
            "\n",
            "VerificaciÃ³n temporal:\n",
            "   Ãšltimo Ã­ndice de train: 651865\n",
            "   Primer Ã­ndice de val: 651866\n",
            "   âœ“ DivisiÃ³n temporal correcta sin overlap\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 16 - DivisiÃ³n en conjuntos de entrenamiento y validaciÃ³n\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"DIVISIÃ“N EN TRAIN/VALIDATION\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir en 80% entrenamiento, 20% validaciÃ³n\n",
        "# Usar shuffle=False para mantener secuencias temporalmente coherentes\n",
        "test_size = 0.2\n",
        "print(f\"Dividiendo en {(1-test_size)*100:.0f}% entrenamiento, {test_size*100:.0f}% validaciÃ³n\")\n",
        "print(f\"Usando shuffle=False para preservar orden temporal del texto\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=42, shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nDivisiÃ³n completada:\")\n",
        "print(f\"   Entrenamiento: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
        "print(f\"   ValidaciÃ³n: X_val {X_val.shape}, y_val {y_val.shape}\")\n",
        "\n",
        "# Verificar que no hay overlap temporal problemÃ¡tico\n",
        "print(f\"\\nVerificaciÃ³n temporal:\")\n",
        "print(f\"   Ãšltimo Ã­ndice de train: {len(X_train)-1}\")\n",
        "print(f\"   Primer Ã­ndice de val: {len(X_train)}\")\n",
        "print(f\"   âœ“ DivisiÃ³n temporal correcta sin overlap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KFAyA4zCWE-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62f09a9-a224-444f-e3ce-7754895fa0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "VERIFICACIÃ“N DE DISTRIBUCIÃ“N POST-DIVISIÃ“N\n",
            "============================================================\n",
            "DistribuciÃ³n despuÃ©s de divisiÃ³n:\n",
            "   Targets Ãºnicos en train: 90\n",
            "   Targets Ãºnicos en val: 86\n",
            "   Caracteres faltantes en train: 3\n",
            "   Caracteres faltantes en val: 7\n",
            "   Â¿Train completo? âœ—\n",
            "   Â¿Val completo? âœ—\n",
            "\n",
            "ComparaciÃ³n de caracteres mÃ¡s frecuentes:\n",
            "Rank Train           Val             Coincide\n",
            "--------------------------------------------------\n",
            "1    'esp'           'esp'           âœ“       \n",
            "2    'a'             'a'             âœ“       \n",
            "3    'e'             'e'             âœ“       \n",
            "4    'o'             'o'             âœ“       \n",
            "5    'n'             'n'             âœ“       \n",
            "6    's'             's'             âœ“       \n",
            "7    'r'             'r'             âœ“       \n",
            "8    'l'             'l'             âœ“       \n",
            "9    'i'             'i'             âœ“       \n",
            "10   'd'             'd'             âœ“       \n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 17 - Verificar que la divisiÃ³n preserva la distribuciÃ³n\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"VERIFICACIÃ“N DE DISTRIBUCIÃ“N POST-DIVISIÃ“N\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "# DistribuciÃ³n en entrenamiento\n",
        "train_target_counts = Counter(y_train)\n",
        "val_target_counts = Counter(y_val)\n",
        "\n",
        "print(f\"DistribuciÃ³n despuÃ©s de divisiÃ³n:\")\n",
        "print(f\"   Targets Ãºnicos en train: {len(train_target_counts)}\")\n",
        "print(f\"   Targets Ãºnicos en val: {len(val_target_counts)}\")\n",
        "\n",
        "# Verificar que ambos conjuntos tienen representaciÃ³n de todas las clases\n",
        "missing_in_train = vocab_size - len(train_target_counts)\n",
        "missing_in_val = vocab_size - len(val_target_counts)\n",
        "\n",
        "print(f\"   Caracteres faltantes en train: {missing_in_train}\")\n",
        "print(f\"   Caracteres faltantes en val: {missing_in_val}\")\n",
        "print(f\"   Â¿Train completo? {'âœ“' if missing_in_train == 0 else 'âœ—'}\")\n",
        "print(f\"   Â¿Val completo? {'âœ“' if missing_in_val == 0 else 'âœ—'}\")\n",
        "\n",
        "# Comparar distribuciones mÃ¡s frecuentes\n",
        "print(f\"\\nComparaciÃ³n de caracteres mÃ¡s frecuentes:\")\n",
        "print(f\"{'Rank':<4} {'Train':<15} {'Val':<15} {'Coincide':<8}\")\n",
        "print(\"-\" * 50)\n",
        "for i in range(min(10, len(train_target_counts), len(val_target_counts))):\n",
        "    train_char = idx2char[train_target_counts.most_common(i+1)[i][0]]\n",
        "    val_char = idx2char[val_target_counts.most_common(i+1)[i][0]]\n",
        "    coincide = \"âœ“\" if train_char == val_char else \"âœ—\"\n",
        "    train_display = \"'esp'\" if train_char == ' ' else f\"'{train_char}'\"\n",
        "    val_display = \"'esp'\" if val_char == ' ' else f\"'{val_char}'\"\n",
        "    print(f\"{i+1:<4} {train_display:<15} {val_display:<15} {coincide:<8}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qcKRl70HFTzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21f813d-165f-4661-cbcd-1906c0d5a1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ESTADÃSTICAS FINALES DEL DATASET\n",
            "============================================================\n",
            "Resumen completo del dataset de GarcÃ­a MÃ¡rquez:\n",
            "   Obra: 'Cien aÃ±os de soledad'\n",
            "   Autor: Gabriel GarcÃ­a MÃ¡rquez\n",
            "   Idioma: EspaÃ±ol\n",
            "   TamaÃ±o original del texto: 814,933 caracteres\n",
            "   Secuencias generadas: 814,833\n",
            "   Longitud de cada secuencia: 100\n",
            "   Vocabulario: 93 caracteres Ãºnicos\n",
            "   Muestras de entrenamiento: 651,866\n",
            "   Muestras de validaciÃ³n: 162,967\n",
            "\n",
            "Eficiencia del dataset:\n",
            "   Caracteres en secuencias: 81,483,300\n",
            "   Eficiencia de uso: 9998.8%\n",
            "   Batches por Ã©poca (batch=128): 5,092\n",
            "   Memoria total aproximada: 0.31 GB\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 18 - EstadÃ­sticas finales del dataset\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"ESTADÃSTICAS FINALES DEL DATASET\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "print(f\"Resumen completo del dataset de GarcÃ­a MÃ¡rquez:\")\n",
        "print(f\"   Obra: 'Cien aÃ±os de soledad'\")\n",
        "print(f\"   Autor: Gabriel GarcÃ­a MÃ¡rquez\")\n",
        "print(f\"   Idioma: EspaÃ±ol\")\n",
        "print(f\"   TamaÃ±o original del texto: {len(article_text):,} caracteres\")\n",
        "print(f\"   Secuencias generadas: {len(sequences):,}\")\n",
        "print(f\"   Longitud de cada secuencia: {seq_length}\")\n",
        "print(f\"   Vocabulario: {vocab_size} caracteres Ãºnicos\")\n",
        "print(f\"   Muestras de entrenamiento: {len(X_train):,}\")\n",
        "print(f\"   Muestras de validaciÃ³n: {len(X_val):,}\")\n",
        "\n",
        "# Calcular densidad de datos\n",
        "total_characters_in_sequences = len(X_train) * seq_length + len(X_val) * seq_length\n",
        "efficiency = (total_characters_in_sequences / len(article_text)) * 100\n",
        "\n",
        "print(f\"\\nEficiencia del dataset:\")\n",
        "print(f\"   Caracteres en secuencias: {total_characters_in_sequences:,}\")\n",
        "print(f\"   Eficiencia de uso: {efficiency:.1f}%\")\n",
        "\n",
        "# Estimaciones para entrenamiento\n",
        "batches_per_epoch_est = len(X_train) // 128  # Asumiendo batch_size=128\n",
        "print(f\"   Batches por Ã©poca (batch=128): {batches_per_epoch_est:,}\")\n",
        "\n",
        "# Calcular memoria total aproximada\n",
        "total_memory_gb = total_memory_mb / 1024\n",
        "print(f\"   Memoria total aproximada: {total_memory_gb:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TVpLCKSZFXZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58973293-d34e-46f1-a340-79838b1c902e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PREPARACIÃ“N DE METADATOS\n",
            "============================================================\n",
            "InformaciÃ³n del dataset preparada:\n",
            "   vocab_size: 93\n",
            "   seq_length: 100\n",
            "   train_samples: 651866\n",
            "   val_samples: 162967\n",
            "   total_chars: 814933\n",
            "   total_sequences: 814833\n",
            "   most_common_char:  \n",
            "   balance_ratio: 129828.00\n",
            "   memory_mb: 313.94\n",
            "   efficiency_percent: 9998.77\n",
            "   author: Gabriel GarcÃ­a MÃ¡rquez\n",
            "   book: Cien aÃ±os de soledad\n",
            "   language: Spanish\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 19 - Guardar informaciÃ³n del dataset\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"PREPARACIÃ“N DE METADATOS\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "dataset_info = {\n",
        "    'vocab_size': vocab_size,\n",
        "    'seq_length': seq_length,\n",
        "    'char2idx': char2idx,\n",
        "    'idx2char': idx2char,\n",
        "    'train_samples': len(X_train),\n",
        "    'val_samples': len(X_val),\n",
        "    'total_chars': len(article_text),\n",
        "    'total_sequences': len(sequences),\n",
        "    'most_common_char': idx2char[target_counts.most_common(1)[0][0]],\n",
        "    'balance_ratio': balance_ratio,\n",
        "    'memory_mb': total_memory_mb,\n",
        "    'efficiency_percent': efficiency,\n",
        "    'author': 'Gabriel GarcÃ­a MÃ¡rquez',\n",
        "    'book': 'Cien aÃ±os de soledad',\n",
        "    'language': 'Spanish'\n",
        "}\n",
        "\n",
        "print(f\"InformaciÃ³n del dataset preparada:\")\n",
        "for key, value in dataset_info.items():\n",
        "    if key not in ['char2idx', 'idx2char']:  # No imprimir diccionarios completos\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key}: {value:.2f}\")\n",
        "        else:\n",
        "            print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wOFCR-KqbW1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d71ccb5-f6d2-4209-a653-8b92ca078a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET LISTO PARA ENTRENAMIENTO\n",
            "============================================================\n",
            "ConfiguraciÃ³n final del dataset:\n",
            "   Input shape: (651866, 100) (samples, sequence_length)\n",
            "   Output shape: (651866,) (samples,)\n",
            "   Validation input: (162967, 100)\n",
            "   Validation output: (162967,)\n",
            "   Vocabulary size: 93\n",
            "   Character-level: âœ“\n",
            "   Spanish text: âœ“\n",
            "   Literary quality: âœ“ (GarcÃ­a MÃ¡rquez)\n",
            "\n",
            "Formato de datos:\n",
            "   Cada input: secuencia de 100 caracteres (como Ã­ndices)\n",
            "   Cada output: Ã­ndice del siguiente carÃ¡cter (0-92)\n",
            "   Tipo de problema: clasificaciÃ³n multiclase (93 clases)\n",
            "   FunciÃ³n de pÃ©rdida recomendada: sparse_categorical_crossentropy\n",
            "\n",
            "Variables disponibles para el modelo:\n",
            "   - X_train, X_val: secuencias de entrada\n",
            "   - y_train, y_val: targets\n",
            "   - vocab_size: 93\n",
            "   - seq_length: 100\n",
            "   - char2idx, idx2char: mapeos\n",
            "   - dataset_info: metadatos completos\n",
            "\n",
            "âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“\n",
            "Â¡DATASET DE GARCÃA MÃRQUEZ LISTO PARA ENTRENAR MODELO LSTM!\n",
            "âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 20 - PreparaciÃ³n final para el modelo\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"DATASET LISTO PARA ENTRENAMIENTO\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "print(f\"ConfiguraciÃ³n final del dataset:\")\n",
        "print(f\"   Input shape: {X_train.shape} (samples, sequence_length)\")\n",
        "print(f\"   Output shape: {y_train.shape} (samples,)\")\n",
        "print(f\"   Validation input: {X_val.shape}\")\n",
        "print(f\"   Validation output: {y_val.shape}\")\n",
        "print(f\"   Vocabulary size: {vocab_size}\")\n",
        "print(f\"   Character-level: âœ“\")\n",
        "print(f\"   Spanish text: âœ“\")\n",
        "print(f\"   Literary quality: âœ“ (GarcÃ­a MÃ¡rquez)\")\n",
        "\n",
        "print(f\"\\nFormato de datos:\")\n",
        "print(f\"   Cada input: secuencia de {seq_length} caracteres (como Ã­ndices)\")\n",
        "print(f\"   Cada output: Ã­ndice del siguiente carÃ¡cter (0-{vocab_size-1})\")\n",
        "print(f\"   Tipo de problema: clasificaciÃ³n multiclase ({vocab_size} clases)\")\n",
        "print(f\"   FunciÃ³n de pÃ©rdida recomendada: sparse_categorical_crossentropy\")\n",
        "\n",
        "print(f\"\\nVariables disponibles para el modelo:\")\n",
        "print(f\"   - X_train, X_val: secuencias de entrada\")\n",
        "print(f\"   - y_train, y_val: targets\")\n",
        "print(f\"   - vocab_size: {vocab_size}\")\n",
        "print(f\"   - seq_length: {seq_length}\")\n",
        "print(f\"   - char2idx, idx2char: mapeos\")\n",
        "print(f\"   - dataset_info: metadatos completos\")\n",
        "\n",
        "print(f\"\\n\" + \"âœ“\"*60)\n",
        "print(f\"Â¡DATASET DE GARCÃA MÃRQUEZ LISTO PARA ENTRENAR MODELO LSTM!\")\n",
        "print(f\"âœ“\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "## Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rkMCZvmhrQz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332d1ab8-27c0-486f-e16f-e0e46d5ec2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DEFINIENDO ARQUITECTURA DEL MODELO LSTM\n",
            "============================================================\n",
            "ConfiguraciÃ³n basada en el corpus de GarcÃ­a MÃ¡rquez:\n",
            "   Vocabulario detectado: 93 caracteres\n",
            "   Secuencias de entrada: 100 caracteres\n",
            "\n",
            "ParÃ¡metros seleccionados:\n",
            "   Embedding dimensions: 256\n",
            "   LSTM units: 512\n",
            "   Dropout rate: 0.3\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 21 - Definir arquitectura del modelo\n",
        "print(\"=\" * 60)\n",
        "print(\"DEFINIENDO ARQUITECTURA DEL MODELO LSTM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "def create_char_lstm_model(vocab_size, seq_length, embedding_dim=256, lstm_units=512, dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Crea un modelo LSTM para predicciÃ³n de caracteres\n",
        "    Basado en las recomendaciones de la Clase 4\n",
        "\n",
        "    Args:\n",
        "        vocab_size: tamaÃ±o del vocabulario de caracteres\n",
        "        seq_length: longitud de las secuencias de entrada\n",
        "        embedding_dim: dimensiÃ³n de los embeddings\n",
        "        lstm_units: nÃºmero de unidades LSTM\n",
        "        dropout_rate: tasa de dropout para regularizaciÃ³n\n",
        "\n",
        "    Returns:\n",
        "        model: modelo Sequential de Keras\n",
        "    \"\"\"\n",
        "    print(f\"Creando modelo LSTM para generaciÃ³n de texto:\")\n",
        "    print(f\"   Vocabulario: {vocab_size} caracteres Ãºnicos\")\n",
        "    print(f\"   Secuencias: {seq_length} caracteres de entrada\")\n",
        "    print(f\"   Embedding: {embedding_dim} dimensiones\")\n",
        "    print(f\"   LSTM: {lstm_units} unidades\")\n",
        "    print(f\"   Dropout: {dropout_rate}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        # Capa de embedding: convierte Ã­ndices de caracteres a vectores densos\n",
        "        Embedding(\n",
        "            input_dim=vocab_size,\n",
        "            output_dim=embedding_dim,\n",
        "            input_length=seq_length,\n",
        "            name='char_embedding'\n",
        "        ),\n",
        "\n",
        "        # Capa LSTM: procesa secuencias de caracteres\n",
        "        # return_sequences=False porque solo necesitamos la salida final\n",
        "        LSTM(\n",
        "            lstm_units,\n",
        "            return_sequences=False,\n",
        "            name='lstm_layer'\n",
        "        ),\n",
        "\n",
        "        # Dropout para regularizaciÃ³n y prevenir overfitting\n",
        "        Dropout(dropout_rate, name='dropout_layer'),\n",
        "\n",
        "        # Capa densa final: clasificaciÃ³n sobre vocabulario completo\n",
        "        Dense(\n",
        "            vocab_size,\n",
        "            activation='softmax',\n",
        "            name='output_layer'\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Configurar parÃ¡metros del modelo basados en el anÃ¡lisis del corpus\n",
        "print(f\"ConfiguraciÃ³n basada en el corpus de GarcÃ­a MÃ¡rquez:\")\n",
        "print(f\"   Vocabulario detectado: {vocab_size} caracteres\")\n",
        "print(f\"   Secuencias de entrada: {seq_length} caracteres\")\n",
        "\n",
        "# ParÃ¡metros del modelo\n",
        "embedding_dim = 256    # DimensiÃ³n de embeddings (suficiente para 93 chars)\n",
        "lstm_units = 512      # Unidades LSTM (capacidad para capturar patrones complejos)\n",
        "dropout_rate = 0.3    # RegularizaciÃ³n moderada\n",
        "\n",
        "print(f\"\\nParÃ¡metros seleccionados:\")\n",
        "print(f\"   Embedding dimensions: {embedding_dim}\")\n",
        "print(f\"   LSTM units: {lstm_units}\")\n",
        "print(f\"   Dropout rate: {dropout_rate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Zd2OkfQYs2Q7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1629c6bc-3444-4875-d937-467d49376ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREANDO EL MODELO\n",
            "============================================================\n",
            "Construyendo arquitectura del modelo...\n",
            "Creando modelo LSTM para generaciÃ³n de texto:\n",
            "   Vocabulario: 93 caracteres Ãºnicos\n",
            "   Secuencias: 100 caracteres de entrada\n",
            "   Embedding: 256 dimensiones\n",
            "   LSTM: 512 unidades\n",
            "   Dropout: 0.3\n",
            "\n",
            "Modelo creado exitosamente!\n",
            "Tipo: Sequential\n",
            "Capas: 4\n",
            "\n",
            "Construyendo modelo con forma de entrada...\n",
            "Modelo construido con input_shape: (100,)\n",
            "\n",
            "------------------------------------------------------------\n",
            "RESUMEN DETALLADO DEL MODELO\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ char_embedding (\u001b[38;5;33mEmbedding\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚        \u001b[38;5;34m23,808\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚     \u001b[38;5;34m1,574,912\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m)             â”‚        \u001b[38;5;34m47,709\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ char_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,808</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,709</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,646,429\u001b[0m (6.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,646,429</span> (6.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,646,429\u001b[0m (6.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,646,429</span> (6.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AnÃ¡lisis de parÃ¡metros:\n",
            "   ParÃ¡metros totales: 1,646,429\n",
            "   Memoria del modelo (aprox): 6.3 MB\n",
            "\n",
            "Desglose por capas:\n",
            "   1. char_embedding  : 23,808 parÃ¡metros (1.4%)\n",
            "   2. lstm_layer      : 1,574,912 parÃ¡metros (95.7%)\n",
            "   3. dropout_layer   : 0 parÃ¡metros (0.0%)\n",
            "   4. output_layer    : 47,709 parÃ¡metros (2.9%)\n",
            "\n",
            "Formas del modelo:\n",
            "   Input shape: (None, 100)\n",
            "   Output shape: (None, 93)\n",
            "   Esperado input: (batch_size, 100)\n",
            "   Esperado output: (batch_size, 93)\n",
            "\n",
            "VerificaciÃ³n de compatibilidad:\n",
            "   X_train shape: (651866, 100)\n",
            "   y_train shape: (651866,)\n",
            "   Â¿Input compatible?: âœ“\n",
            "   Â¿Output compatible?: âœ“\n",
            "   Â¿Targets en rango?: âœ“\n",
            "\n",
            "CaracterÃ­sticas de la tarea:\n",
            "   Tipo: PredicciÃ³n de prÃ³ximo carÃ¡cter\n",
            "   Problema: ClasificaciÃ³n multiclase\n",
            "   Clases: 93 caracteres Ãºnicos\n",
            "   Secuencial: SÃ­ (LSTM)\n",
            "   Idioma: EspaÃ±ol (GarcÃ­a MÃ¡rquez)\n",
            "   GÃ©nero: Literatura (realismo mÃ¡gico)\n",
            "\n",
            "âœ“ Modelo definido y verificado, listo para compilaciÃ³n!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# BLOQUE 22 - Crear e inspeccionar el modelo\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"CREANDO EL MODELO\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "# Crear el modelo\n",
        "print(\"Construyendo arquitectura del modelo...\")\n",
        "model = create_char_lstm_model(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_length=seq_length,\n",
        "    embedding_dim=embedding_dim,\n",
        "    lstm_units=lstm_units,\n",
        "    dropout_rate=dropout_rate\n",
        ")\n",
        "\n",
        "print(f\"\\nModelo creado exitosamente!\")\n",
        "print(f\"Tipo: {type(model).__name__}\")\n",
        "print(f\"Capas: {len(model.layers)}\")\n",
        "\n",
        "# Construir el modelo manualmente con la forma de entrada correcta\n",
        "print(f\"\\nConstruyendo modelo con forma de entrada...\")\n",
        "input_shape = (seq_length,)  # Forma sin batch dimension\n",
        "model.build(input_shape=(None, seq_length))  # Con batch dimension para build\n",
        "\n",
        "print(f\"Modelo construido con input_shape: {input_shape}\")\n",
        "\n",
        "# Mostrar resumen detallado del modelo\n",
        "print(f\"\\n\" + \"-\" * 60)\n",
        "print(f\"RESUMEN DETALLADO DEL MODELO\")\n",
        "print(f\"-\" * 60)\n",
        "model.summary()\n",
        "\n",
        "# Calcular y mostrar informaciÃ³n de parÃ¡metros\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nAnÃ¡lisis de parÃ¡metros:\")\n",
        "print(f\"   ParÃ¡metros totales: {total_params:,}\")\n",
        "\n",
        "# Estimar memoria del modelo\n",
        "model_memory_mb = (total_params * 4) / (1024 * 1024)  # float32 = 4 bytes\n",
        "print(f\"   Memoria del modelo (aprox): {model_memory_mb:.1f} MB\")\n",
        "\n",
        "# Desglose de parÃ¡metros por capa\n",
        "print(f\"\\nDesglose por capas:\")\n",
        "for i, layer in enumerate(model.layers):\n",
        "    layer_params = layer.count_params()\n",
        "    percentage = (layer_params / total_params) * 100 if total_params > 0 else 0\n",
        "    print(f\"   {i+1}. {layer.name:15} : {layer_params:,} parÃ¡metros ({percentage:.1f}%)\")\n",
        "\n",
        "# Verificar formas de entrada y salida\n",
        "print(f\"\\nFormas del modelo:\")\n",
        "print(f\"   Input shape: {model.input_shape}\")\n",
        "print(f\"   Output shape: {model.output_shape}\")\n",
        "print(f\"   Esperado input: (batch_size, {seq_length})\")\n",
        "print(f\"   Esperado output: (batch_size, {vocab_size})\")\n",
        "\n",
        "# Verificar compatibilidad con nuestros datos\n",
        "print(f\"\\nVerificaciÃ³n de compatibilidad:\")\n",
        "print(f\"   X_train shape: {X_train.shape}\")\n",
        "print(f\"   y_train shape: {y_train.shape}\")\n",
        "print(f\"   Â¿Input compatible?: {'âœ“' if X_train.shape[1] == seq_length else 'âœ—'}\")\n",
        "print(f\"   Â¿Output compatible?: {'âœ“' if y_train.min() >= 0 and y_train.max() < vocab_size else 'âœ—'}\")\n",
        "print(f\"   Â¿Targets en rango?: {'âœ“' if 0 <= y_train.min() and y_train.max() < vocab_size else 'âœ—'}\")\n",
        "\n",
        "# InformaciÃ³n sobre la tarea\n",
        "print(f\"\\nCaracterÃ­sticas de la tarea:\")\n",
        "print(f\"   Tipo: PredicciÃ³n de prÃ³ximo carÃ¡cter\")\n",
        "print(f\"   Problema: ClasificaciÃ³n multiclase\")\n",
        "print(f\"   Clases: {vocab_size} caracteres Ãºnicos\")\n",
        "print(f\"   Secuencial: SÃ­ (LSTM)\")\n",
        "print(f\"   Idioma: EspaÃ±ol (GarcÃ­a MÃ¡rquez)\")\n",
        "print(f\"   GÃ©nero: Literatura (realismo mÃ¡gico)\")\n",
        "\n",
        "print(f\"\\nâœ“ Modelo definido y verificado, listo para compilaciÃ³n!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algÃºn evento, son muy Ãºtiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cÃ¡lculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "zUHX3r5JD-MG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fffd06-b3a0-4b2f-b62a-e9e85cefb2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "COMPILANDO EL MODELO\n",
            "============================================================\n",
            "Configurando optimizador y funciÃ³n de pÃ©rdida...\n",
            "Optimizador seleccionado:\n",
            "   Tipo: RMSprop (recomendado en Clase 4)\n",
            "   Learning rate: 0.001\n",
            "   JustificaciÃ³n: Mejor convergencia para RNNs\n",
            "\n",
            "Modelo compilado exitosamente:\n",
            "   Optimizador: RMSprop\n",
            "   FunciÃ³n de pÃ©rdida: sparse_categorical_crossentropy\n",
            "   MÃ©tricas: accuracy\n",
            "\n",
            "JustificaciÃ³n de sparse_categorical_crossentropy:\n",
            "   âœ“ Targets como Ã­ndices enteros (no one-hot)\n",
            "   âœ“ Problema de clasificaciÃ³n multiclase\n",
            "   âœ“ 93 clases (caracteres)\n",
            "   âœ“ Eficiente en memoria\n",
            "\n",
            "ConfiguraciÃ³n final del modelo:\n",
            "   Entrada: secuencias de 100 caracteres\n",
            "   Salida: probabilidades sobre 93 caracteres\n",
            "   ParÃ¡metros: 1,646,429\n",
            "   Memoria: 6.3 MB\n",
            "\n",
            "PreparaciÃ³n para entrenamiento:\n",
            "   Dataset: 651,866 secuencias de entrenamiento\n",
            "   ValidaciÃ³n: 162,967 secuencias\n",
            "   Batch size recomendado: 64-128\n",
            "   Ã‰pocas estimadas: 20-50\n",
            "\n",
            "============================================================\n",
            "MODELO LISTO PARA ENTRENAMIENTO\n",
            "============================================================\n",
            "âœ“ Arquitectura: Embedding + LSTM + Dropout + Dense\n",
            "âœ“ ParÃ¡metros: 1,646,429\n",
            "âœ“ Optimizador: RMSprop configurado\n",
            "âœ“ Loss: sparse_categorical_crossentropy\n",
            "âœ“ Compatibilidad: Verificada con dataset\n",
            "âœ“ Memoria: ~6.3 MB\n",
            "\n",
            "ðŸš€ Â¡Listo para entrenar modelo de GarcÃ­a MÃ¡rquez!\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 23 - COMPILAR EL MODELO\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPILANDO EL MODELO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Usar RMSprop como se recomienda en las sugerencias de la Clase 4\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "print(\"Configurando optimizador y funciÃ³n de pÃ©rdida...\")\n",
        "\n",
        "# Configurar optimizador RMSprop\n",
        "learning_rate = 0.001  # Learning rate inicial recomendado\n",
        "optimizer = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "print(f\"Optimizador seleccionado:\")\n",
        "print(f\"   Tipo: RMSprop (recomendado en Clase 4)\")\n",
        "print(f\"   Learning rate: {learning_rate}\")\n",
        "print(f\"   JustificaciÃ³n: Mejor convergencia para RNNs\")\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',  # Para targets como Ã­ndices enteros\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(f\"\\nModelo compilado exitosamente:\")\n",
        "print(f\"   Optimizador: RMSprop\")\n",
        "print(f\"   FunciÃ³n de pÃ©rdida: sparse_categorical_crossentropy\")\n",
        "print(f\"   MÃ©tricas: accuracy\")\n",
        "\n",
        "# Explicar la elecciÃ³n de la funciÃ³n de pÃ©rdida\n",
        "print(f\"\\nJustificaciÃ³n de sparse_categorical_crossentropy:\")\n",
        "print(f\"   âœ“ Targets como Ã­ndices enteros (no one-hot)\")\n",
        "print(f\"   âœ“ Problema de clasificaciÃ³n multiclase\")\n",
        "print(f\"   âœ“ {vocab_size} clases (caracteres)\")\n",
        "print(f\"   âœ“ Eficiente en memoria\")\n",
        "\n",
        "# Verificar configuraciÃ³n final\n",
        "print(f\"\\nConfiguraciÃ³n final del modelo:\")\n",
        "print(f\"   Entrada: secuencias de {seq_length} caracteres\")\n",
        "print(f\"   Salida: probabilidades sobre {vocab_size} caracteres\")\n",
        "print(f\"   ParÃ¡metros: {model.count_params():,}\")\n",
        "print(f\"   Memoria: {(model.count_params() * 4) / (1024*1024):.1f} MB\")\n",
        "\n",
        "# Preparar para entrenamiento\n",
        "print(f\"\\nPreparaciÃ³n para entrenamiento:\")\n",
        "print(f\"   Dataset: {len(X_train):,} secuencias de entrenamiento\")\n",
        "print(f\"   ValidaciÃ³n: {len(X_val):,} secuencias\")\n",
        "print(f\"   Batch size recomendado: 64-128\")\n",
        "print(f\"   Ã‰pocas estimadas: 20-50\")\n",
        "\n",
        "# Mostrar configuraciÃ³n completa una vez mÃ¡s\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"MODELO LISTO PARA ENTRENAMIENTO\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"âœ“ Arquitectura: Embedding + LSTM + Dropout + Dense\")\n",
        "print(f\"âœ“ ParÃ¡metros: {model.count_params():,}\")\n",
        "print(f\"âœ“ Optimizador: RMSprop configurado\")\n",
        "print(f\"âœ“ Loss: sparse_categorical_crossentropy\")\n",
        "print(f\"âœ“ Compatibilidad: Verificada con dataset\")\n",
        "print(f\"âœ“ Memoria: ~{(model.count_params() * 4) / (1024*1024):.1f} MB\")\n",
        "\n",
        "print(f\"\\nðŸš€ Â¡Listo para entrenar modelo de GarcÃ­a MÃ¡rquez!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98235a3-4225-40a0-fb70-7a06e066349e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONFIGURANDO CALLBACKS PARA ENTRENAMIENTO\n",
            "============================================================\n",
            "Configurando callbacks adicionales...\n",
            "Callbacks configurados:\n",
            "   âœ“ PerplexityCallback: monitoreo de perplejidad\n",
            "   âœ“ EarlyStopping: patience=15 Ã©pocas\n",
            "   âœ“ ReduceLROnPlateau: factor=0.5, patience=8\n",
            "   âœ“ ModelCheckpoint: guarda mejor modelo\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 24 - Definir callback para perplejidad y otros callbacks\n",
        "print(\"=\" * 60)\n",
        "print(\"CONFIGURANDO CALLBACKS PARA ENTRENAMIENTO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "class PerplexityCallback(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Callback personalizado para calcular y monitorear perplejidad durante entrenamiento\n",
        "    Como se sugiere en las instrucciones de la Clase 4: \"guiarse por el descenso de la perplejidad\"\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.train_perplexities = []\n",
        "        self.val_perplexities = []\n",
        "        self.epoch_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_perplexity = float('inf')\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Obtener losses del entrenamiento\n",
        "        train_loss = logs.get('loss', 0)\n",
        "        val_loss = logs.get('val_loss', 0)\n",
        "\n",
        "        # Calcular perplejidades (perplejidad = exp(loss))\n",
        "        train_perplexity = np.exp(train_loss)\n",
        "        val_perplexity = np.exp(val_loss)\n",
        "\n",
        "        # Guardar valores para anÃ¡lisis posterior\n",
        "        self.epoch_losses.append(train_loss)\n",
        "        self.val_losses.append(val_loss)\n",
        "        self.train_perplexities.append(train_perplexity)\n",
        "        self.val_perplexities.append(val_perplexity)\n",
        "\n",
        "        # Actualizar mejor perplejidad\n",
        "        if val_perplexity < self.best_val_perplexity:\n",
        "            self.best_val_perplexity = val_perplexity\n",
        "            self.best_epoch = epoch + 1\n",
        "\n",
        "        # Mostrar progreso con perplejidad\n",
        "        print(f\"   Ã‰poca {epoch+1:2d} - Train Perplexity: {train_perplexity:6.2f}, Val Perplexity: {val_perplexity:6.2f}\")\n",
        "\n",
        "        # Alerta si la perplejidad estÃ¡ aumentando mucho\n",
        "        if epoch > 5 and val_perplexity > min(self.val_perplexities[-5:]) * 1.2:\n",
        "            print(f\"   âš ï¸  Perplejidad aumentando - posible overfitting\")\n",
        "\n",
        "    def plot_perplexity(self):\n",
        "        \"\"\"Graficar evoluciÃ³n de la perplejidad\"\"\"\n",
        "        if len(self.train_perplexities) == 0:\n",
        "            print(\"No hay datos de perplejidad para graficar\")\n",
        "            return\n",
        "\n",
        "        epochs = range(1, len(self.train_perplexities) + 1)\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # GrÃ¡fico 1: Perplejidad\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(epochs, self.train_perplexities, 'b-', label='Train Perplexity', linewidth=2)\n",
        "        plt.plot(epochs, self.val_perplexities, 'r-', label='Val Perplexity', linewidth=2)\n",
        "        plt.axvline(x=self.best_epoch, color='g', linestyle='--', alpha=0.7, label=f'Best epoch ({self.best_epoch})')\n",
        "        plt.title('EvoluciÃ³n de la Perplejidad')\n",
        "        plt.xlabel('Ã‰poca')\n",
        "        plt.ylabel('Perplejidad')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # GrÃ¡fico 2: Loss\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(epochs, self.epoch_losses, 'b-', label='Train Loss', linewidth=2)\n",
        "        plt.plot(epochs, self.val_losses, 'r-', label='Val Loss', linewidth=2)\n",
        "        plt.axvline(x=self.best_epoch, color='g', linestyle='--', alpha=0.7, label=f'Best epoch ({self.best_epoch})')\n",
        "        plt.title('EvoluciÃ³n del Loss')\n",
        "        plt.xlabel('Ã‰poca')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # GrÃ¡fico 3: Perplejidad (escala log)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.semilogy(epochs, self.train_perplexities, 'b-', label='Train Perplexity', linewidth=2)\n",
        "        plt.semilogy(epochs, self.val_perplexities, 'r-', label='Val Perplexity', linewidth=2)\n",
        "        plt.axvline(x=self.best_epoch, color='g', linestyle='--', alpha=0.7, label=f'Best epoch ({self.best_epoch})')\n",
        "        plt.title('Perplejidad (Escala Log)')\n",
        "        plt.xlabel('Ã‰poca')\n",
        "        plt.ylabel('Perplejidad (log)')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Mostrar estadÃ­sticas finales\n",
        "        final_train_perp = self.train_perplexities[-1]\n",
        "        final_val_perp = self.val_perplexities[-1]\n",
        "\n",
        "        print(f\"\\nESTADÃSTICAS DE PERPLEJIDAD:\")\n",
        "        print(f\"   Mejor perplejidad de validaciÃ³n: {self.best_val_perplexity:.2f} (Ã©poca {self.best_epoch})\")\n",
        "        print(f\"   Perplejidad final de entrenamiento: {final_train_perp:.2f}\")\n",
        "        print(f\"   Perplejidad final de validaciÃ³n: {final_val_perp:.2f}\")\n",
        "\n",
        "        # EvaluaciÃ³n del entrenamiento\n",
        "        if final_val_perp < self.best_val_perplexity * 1.1:\n",
        "            print(f\"   âœ“ Entrenamiento exitoso - perplejidad estable\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸  Posible overfitting - perplejidad final > mejor perplejidad\")\n",
        "\n",
        "# Crear callback de perplejidad\n",
        "perplexity_callback = PerplexityCallback()\n",
        "\n",
        "# Configurar callbacks adicionales para entrenamiento robusto\n",
        "print(\"Configurando callbacks adicionales...\")\n",
        "\n",
        "# Early stopping: parar si no hay mejora en perplejidad\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,  # MÃ¡s paciencia para modelos de lenguaje\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    min_delta=0.001\n",
        ")\n",
        "\n",
        "# Reducir learning rate cuando la perplejidad se estanque\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=8,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1,\n",
        "    cooldown=2\n",
        ")\n",
        "\n",
        "# Guardar el mejor modelo\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_garcia_marquez_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Lista de todos los callbacks\n",
        "callbacks = [perplexity_callback, early_stopping, reduce_lr, model_checkpoint]\n",
        "\n",
        "print(f\"Callbacks configurados:\")\n",
        "print(f\"   âœ“ PerplexityCallback: monitoreo de perplejidad\")\n",
        "print(f\"   âœ“ EarlyStopping: patience={15} Ã©pocas\")\n",
        "print(f\"   âœ“ ReduceLROnPlateau: factor=0.5, patience={8}\")\n",
        "print(f\"   âœ“ ModelCheckpoint: guarda mejor modelo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "K30JHB3Dv-mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cefc38e-ccbf-4095-9099-7ae95b18ac65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURANDO PARÃMETROS DE ENTRENAMIENTO\n",
            "============================================================\n",
            "ConfiguraciÃ³n de entrenamiento:\n",
            "   Batch size: 128\n",
            "   Ã‰pocas mÃ¡ximas: 50\n",
            "   Frecuencia de validaciÃ³n: cada 1 Ã©poca\n",
            "\n",
            "EstadÃ­sticas del entrenamiento:\n",
            "   Muestras de entrenamiento: 651,866\n",
            "   Muestras de validaciÃ³n: 162,967\n",
            "   Pasos por Ã©poca: 5,092\n",
            "   Pasos de validaciÃ³n: 1,273\n",
            "   Pasos totales estimados: 254,600\n",
            "\n",
            "Estimaciones de tiempo:\n",
            "   Tiempo estimado por paso: 1.0s\n",
            "   Tiempo total estimado: 70.7 horas\n",
            "   Tiempo por Ã©poca estimado: 84.9 minutos\n",
            "\n",
            "Uso de memoria estimado:\n",
            "   Modelo: 6.3 MB\n",
            "   Datos: 251.2 MB\n",
            "   Total: 257.4 MB\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 25 - Configurar parÃ¡metros de entrenamiento\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"CONFIGURANDO PARÃMETROS DE ENTRENAMIENTO\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "# ParÃ¡metros de entrenamiento optimizados para el corpus de GarcÃ­a MÃ¡rquez\n",
        "batch_size = 128      # Balance entre memoria y convergencia\n",
        "epochs = 50          # MÃ¡ximo, early stopping puede parar antes\n",
        "validation_freq = 1   # Validar cada Ã©poca\n",
        "\n",
        "print(f\"ConfiguraciÃ³n de entrenamiento:\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Ã‰pocas mÃ¡ximas: {epochs}\")\n",
        "print(f\"   Frecuencia de validaciÃ³n: cada {validation_freq} Ã©poca\")\n",
        "\n",
        "# Calcular estadÃ­sticas de entrenamiento\n",
        "steps_per_epoch = len(X_train) // batch_size\n",
        "validation_steps = len(X_val) // batch_size\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "print(f\"\\nEstadÃ­sticas del entrenamiento:\")\n",
        "print(f\"   Muestras de entrenamiento: {len(X_train):,}\")\n",
        "print(f\"   Muestras de validaciÃ³n: {len(X_val):,}\")\n",
        "print(f\"   Pasos por Ã©poca: {steps_per_epoch:,}\")\n",
        "print(f\"   Pasos de validaciÃ³n: {validation_steps:,}\")\n",
        "print(f\"   Pasos totales estimados: {total_steps:,}\")\n",
        "\n",
        "# Estimar tiempo de entrenamiento (muy aproximado)\n",
        "# Basado en modelos similares: ~0.5-2 segundos por step con LSTM\n",
        "time_per_step_est = 1.0  # segundos (estimaciÃ³n conservadora)\n",
        "total_time_est = (total_steps * time_per_step_est) / 3600  # horas\n",
        "\n",
        "print(f\"\\nEstimaciones de tiempo:\")\n",
        "print(f\"   Tiempo estimado por paso: {time_per_step_est:.1f}s\")\n",
        "print(f\"   Tiempo total estimado: {total_time_est:.1f} horas\")\n",
        "print(f\"   Tiempo por Ã©poca estimado: {(steps_per_epoch * time_per_step_est / 60):.1f} minutos\")\n",
        "\n",
        "# InformaciÃ³n sobre el modelo y hardware\n",
        "model_memory = (model.count_params() * 4) / (1024**2)  # MB\n",
        "data_memory = (X_train.nbytes + y_train.nbytes) / (1024**2)  # MB\n",
        "total_memory = model_memory + data_memory\n",
        "\n",
        "print(f\"\\nUso de memoria estimado:\")\n",
        "print(f\"   Modelo: {model_memory:.1f} MB\")\n",
        "print(f\"   Datos: {data_memory:.1f} MB\")\n",
        "print(f\"   Total: {total_memory:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Rhy5hZN38qfO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2931307d-423f-40eb-8e7f-d23b615bb6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "INICIANDO ENTRENAMIENTO DEL MODELO GARCÃA MÃRQUEZ\n",
            "============================================================\n",
            "ConfiguraciÃ³n final:\n",
            "   ðŸ“š Corpus: 'Cien aÃ±os de soledad' de GarcÃ­a MÃ¡rquez\n",
            "   ðŸ§  Modelo: LSTM con 1,646,429 parÃ¡metros\n",
            "   ðŸ“Š Datos: 651,866 secuencias de entrenamiento\n",
            "   âš™ï¸  Batch size: 128\n",
            "   ðŸŽ¯ Objetivo: Aprender a generar texto estilo GarcÃ­a MÃ¡rquez\n",
            "\n",
            "GuiÃ¡ndose por el descenso de la perplejidad como sugiere la Clase 4...\n",
            "Comenzando entrenamiento...\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3609 - loss: 2.1923   Ã‰poca  1 - Train Perplexity:   6.57, Val Perplexity:   4.62\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.53089, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 53ms/step - accuracy: 0.3609 - loss: 2.1922 - val_accuracy: 0.5390 - val_loss: 1.5309 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5495 - loss: 1.5001   Ã‰poca  2 - Train Perplexity:   4.31, Val Perplexity:   3.96\n",
            "\n",
            "Epoch 2: val_loss improved from 1.53089 to 1.37555, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 53ms/step - accuracy: 0.5495 - loss: 1.5001 - val_accuracy: 0.5835 - val_loss: 1.3756 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5924 - loss: 1.3489   Ã‰poca  3 - Train Perplexity:   3.81, Val Perplexity:   3.72\n",
            "\n",
            "Epoch 3: val_loss improved from 1.37555 to 1.31481, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.5924 - loss: 1.3489 - val_accuracy: 0.5997 - val_loss: 1.3148 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6131 - loss: 1.2716   Ã‰poca  4 - Train Perplexity:   3.56, Val Perplexity:   3.61\n",
            "\n",
            "Epoch 4: val_loss improved from 1.31481 to 1.28388, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 53ms/step - accuracy: 0.6131 - loss: 1.2716 - val_accuracy: 0.6097 - val_loss: 1.2839 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6266 - loss: 1.2202   Ã‰poca  5 - Train Perplexity:   3.40, Val Perplexity:   3.54\n",
            "\n",
            "Epoch 5: val_loss improved from 1.28388 to 1.26328, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 49ms/step - accuracy: 0.6266 - loss: 1.2202 - val_accuracy: 0.6155 - val_loss: 1.2633 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6362 - loss: 1.1829   Ã‰poca  6 - Train Perplexity:   3.29, Val Perplexity:   3.51\n",
            "\n",
            "Epoch 6: val_loss improved from 1.26328 to 1.25497, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 53ms/step - accuracy: 0.6362 - loss: 1.1829 - val_accuracy: 0.6205 - val_loss: 1.2550 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6445 - loss: 1.1547   Ã‰poca  7 - Train Perplexity:   3.20, Val Perplexity:   3.48\n",
            "\n",
            "Epoch 7: val_loss improved from 1.25497 to 1.24759, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.6445 - loss: 1.1547 - val_accuracy: 0.6230 - val_loss: 1.2476 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6503 - loss: 1.1334   Ã‰poca  8 - Train Perplexity:   3.14, Val Perplexity:   3.45\n",
            "\n",
            "Epoch 8: val_loss improved from 1.24759 to 1.23859, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 53ms/step - accuracy: 0.6503 - loss: 1.1334 - val_accuracy: 0.6259 - val_loss: 1.2386 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6561 - loss: 1.1120   Ã‰poca  9 - Train Perplexity:   3.08, Val Perplexity:   3.46\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.23859\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 49ms/step - accuracy: 0.6561 - loss: 1.1120 - val_accuracy: 0.6267 - val_loss: 1.2414 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6585 - loss: 1.1022   Ã‰poca 10 - Train Perplexity:   3.04, Val Perplexity:   3.45\n",
            "\n",
            "Epoch 10: val_loss improved from 1.23859 to 1.23785, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 53ms/step - accuracy: 0.6585 - loss: 1.1023 - val_accuracy: 0.6272 - val_loss: 1.2379 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6625 - loss: 1.0866   Ã‰poca 11 - Train Perplexity:   3.01, Val Perplexity:   3.46\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.6625 - loss: 1.0866 - val_accuracy: 0.6269 - val_loss: 1.2406 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6646 - loss: 1.0786   Ã‰poca 12 - Train Perplexity:   2.99, Val Perplexity:   3.46\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.6646 - loss: 1.0786 - val_accuracy: 0.6269 - val_loss: 1.2415 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6678 - loss: 1.0693   Ã‰poca 13 - Train Perplexity:   2.96, Val Perplexity:   3.47\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 49ms/step - accuracy: 0.6678 - loss: 1.0693 - val_accuracy: 0.6264 - val_loss: 1.2444 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6690 - loss: 1.0650   Ã‰poca 14 - Train Perplexity:   2.95, Val Perplexity:   3.47\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 49ms/step - accuracy: 0.6690 - loss: 1.0650 - val_accuracy: 0.6274 - val_loss: 1.2430 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6685 - loss: 1.0637   Ã‰poca 15 - Train Perplexity:   2.94, Val Perplexity:   3.48\n",
            "\n",
            "Epoch 15: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 53ms/step - accuracy: 0.6685 - loss: 1.0637 - val_accuracy: 0.6282 - val_loss: 1.2483 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6691 - loss: 1.0636   Ã‰poca 16 - Train Perplexity:   2.94, Val Perplexity:   3.49\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 53ms/step - accuracy: 0.6691 - loss: 1.0636 - val_accuracy: 0.6276 - val_loss: 1.2500 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6704 - loss: 1.0609   Ã‰poca 17 - Train Perplexity:   2.94, Val Perplexity:   3.49\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 53ms/step - accuracy: 0.6704 - loss: 1.0609 - val_accuracy: 0.6261 - val_loss: 1.2485 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6701 - loss: 1.0594   Ã‰poca 18 - Train Perplexity:   2.94, Val Perplexity:   3.51\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 1.23785\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 49ms/step - accuracy: 0.6701 - loss: 1.0594 - val_accuracy: 0.6256 - val_loss: 1.2543 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6807 - loss: 1.0225   Ã‰poca 19 - Train Perplexity:   2.77, Val Perplexity:   3.44\n",
            "\n",
            "Epoch 19: val_loss improved from 1.23785 to 1.23488, saving model to best_garcia_marquez_model.keras\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 53ms/step - accuracy: 0.6807 - loss: 1.0225 - val_accuracy: 0.6330 - val_loss: 1.2349 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6939 - loss: 0.9764   Ã‰poca 20 - Train Perplexity:   2.68, Val Perplexity:   3.46\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 49ms/step - accuracy: 0.6939 - loss: 0.9764 - val_accuracy: 0.6315 - val_loss: 1.2408 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6992 - loss: 0.9588   Ã‰poca 21 - Train Perplexity:   2.64, Val Perplexity:   3.48\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 53ms/step - accuracy: 0.6992 - loss: 0.9588 - val_accuracy: 0.6332 - val_loss: 1.2458 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7033 - loss: 0.9436   Ã‰poca 22 - Train Perplexity:   2.61, Val Perplexity:   3.48\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 53ms/step - accuracy: 0.7033 - loss: 0.9436 - val_accuracy: 0.6319 - val_loss: 1.2468 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7040 - loss: 0.9397   Ã‰poca 23 - Train Perplexity:   2.59, Val Perplexity:   3.49\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.7040 - loss: 0.9397 - val_accuracy: 0.6320 - val_loss: 1.2498 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7072 - loss: 0.9304   Ã‰poca 24 - Train Perplexity:   2.57, Val Perplexity:   3.52\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 49ms/step - accuracy: 0.7071 - loss: 0.9304 - val_accuracy: 0.6308 - val_loss: 1.2577 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7084 - loss: 0.9275   Ã‰poca 25 - Train Perplexity:   2.56, Val Perplexity:   3.54\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 53ms/step - accuracy: 0.7084 - loss: 0.9275 - val_accuracy: 0.6302 - val_loss: 1.2643 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7089 - loss: 0.9227   Ã‰poca 26 - Train Perplexity:   2.55, Val Perplexity:   3.55\n",
            "\n",
            "Epoch 26: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.7089 - loss: 0.9227 - val_accuracy: 0.6311 - val_loss: 1.2677 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7074 - loss: 0.9243   Ã‰poca 27 - Train Perplexity:   2.54, Val Perplexity:   3.57\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 54ms/step - accuracy: 0.7074 - loss: 0.9243 - val_accuracy: 0.6289 - val_loss: 1.2721 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7191 - loss: 0.8899   Ã‰poca 28 - Train Perplexity:   2.43, Val Perplexity:   3.56\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 49ms/step - accuracy: 0.7191 - loss: 0.8899 - val_accuracy: 0.6304 - val_loss: 1.2694 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7290 - loss: 0.8568   Ã‰poca 29 - Train Perplexity:   2.37, Val Perplexity:   3.59\n",
            "\n",
            "Epoch 29: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 49ms/step - accuracy: 0.7290 - loss: 0.8569 - val_accuracy: 0.6318 - val_loss: 1.2768 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7327 - loss: 0.8446   Ã‰poca 30 - Train Perplexity:   2.34, Val Perplexity:   3.62\n",
            "\n",
            "Epoch 30: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 53ms/step - accuracy: 0.7327 - loss: 0.8446 - val_accuracy: 0.6300 - val_loss: 1.2862 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7356 - loss: 0.8326   Ã‰poca 31 - Train Perplexity:   2.32, Val Perplexity:   3.64\n",
            "\n",
            "Epoch 31: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 53ms/step - accuracy: 0.7356 - loss: 0.8326 - val_accuracy: 0.6288 - val_loss: 1.2915 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7389 - loss: 0.8245   Ã‰poca 32 - Train Perplexity:   2.30, Val Perplexity:   3.66\n",
            "\n",
            "Epoch 32: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 49ms/step - accuracy: 0.7389 - loss: 0.8245 - val_accuracy: 0.6281 - val_loss: 1.2981 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m5092/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7406 - loss: 0.8198   Ã‰poca 33 - Train Perplexity:   2.29, Val Perplexity:   3.69\n",
            "\n",
            "Epoch 33: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 53ms/step - accuracy: 0.7406 - loss: 0.8198 - val_accuracy: 0.6292 - val_loss: 1.3048 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7418 - loss: 0.8139   Ã‰poca 34 - Train Perplexity:   2.27, Val Perplexity:   3.71\n",
            "\n",
            "Epoch 34: val_loss did not improve from 1.23488\n",
            "\u001b[1m5093/5093\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 53ms/step - accuracy: 0.7418 - loss: 0.8139 - val_accuracy: 0.6274 - val_loss: 1.3106 - learning_rate: 2.5000e-04\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\n",
            "============================================================\n",
            "ENTRENAMIENTO COMPLETADO\n",
            "============================================================\n",
            "Generando grÃ¡ficos de perplejidad...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ESTADÃSTICAS DE PERPLEJIDAD:\n",
            "   Mejor perplejidad de validaciÃ³n: 3.44 (Ã©poca 19)\n",
            "   Perplejidad final de entrenamiento: 2.27\n",
            "   Perplejidad final de validaciÃ³n: 3.71\n",
            "   âœ“ Entrenamiento exitoso - perplejidad estable\n",
            "Evaluando modelo final...\n",
            "\n",
            "RESULTADOS FINALES DEL ENTRENAMIENTO:\n",
            "   ðŸ“ˆ Train - Loss: 0.8745, Accuracy: 0.7235, Perplejidad: 2.40\n",
            "   ðŸ“Š Val   - Loss: 1.2349, Accuracy: 0.6330, Perplejidad: 3.44\n",
            "\n",
            "COMPARACIÃ“N CON BASELINE ALEATORIO:\n",
            "   ðŸŽ² Accuracy aleatoria: 0.010753\n",
            "   ðŸŽ² Perplejidad aleatoria: 93\n",
            "   ðŸ“ˆ Mejora en perplejidad: 27.1x\n",
            "   ðŸ“ˆ Mejora en accuracy: 58.9x\n",
            "\n",
            "EVALUACIÃ“N DE CALIDAD DEL MODELO:\n",
            "   ðŸŽ¯ Perplejidad de validaciÃ³n: 3.44 (Excelente)\n",
            "   ðŸ“š Capacidad de aprender GarcÃ­a MÃ¡rquez: Alta\n",
            "\n",
            "ðŸ’¾ Modelo guardado como: best_garcia_marquez_model.keras\n",
            "ðŸ’¾ Info de entrenamiento: garcia_marquez_training_info.pkl\n",
            "\n",
            "ðŸŽ‰ Â¡MODELO DE GARCÃA MÃRQUEZ ENTRENADO EXITOSAMENTE!\n",
            "ðŸš€ Listo para generar texto estilo 'Cien aÃ±os de soledad'!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# BLOQUE 26 - Entrenar el modelo\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"INICIANDO ENTRENAMIENTO DEL MODELO GARCÃA MÃRQUEZ\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "print(f\"ConfiguraciÃ³n final:\")\n",
        "print(f\"   ðŸ“š Corpus: 'Cien aÃ±os de soledad' de GarcÃ­a MÃ¡rquez\")\n",
        "print(f\"   ðŸ§  Modelo: LSTM con {model.count_params():,} parÃ¡metros\")\n",
        "print(f\"   ðŸ“Š Datos: {len(X_train):,} secuencias de entrenamiento\")\n",
        "print(f\"   âš™ï¸  Batch size: {batch_size}\")\n",
        "print(f\"   ðŸŽ¯ Objetivo: Aprender a generar texto estilo GarcÃ­a MÃ¡rquez\")\n",
        "\n",
        "print(f\"\\nGuiÃ¡ndose por el descenso de la perplejidad como sugiere la Clase 4...\")\n",
        "print(f\"Comenzando entrenamiento...\\n\")\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    validation_freq=validation_freq\n",
        ")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"ENTRENAMIENTO COMPLETADO\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "# Mostrar grÃ¡ficos de perplejidad\n",
        "print(\"Generando grÃ¡ficos de perplejidad...\")\n",
        "perplexity_callback.plot_perplexity()\n",
        "\n",
        "# Evaluar modelo final\n",
        "print(\"Evaluando modelo final...\")\n",
        "final_train_loss, final_train_acc = model.evaluate(X_train, y_train, verbose=0, batch_size=batch_size)\n",
        "final_val_loss, final_val_acc = model.evaluate(X_val, y_val, verbose=0, batch_size=batch_size)\n",
        "\n",
        "final_train_perp = np.exp(final_train_loss)\n",
        "final_val_perp = np.exp(final_val_loss)\n",
        "\n",
        "print(f\"\\nRESULTADOS FINALES DEL ENTRENAMIENTO:\")\n",
        "print(f\"   ðŸ“ˆ Train - Loss: {final_train_loss:.4f}, Accuracy: {final_train_acc:.4f}, Perplejidad: {final_train_perp:.2f}\")\n",
        "print(f\"   ðŸ“Š Val   - Loss: {final_val_loss:.4f}, Accuracy: {final_val_acc:.4f}, Perplejidad: {final_val_perp:.2f}\")\n",
        "\n",
        "# Comparar con baseline aleatorio\n",
        "random_accuracy = 1.0 / vocab_size\n",
        "random_perplexity = vocab_size\n",
        "improvement_factor = random_perplexity / final_val_perp\n",
        "\n",
        "print(f\"\\nCOMPARACIÃ“N CON BASELINE ALEATORIO:\")\n",
        "print(f\"   ðŸŽ² Accuracy aleatoria: {random_accuracy:.6f}\")\n",
        "print(f\"   ðŸŽ² Perplejidad aleatoria: {random_perplexity:.0f}\")\n",
        "print(f\"   ðŸ“ˆ Mejora en perplejidad: {improvement_factor:.1f}x\")\n",
        "print(f\"   ðŸ“ˆ Mejora en accuracy: {final_val_acc/random_accuracy:.1f}x\")\n",
        "\n",
        "# Evaluar calidad del entrenamiento\n",
        "if final_val_perp < 10:\n",
        "    quality = \"Excelente\"\n",
        "elif final_val_perp < 20:\n",
        "    quality = \"Muy buena\"\n",
        "elif final_val_perp < 50:\n",
        "    quality = \"Buena\"\n",
        "else:\n",
        "    quality = \"Mejorable\"\n",
        "\n",
        "print(f\"\\nEVALUACIÃ“N DE CALIDAD DEL MODELO:\")\n",
        "print(f\"   ðŸŽ¯ Perplejidad de validaciÃ³n: {final_val_perp:.2f} ({quality})\")\n",
        "print(f\"   ðŸ“š Capacidad de aprender GarcÃ­a MÃ¡rquez: {'Alta' if final_val_perp < 15 else 'Media' if final_val_perp < 30 else 'Baja'}\")\n",
        "\n",
        "# Guardar informaciÃ³n de entrenamiento\n",
        "training_info = {\n",
        "    'history': history.history,\n",
        "    'final_val_perplexity': final_val_perp,\n",
        "    'final_val_accuracy': final_val_acc,\n",
        "    'final_train_perplexity': final_train_perp,\n",
        "    'final_train_accuracy': final_train_acc,\n",
        "    'vocab_size': vocab_size,\n",
        "    'seq_length': seq_length,\n",
        "    'improvement_factor': improvement_factor,\n",
        "    'epochs_trained': len(history.history['loss']),\n",
        "    'best_epoch': perplexity_callback.best_epoch,\n",
        "    'best_val_perplexity': perplexity_callback.best_val_perplexity\n",
        "}\n",
        "\n",
        "with open('garcia_marquez_training_info.pkl', 'wb') as f:\n",
        "    pickle.dump(training_info, f)\n",
        "\n",
        "print(f\"\\nðŸ’¾ Modelo guardado como: best_garcia_marquez_model.keras\")\n",
        "print(f\"ðŸ’¾ Info de entrenamiento: garcia_marquez_training_info.pkl\")\n",
        "\n",
        "print(f\"\\nðŸŽ‰ Â¡MODELO DE GARCÃA MÃRQUEZ ENTRENADO EXITOSAMENTE!\")\n",
        "print(f\"ðŸš€ Listo para generar texto estilo 'Cien aÃ±os de soledad'!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### PredicciÃ³n del prÃ³ximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e977d5-f343-431e-e086-742cd198e953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PREDICCIÃ“N DEL PRÃ“XIMO CARÃCTER\n",
            "============================================================\n",
            "Funciones de predicciÃ³n definidas:\n",
            "   âœ“ predict_next_char: predicciÃ³n bÃ¡sica\n",
            "   âœ“ analyze_predictions: anÃ¡lisis de probabilidades\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 27 - FunciÃ³n para predicciÃ³n del prÃ³ximo carÃ¡cter\n",
        "print(\"=\" * 60)\n",
        "print(\"PREDICCIÃ“N DEL PRÃ“XIMO CARÃCTER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def predict_next_char(model, seed_text, char2idx, idx2char, seq_length):\n",
        "    \"\"\"\n",
        "    Predice el prÃ³ximo carÃ¡cter dado un texto semilla\n",
        "    FunciÃ³n base para todas las estrategias de generaciÃ³n\n",
        "\n",
        "    Args:\n",
        "        model: modelo LSTM entrenado\n",
        "        seed_text: texto inicial para predicciÃ³n\n",
        "        char2idx: diccionario char -> Ã­ndice\n",
        "        idx2char: diccionario Ã­ndice -> char\n",
        "        seq_length: longitud de secuencia del modelo\n",
        "\n",
        "    Returns:\n",
        "        predicted_char: carÃ¡cter predicho\n",
        "        predictions: probabilidades completas del vocabulario\n",
        "    \"\"\"\n",
        "    # Preparar secuencia de entrada\n",
        "    if len(seed_text) >= seq_length:\n",
        "        # Usar los Ãºltimos seq_length caracteres\n",
        "        input_sequence = seed_text[-seq_length:]\n",
        "    else:\n",
        "        # Si el texto es muy corto, rellenar con espacios al inicio\n",
        "        input_sequence = seed_text.rjust(seq_length, ' ')\n",
        "\n",
        "    # Convertir caracteres a Ã­ndices\n",
        "    sequence_indices = []\n",
        "    for char in input_sequence:\n",
        "        if char in char2idx:\n",
        "            sequence_indices.append(char2idx[char])\n",
        "        else:\n",
        "            # Usar espacio para caracteres desconocidos\n",
        "            sequence_indices.append(char2idx.get(' ', 0))\n",
        "\n",
        "    # Convertir a array numpy y agregar dimensiÃ³n batch\n",
        "    x = np.array(sequence_indices).reshape(1, seq_length)\n",
        "\n",
        "    # Obtener predicciones del modelo\n",
        "    predictions = model.predict(x, verbose=0)\n",
        "\n",
        "    # Obtener Ã­ndice del carÃ¡cter mÃ¡s probable (greedy)\n",
        "    predicted_idx = np.argmax(predictions[0])\n",
        "    predicted_char = idx2char[predicted_idx]\n",
        "\n",
        "    return predicted_char, predictions[0]\n",
        "\n",
        "def analyze_predictions(predictions, idx2char, top_k=10):\n",
        "    \"\"\"\n",
        "    Analiza las predicciones del modelo mostrando los caracteres mÃ¡s probables\n",
        "    \"\"\"\n",
        "    # Obtener top K predicciones\n",
        "    top_indices = np.argsort(predictions)[-top_k:][::-1]\n",
        "    top_probs = predictions[top_indices]\n",
        "    top_chars = [idx2char[idx] for idx in top_indices]\n",
        "\n",
        "    print(f\"Top {top_k} caracteres mÃ¡s probables:\")\n",
        "    for i, (char_idx, char, prob) in enumerate(zip(top_indices, top_chars, top_probs)):\n",
        "        # Formatear caracteres especiales para mejor visualizaciÃ³n\n",
        "        if char == ' ':\n",
        "            char_display = \"'espacio'\"\n",
        "        elif char == '\\n':\n",
        "            char_display = \"'salto'\"\n",
        "        elif char in '\\t\\r':\n",
        "            char_display = f\"'{repr(char)}'\"\n",
        "        else:\n",
        "            char_display = f\"'{char}'\"\n",
        "\n",
        "        print(f\"   {i+1:2d}. {char_display:>12} -> {prob:.4f} ({prob*100:5.1f}%)\")\n",
        "\n",
        "    return top_chars, top_probs\n",
        "\n",
        "print(\"Funciones de predicciÃ³n definidas:\")\n",
        "print(\"   âœ“ predict_next_char: predicciÃ³n bÃ¡sica\")\n",
        "print(\"   âœ“ analyze_predictions: anÃ¡lisis de probabilidades\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a78aa49-32e0-4688-e395-607b5b6107e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DE PREDICCIÃ“N CON FRASES DE GARCÃA MÃRQUEZ\n",
            "============================================================\n",
            "Probando predicciÃ³n con 8 frases inspiradas en GarcÃ­a MÃ¡rquez:\n",
            "Cada predicciÃ³n muestra el carÃ¡cter mÃ¡s probable y anÃ¡lisis detallado\n",
            "\n",
            "PRUEBA 1:\n",
            "Semilla: 'Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a habÃ­a de'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a habÃ­a de '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.4833 ( 48.3%)\n",
            "    2.          's' -> 0.2284 ( 22.8%)\n",
            "    3.          'j' -> 0.1032 ( 10.3%)\n",
            "    4.      'salto' -> 0.0490 (  4.9%)\n",
            "    5.          'c' -> 0.0445 (  4.4%)\n",
            "    6.          'm' -> 0.0219 (  2.2%)\n",
            "    7.          't' -> 0.0151 (  1.5%)\n",
            "    8.          'd' -> 0.0105 (  1.1%)\n",
            "EntropÃ­a de la predicciÃ³n: 1.645 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Alta (0.483)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 2:\n",
            "Semilla: 'Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava construidas a la orilla'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava construidas a la orilla '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.8926 ( 89.3%)\n",
            "    2.          ',' -> 0.0551 (  5.5%)\n",
            "    3.      'salto' -> 0.0242 (  2.4%)\n",
            "    4.          '.' -> 0.0234 (  2.3%)\n",
            "    5.          'n' -> 0.0013 (  0.1%)\n",
            "    6.          's' -> 0.0008 (  0.1%)\n",
            "    7.          'c' -> 0.0007 (  0.1%)\n",
            "    8.          'p' -> 0.0004 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.477 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.893)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 3:\n",
            "Semilla: 'La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma, con las puertas'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma, con las puertas '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.9417 ( 94.2%)\n",
            "    2.          ',' -> 0.0289 (  2.9%)\n",
            "    3.      'salto' -> 0.0213 (  2.1%)\n",
            "    4.          '.' -> 0.0079 (  0.8%)\n",
            "    5.          'a' -> 0.0000 (  0.0%)\n",
            "    6.          'e' -> 0.0000 (  0.0%)\n",
            "    7.          'i' -> 0.0000 (  0.0%)\n",
            "    8.          'Â»' -> 0.0000 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.282 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.942)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 4:\n",
            "Semilla: 'Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os y tenÃ­a'\n",
            "PredicciÃ³n: 'n'\n",
            "Resultado: 'Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os y tenÃ­an'\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.          'n' -> 0.5046 ( 50.5%)\n",
            "    2.    'espacio' -> 0.4855 ( 48.6%)\n",
            "    3.      'salto' -> 0.0085 (  0.9%)\n",
            "    4.          ',' -> 0.0003 (  0.0%)\n",
            "    5.          '.' -> 0.0002 (  0.0%)\n",
            "    6.          't' -> 0.0002 (  0.0%)\n",
            "    7.          's' -> 0.0002 (  0.0%)\n",
            "    8.          'e' -> 0.0001 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.749 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.505)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 5:\n",
            "Semilla: 'El mundo era tan reciente, que muchas cosas carecÃ­an de nombre, y para mencionarlas habÃ­a'\n",
            "PredicciÃ³n: 'n'\n",
            "Resultado: 'El mundo era tan reciente, que muchas cosas carecÃ­an de nombre, y para mencionarlas habÃ­an'\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.          'n' -> 0.7329 ( 73.3%)\n",
            "    2.    'espacio' -> 0.2450 ( 24.5%)\n",
            "    3.      'salto' -> 0.0198 (  2.0%)\n",
            "    4.          's' -> 0.0012 (  0.1%)\n",
            "    5.          'l' -> 0.0004 (  0.0%)\n",
            "    6.          'b' -> 0.0001 (  0.0%)\n",
            "    7.          'm' -> 0.0001 (  0.0%)\n",
            "    8.          't' -> 0.0001 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.668 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.733)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 6:\n",
            "Semilla: 'JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor que se verÃ­a jamÃ¡s en la aldea'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor que se verÃ­a jamÃ¡s en la aldea '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.4610 ( 46.1%)\n",
            "    2.          '.' -> 0.3112 ( 31.1%)\n",
            "    3.          ',' -> 0.2120 ( 21.2%)\n",
            "    4.      'salto' -> 0.0137 (  1.4%)\n",
            "    5.          'r' -> 0.0007 (  0.1%)\n",
            "    6.          'n' -> 0.0005 (  0.1%)\n",
            "    7.          'd' -> 0.0002 (  0.0%)\n",
            "    8.          'b' -> 0.0001 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 1.126 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Alta (0.461)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 7:\n",
            "Semilla: 'En marzo volvieron los gitanos. Esta vez llevaban un catalejo y una lupa del tamaÃ±o'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'En marzo volvieron los gitanos. Esta vez llevaban un catalejo y una lupa del tamaÃ±o '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.7075 ( 70.8%)\n",
            "    2.          ',' -> 0.1734 ( 17.3%)\n",
            "    3.          '.' -> 0.0968 (  9.7%)\n",
            "    4.      'salto' -> 0.0171 (  1.7%)\n",
            "    5.          'r' -> 0.0025 (  0.2%)\n",
            "    6.          ':' -> 0.0006 (  0.1%)\n",
            "    7.          'o' -> 0.0005 (  0.1%)\n",
            "    8.          'a' -> 0.0003 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.883 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.708)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "PRUEBA 8:\n",
            "Semilla: 'La soledad de AmÃ©rica Latina se volviÃ³ palpable en las calles desiertas donde'\n",
            "PredicciÃ³n: ' '\n",
            "Resultado: 'La soledad de AmÃ©rica Latina se volviÃ³ palpable en las calles desiertas donde '\n",
            "Top 8 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.9207 ( 92.1%)\n",
            "    2.      'salto' -> 0.0768 (  7.7%)\n",
            "    3.          'l' -> 0.0010 (  0.1%)\n",
            "    4.          's' -> 0.0004 (  0.0%)\n",
            "    5.          ',' -> 0.0002 (  0.0%)\n",
            "    6.          'c' -> 0.0001 (  0.0%)\n",
            "    7.          'd' -> 0.0001 (  0.0%)\n",
            "    8.          'a' -> 0.0001 (  0.0%)\n",
            "EntropÃ­a de la predicciÃ³n: 0.294 (menor = mÃ¡s confianza)\n",
            "Confianza del modelo: Muy alta (0.921)\n",
            "Caracteres tÃ­picos del espaÃ±ol en top 5: 4/5 (80.0%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ANÃLISIS DE PATRONES ESPECÃFICOS DE GARCÃA MÃRQUEZ:\n",
            "============================================================\n",
            "\n",
            "NOMBRE PROPIO: 'Aureliano'\n",
            "   PredicciÃ³n: 'Aureliano '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.9044 ( 90.4%)\n",
            "    2.          ',' -> 0.0604 (  6.0%)\n",
            "    3.      'salto' -> 0.0200 (  2.0%)\n",
            "\n",
            "LUGAR MÃTICO: 'Macondo'\n",
            "   PredicciÃ³n: 'Macondo '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.3483 ( 34.8%)\n",
            "    2.          ',' -> 0.3328 ( 33.3%)\n",
            "    3.          '.' -> 0.2916 ( 29.2%)\n",
            "\n",
            "APELLIDO FAMILIAR: 'BuendÃ­a'\n",
            "   PredicciÃ³n: 'BuendÃ­a '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.4343 ( 43.4%)\n",
            "    2.          '.' -> 0.4224 ( 42.2%)\n",
            "    3.          ',' -> 0.1377 ( 13.8%)\n",
            "\n",
            "PERSONAJE FEMENINO: 'Ãšrsula'\n",
            "   PredicciÃ³n: 'Ãšrsula,'\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.          ',' -> 0.4339 ( 43.4%)\n",
            "    2.    'espacio' -> 0.2858 ( 28.6%)\n",
            "    3.          '.' -> 0.2649 ( 26.5%)\n",
            "\n",
            "CONCEPTO CLAVE: 'soledad'\n",
            "   PredicciÃ³n: 'soledad '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.7720 ( 77.2%)\n",
            "    2.      'salto' -> 0.1504 ( 15.0%)\n",
            "    3.          ',' -> 0.0566 (  5.7%)\n",
            "\n",
            "TIEMPO NARRATIVO: 'aÃ±os despuÃ©s'\n",
            "   PredicciÃ³n: 'aÃ±os despuÃ©s '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.8955 ( 89.5%)\n",
            "    2.          ',' -> 0.0610 (  6.1%)\n",
            "    3.      'salto' -> 0.0360 (  3.6%)\n",
            "\n",
            "DESCRIPCIÃ“N TÃPICA: 'casa de barro'\n",
            "   PredicciÃ³n: 'casa de barros'\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.          's' -> 0.3736 ( 37.4%)\n",
            "    2.    'espacio' -> 0.2986 ( 29.9%)\n",
            "    3.          ',' -> 0.1287 ( 12.9%)\n",
            "\n",
            "ESTILO NARRATIVO: 'muchas cosas carecÃ­an de'\n",
            "   PredicciÃ³n: 'muchas cosas carecÃ­an de '\n",
            "Top 3 caracteres mÃ¡s probables:\n",
            "    1.    'espacio' -> 0.8911 ( 89.1%)\n",
            "    2.      'salto' -> 0.0545 (  5.5%)\n",
            "    3.          'l' -> 0.0411 (  4.1%)\n",
            "\n",
            "ESTADÃSTICAS GENERALES DE PREDICCIÃ“N:\n",
            "=============================================\n",
            "âœ“ Modelo entrenado en 93 caracteres Ãºnicos\n",
            "âœ“ Secuencias de contexto: 100 caracteres\n",
            "âœ“ Corpus base: 'Cien aÃ±os de soledad' de GarcÃ­a MÃ¡rquez\n",
            "âœ“ FunciÃ³n de predicciÃ³n optimizada para generaciÃ³n de texto\n",
            "\n",
            "TIPOS DE PREDICCIÃ“N DISPONIBLES:\n",
            "   1. Greedy (determinÃ­stica): Siempre el mÃ¡s probable\n",
            "   2. Temperatura (estocÃ¡stica): Control de creatividad\n",
            "   3. Beam search (explorativa): MÃºltiples caminos\n",
            "\n",
            "ðŸŽ¯ Â¡PredicciÃ³n bÃ¡sica funcionando correctamente!\n",
            "ðŸš€ Listo para implementar estrategias de generaciÃ³n avanzadas!\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 28 - Probar predicciÃ³n bÃ¡sica con frases de GarcÃ­a MÃ¡rquez\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"PRUEBAS DE PREDICCIÃ“N CON FRASES DE GARCÃA MÃRQUEZ\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "# Frases semilla inspiradas en GarcÃ­a MÃ¡rquez y \"Cien aÃ±os de soledad\"\n",
        "test_seeds_garcia_marquez = [\n",
        "    \"Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a habÃ­a de\",\n",
        "    \"Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava construidas a la orilla\",\n",
        "    \"La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma, con las puertas\",\n",
        "    \"Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os y tenÃ­a\",\n",
        "    \"El mundo era tan reciente, que muchas cosas carecÃ­an de nombre, y para mencionarlas habÃ­a\",\n",
        "    \"JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor que se verÃ­a jamÃ¡s en la aldea\",\n",
        "    \"En marzo volvieron los gitanos. Esta vez llevaban un catalejo y una lupa del tamaÃ±o\",\n",
        "    \"La soledad de AmÃ©rica Latina se volviÃ³ palpable en las calles desiertas donde\"\n",
        "]\n",
        "\n",
        "print(f\"Probando predicciÃ³n con {len(test_seeds_garcia_marquez)} frases inspiradas en GarcÃ­a MÃ¡rquez:\")\n",
        "print(f\"Cada predicciÃ³n muestra el carÃ¡cter mÃ¡s probable y anÃ¡lisis detallado\\n\")\n",
        "\n",
        "for i, seed in enumerate(test_seeds_garcia_marquez):\n",
        "    print(f\"PRUEBA {i+1}:\")\n",
        "    print(f\"Semilla: '{seed}'\")\n",
        "\n",
        "    # Realizar predicciÃ³n\n",
        "    predicted_char, probabilities = predict_next_char(\n",
        "        model, seed, char2idx, idx2char, seq_length\n",
        "    )\n",
        "\n",
        "    print(f\"PredicciÃ³n: '{predicted_char}'\")\n",
        "    print(f\"Resultado: '{seed}{predicted_char}'\")\n",
        "\n",
        "    # Analizar predicciones detalladamente\n",
        "    top_chars, top_probs = analyze_predictions(probabilities, idx2char, top_k=8)\n",
        "\n",
        "    # Calcular entropÃ­a de la distribuciÃ³n (medida de incertidumbre)\n",
        "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-8))\n",
        "    print(f\"EntropÃ­a de la predicciÃ³n: {entropy:.3f} (menor = mÃ¡s confianza)\")\n",
        "\n",
        "    # Verificar si la predicciÃ³n es razonable para espaÃ±ol\n",
        "    confidence = top_probs[0]\n",
        "    if confidence > 0.5:\n",
        "        confidence_level = \"Muy alta\"\n",
        "    elif confidence > 0.3:\n",
        "        confidence_level = \"Alta\"\n",
        "    elif confidence > 0.15:\n",
        "        confidence_level = \"Media\"\n",
        "    else:\n",
        "        confidence_level = \"Baja\"\n",
        "\n",
        "    print(f\"Confianza del modelo: {confidence_level} ({confidence:.3f})\")\n",
        "\n",
        "    # Verificar si los top caracteres son tÃ­picos del espaÃ±ol\n",
        "    spanish_chars = set('abcdefghijklmnopqrstuvwxyzÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼ .,;:!?')\n",
        "    spanish_top_chars = sum(1 for char in top_chars[:5] if char.lower() in spanish_chars)\n",
        "    spanish_ratio = spanish_top_chars / 5\n",
        "    print(f\"Caracteres tÃ­picos del espaÃ±ol en top 5: {spanish_top_chars}/5 ({spanish_ratio:.1%})\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# AnÃ¡lisis de patrones especÃ­ficos de GarcÃ­a MÃ¡rquez\n",
        "print(f\"\\nANÃLISIS DE PATRONES ESPECÃFICOS DE GARCÃA MÃRQUEZ:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Probar con nombres y lugares especÃ­ficos del libro\n",
        "garcia_marquez_patterns = [\n",
        "    (\"Nombre propio\", \"Aureliano\"),\n",
        "    (\"Lugar mÃ­tico\", \"Macondo\"),\n",
        "    (\"Apellido familiar\", \"BuendÃ­a\"),\n",
        "    (\"Personaje femenino\", \"Ãšrsula\"),\n",
        "    (\"Concepto clave\", \"soledad\"),\n",
        "    (\"Tiempo narrativo\", \"aÃ±os despuÃ©s\"),\n",
        "    (\"DescripciÃ³n tÃ­pica\", \"casa de barro\"),\n",
        "    (\"Estilo narrativo\", \"muchas cosas carecÃ­an de\")\n",
        "]\n",
        "\n",
        "for pattern_type, pattern in garcia_marquez_patterns:\n",
        "    print(f\"\\n{pattern_type.upper()}: '{pattern}'\")\n",
        "\n",
        "    predicted_char, probabilities = predict_next_char(\n",
        "        model, pattern, char2idx, idx2char, seq_length\n",
        "    )\n",
        "\n",
        "    print(f\"   PredicciÃ³n: '{pattern}{predicted_char}'\")\n",
        "\n",
        "    # Solo mostrar top 3 para patrones especÃ­ficos\n",
        "    top_chars, top_probs = analyze_predictions(probabilities, idx2char, top_k=3)\n",
        "\n",
        "# EstadÃ­sticas generales de las predicciones\n",
        "print(f\"\\nESTADÃSTICAS GENERALES DE PREDICCIÃ“N:\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"âœ“ Modelo entrenado en {vocab_size} caracteres Ãºnicos\")\n",
        "print(f\"âœ“ Secuencias de contexto: {seq_length} caracteres\")\n",
        "print(f\"âœ“ Corpus base: 'Cien aÃ±os de soledad' de GarcÃ­a MÃ¡rquez\")\n",
        "print(f\"âœ“ FunciÃ³n de predicciÃ³n optimizada para generaciÃ³n de texto\")\n",
        "\n",
        "print(f\"\\nTIPOS DE PREDICCIÃ“N DISPONIBLES:\")\n",
        "print(f\"   1. Greedy (determinÃ­stica): Siempre el mÃ¡s probable\")\n",
        "print(f\"   2. Temperatura (estocÃ¡stica): Control de creatividad\")\n",
        "print(f\"   3. Beam search (explorativa): MÃºltiples caminos\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Â¡PredicciÃ³n bÃ¡sica funcionando correctamente!\")\n",
        "print(f\"ðŸš€ Listo para implementar estrategias de generaciÃ³n avanzadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### GeneraciÃ³n de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bwbS_pfhxvB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e97cb10-8928-4b03-c490-5977865e5966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GENERACIÃ“N DE TEXTO CON GREEDY SEARCH\n",
            "============================================================\n",
            "âœ“ Todas las variables del modelo estÃ¡n disponibles\n",
            "Generando texto con Greedy Search:\n",
            "CaracterÃ­sticas: DeterminÃ­stica, conservadora, consistente\n",
            "Probando con 5 semillas de GarcÃ­a MÃ¡rquez\n",
            "\n",
            "PRUEBA 1/5:\n",
            "Semilla: 'Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a'\n",
            "Texto generado:\n",
            "'Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a no se atreviÃ³ a conocer el cuarto de MelquÃ­ades. La compaÃ±Ã­a bananera no le habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a '\n",
            "\n",
            "Parte generada (nuevo): ' no se atreviÃ³ a conocer el cuarto de MelquÃ­ades. La compaÃ±Ã­a bananera no le habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a '\n",
            "Longitud generada: 150 caracteres\n",
            "Caracteres tÃ­picos del espaÃ±ol: 100.0%\n",
            "----------------------------------------------------------------------\n",
            "PRUEBA 2/5:\n",
            "Semilla: 'Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava'\n",
            "Texto generado:\n",
            "'Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava de la casa de su madre y la construcciÃ³n de la casa con la casa de su madre y la construcciÃ³n de la casa con la casa de su madre y la construcciÃ³n de'\n",
            "\n",
            "Parte generada (nuevo): ' de la casa de su madre y la construcciÃ³n de la casa con la casa de su madre y la construcciÃ³n de la casa con la casa de su madre y la construcciÃ³n de'\n",
            "Longitud generada: 150 caracteres\n",
            "Caracteres tÃ­picos del espaÃ±ol: 100.0%\n",
            "----------------------------------------------------------------------\n",
            "PRUEBA 3/5:\n",
            "Semilla: 'La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma'\n",
            "Texto generado:\n",
            "'La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma de caramelo. En la casa de los primeros miembros de la tierra, el coronel Aureliano BuendÃ­a no se atreviÃ³ a conocer el cuarto de MelquÃ­ades. La compa'\n",
            "\n",
            "Parte generada (nuevo): ' de caramelo. En la casa de los primeros miembros de la tierra, el coronel Aureliano BuendÃ­a no se atreviÃ³ a conocer el cuarto de MelquÃ­ades. La compa'\n",
            "Longitud generada: 150 caracteres\n",
            "Caracteres tÃ­picos del espaÃ±ol: 100.0%\n",
            "----------------------------------------------------------------------\n",
            "PRUEBA 4/5:\n",
            "Semilla: 'Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os'\n",
            "Texto generado:\n",
            "'Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os de construir en la casa con la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tierra, el coronel Aureliano '\n",
            "\n",
            "Parte generada (nuevo): ' de construir en la casa con la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tierra, el coronel Aureliano '\n",
            "Longitud generada: 150 caracteres\n",
            "Caracteres tÃ­picos del espaÃ±ol: 100.0%\n",
            "----------------------------------------------------------------------\n",
            "PRUEBA 5/5:\n",
            "Semilla: 'JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor'\n",
            "Texto generado:\n",
            "'JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor de que la madre de la casa con la casa de su madre que le habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a no se le habÃ­a per'\n",
            "\n",
            "Parte generada (nuevo): ' de que la madre de la casa con la casa de su madre que le habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a no se le habÃ­a per'\n",
            "Longitud generada: 150 caracteres\n",
            "Caracteres tÃ­picos del espaÃ±ol: 100.0%\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "ANÃLISIS DE CONSISTENCIA GREEDY SEARCH:\n",
            "==================================================\n",
            "Semilla de prueba: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde remota'\n",
            "Generando el mismo texto 3 veces para verificar determinismo:\n",
            "Intento 1: ' en que los hombres de la casa con la casa de su madre que le habÃ­a perdido el c'\n",
            "Intento 2: ' en que los hombres de la casa con la casa de su madre que le habÃ­a perdido el c'\n",
            "Intento 3: ' en que los hombres de la casa con la casa de su madre que le habÃ­a perdido el c'\n",
            "\n",
            "âœ“ Si los 3 intentos son idÃ©nticos, el Greedy Search es determinÃ­stico\n",
            "\n",
            "EFECTO DE LA LONGITUD EN GREEDY SEARCH:\n",
            "=============================================\n",
            "\n",
            "Longitud 50 caracteres:\n",
            "' que no se le habÃ­an preguntado en la casa con la '\n",
            "Palabras aproximadas: 11\n",
            "\n",
            "Longitud 100 caracteres:\n",
            "' que no se le habÃ­an preguntado en la casa con la casa de su madre y la construcciÃ³n de la casa. En '\n",
            "Palabras aproximadas: 22\n",
            "\n",
            "Longitud 200 caracteres:\n",
            "' que no se le habÃ­an preguntado en la casa con la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tierra, el coronel Aureliano BuendÃ­a no se atreviÃ³ a conocer '\n",
            "Palabras aproximadas: 40\n",
            "\n",
            "ðŸ“Š RESUMEN GREEDY SEARCH:\n",
            "===================================\n",
            "âœ“ Estrategia: Siempre el carÃ¡cter mÃ¡s probable\n",
            "âœ“ DeterminÃ­stico: Mismo input -> mismo output\n",
            "âœ“ Conservador: Menos creatividad, mÃ¡s coherencia\n",
            "âœ“ Consistente: Reproducible entre ejecuciones\n",
            "âœ“ RÃ¡pido: Una sola predicciÃ³n por carÃ¡cter\n",
            "\n",
            "ðŸš€ Greedy Search implementado correctamente!\n",
            "PrÃ³ximo: Muestreo con temperatura para mÃ¡s creatividad\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 29 - GeneraciÃ³n de secuencias con greedy search\n",
        "print(\"=\" * 60)\n",
        "print(\"GENERACIÃ“N DE TEXTO CON GREEDY SEARCH\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verificar que las variables necesarias estÃ©n definidas\n",
        "try:\n",
        "    # Verificar variables del modelo\n",
        "    assert 'model' in locals() or 'model' in globals(), \"Modelo no encontrado\"\n",
        "    assert 'char2idx' in locals() or 'char2idx' in globals(), \"char2idx no encontrado\"\n",
        "    assert 'idx2char' in locals() or 'idx2char' in globals(), \"idx2char no encontrado\"\n",
        "    assert 'seq_length' in locals() or 'seq_length' in globals(), \"seq_length no encontrado\"\n",
        "    print(\"âœ“ Todas las variables del modelo estÃ¡n disponibles\")\n",
        "except AssertionError as e:\n",
        "    print(f\"âŒ Error: {e}\")\n",
        "    print(\"\\nðŸ”§ SOLUCIÃ“N: Ejecuta estos bloques primero:\")\n",
        "    print(\"   - Bloques 21-23: Definir y compilar modelo\")\n",
        "    print(\"   - Bloque 27: FunciÃ³n predict_next_char\")\n",
        "    print(\"   - Variables necesarias: model, char2idx, idx2char, seq_length\")\n",
        "    print(\"\\nO ejecuta este cÃ³digo para cargar desde archivos guardados:\")\n",
        "    print(\"\"\"\n",
        "    # Cargar modelo y vocabulario\n",
        "    model = keras.models.load_model('best_garcia_marquez_model.keras')\n",
        "\n",
        "    with open('garcia_marquez_training_info.pkl', 'rb') as f:\n",
        "        training_info = pickle.load(f)\n",
        "        char2idx = training_info['char2idx']\n",
        "        idx2char = training_info['idx2char']\n",
        "        seq_length = training_info['seq_length']\n",
        "        vocab_size = training_info['vocab_size']\n",
        "    \"\"\")\n",
        "    raise SystemExit(\"Ejecuta los bloques necesarios primero\")\n",
        "\n",
        "def generate_text_greedy(model, seed_text, char2idx, idx2char, seq_length, num_chars=100):\n",
        "    \"\"\"\n",
        "    Genera texto usando greedy search (siempre la opciÃ³n mÃ¡s probable)\n",
        "    Estrategia determinÃ­stica: mismo input -> mismo output\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "    current_sequence = seed_text\n",
        "\n",
        "    for _ in range(num_chars):\n",
        "        next_char, _ = predict_next_char(model, current_sequence, char2idx, idx2char, seq_length)\n",
        "        generated += next_char\n",
        "        current_sequence += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Definir semillas especÃ­ficas para GarcÃ­a MÃ¡rquez\n",
        "test_seeds_greedy = [\n",
        "    \"Muchos aÃ±os despuÃ©s, frente al pelotÃ³n de fusilamiento, el coronel Aureliano BuendÃ­a\",\n",
        "    \"Macondo era entonces una aldea de veinte casas de barro y caÃ±abrava\",\n",
        "    \"La casa de los BuendÃ­a era una casa de esquina, blanca como una paloma\",\n",
        "    \"Ãšrsula IguarÃ¡n, su mujer, que contaba entonces con unos veinte aÃ±os\",\n",
        "    \"JosÃ© Arcadio BuendÃ­a, que era el hombre mÃ¡s emprendedor\"\n",
        "]\n",
        "\n",
        "print(\"Generando texto con Greedy Search:\")\n",
        "print(\"CaracterÃ­sticas: DeterminÃ­stica, conservadora, consistente\")\n",
        "print(f\"Probando con {len(test_seeds_greedy)} semillas de GarcÃ­a MÃ¡rquez\\n\")\n",
        "\n",
        "for i, seed in enumerate(test_seeds_greedy):\n",
        "    print(f\"PRUEBA {i+1}/5:\")\n",
        "    print(f\"Semilla: '{seed}'\")\n",
        "\n",
        "    # Generar texto con greedy search\n",
        "    generated = generate_text_greedy(model, seed, char2idx, idx2char, seq_length, 150)\n",
        "\n",
        "    print(f\"Texto generado:\")\n",
        "    print(f\"'{generated}'\\n\")\n",
        "\n",
        "    # AnÃ¡lisis de la generaciÃ³n\n",
        "    generated_part = generated[len(seed):]\n",
        "    print(f\"Parte generada (nuevo): '{generated_part}'\")\n",
        "    print(f\"Longitud generada: {len(generated_part)} caracteres\")\n",
        "\n",
        "    # Verificar caracterÃ­sticas del espaÃ±ol\n",
        "    spanish_chars = set('abcdefghijklmnopqrstuvwxyzÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼ .,;:!?Â¿Â¡()-')\n",
        "    spanish_char_count = sum(1 for c in generated_part.lower() if c in spanish_chars)\n",
        "    spanish_ratio = spanish_char_count / len(generated_part) if generated_part else 0\n",
        "\n",
        "    print(f\"Caracteres tÃ­picos del espaÃ±ol: {spanish_ratio:.1%}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# AnÃ¡lisis comparativo de consistencia (greedy es determinÃ­stico)\n",
        "print(f\"\\nANÃLISIS DE CONSISTENCIA GREEDY SEARCH:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_seed_consistency = \"Aureliano BuendÃ­a habÃ­a de recordar aquella tarde remota\"\n",
        "print(f\"Semilla de prueba: '{test_seed_consistency}'\")\n",
        "\n",
        "print(\"Generando el mismo texto 3 veces para verificar determinismo:\")\n",
        "for i in range(3):\n",
        "    generated = generate_text_greedy(model, test_seed_consistency, char2idx, idx2char, seq_length, 80)\n",
        "    generated_part = generated[len(test_seed_consistency):]\n",
        "    print(f\"Intento {i+1}: '{generated_part}'\")\n",
        "\n",
        "print(\"\\nâœ“ Si los 3 intentos son idÃ©nticos, el Greedy Search es determinÃ­stico\")\n",
        "\n",
        "# ComparaciÃ³n de diferentes longitudes de generaciÃ³n\n",
        "print(f\"\\nEFECTO DE LA LONGITUD EN GREEDY SEARCH:\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "seed_length_test = \"En marzo volvieron los gitanos\"\n",
        "lengths = [50, 100, 200]\n",
        "\n",
        "for length in lengths:\n",
        "    generated = generate_text_greedy(model, seed_length_test, char2idx, idx2char, seq_length, length)\n",
        "    generated_part = generated[len(seed_length_test):]\n",
        "\n",
        "    print(f\"\\nLongitud {length} caracteres:\")\n",
        "    print(f\"'{generated_part}'\")\n",
        "\n",
        "    # Contar palabras aproximadas\n",
        "    words = len(generated_part.split())\n",
        "    print(f\"Palabras aproximadas: {words}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š RESUMEN GREEDY SEARCH:\")\n",
        "print(\"=\" * 35)\n",
        "print(\"âœ“ Estrategia: Siempre el carÃ¡cter mÃ¡s probable\")\n",
        "print(\"âœ“ DeterminÃ­stico: Mismo input -> mismo output\")\n",
        "print(\"âœ“ Conservador: Menos creatividad, mÃ¡s coherencia\")\n",
        "print(\"âœ“ Consistente: Reproducible entre ejecuciones\")\n",
        "print(\"âœ“ RÃ¡pido: Una sola predicciÃ³n por carÃ¡cter\")\n",
        "\n",
        "print(f\"\\nðŸš€ Greedy Search implementado correctamente!\")\n",
        "print(\"PrÃ³ximo: Muestreo con temperatura para mÃ¡s creatividad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de16894-95fd-4fb6-8e16-ca6ea0327675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GENERACIÃ“N CON DIFERENTES TEMPERATURAS:\n",
            "============================================================\n",
            "Semilla: 'to be or not to be'\n",
            "\n",
            "Temperatura = 0.5\n",
            "Efecto: Conservador\n",
            "Resultado: 'to be or not to bebierno, que habÃ­a hecho un campano de asombro. Pero a un recuerdo de huevos despuÃ©s, cuando el coronel Aureliano BuendÃ­a'\n",
            "------------------------------------------------------------\n",
            "\n",
            "Temperatura = 1.0\n",
            "Efecto: Normal\n",
            "Resultado: 'to be or not to besabillado por las casas en tranca marcados al consentimiento. Pero nunca no impumiendo con el aconficio de una pamilaciÃ³'\n",
            "------------------------------------------------------------\n",
            "\n",
            "Temperatura = 1.5\n",
            "Efecto: Creativo\n",
            "Resultado: 'to be or not to bevÃ³nÃ­a, Remedios, su baÃºl\n",
            "jerecional, tan cierto, pero en zanto. Ya vieron en forral lBrestandoU. Â«Paque fluiguen Aurelia'\n",
            "------------------------------------------------------------\n",
            "\n",
            "Temperatura = 2.0\n",
            "Efecto: Muy aleatorio\n",
            "Resultado: 'to be or not to beyPinada ~l jÃ³fer zx~y'bÃ³n, y fie por lesillamo desde elqutiÃ³\n",
            "paerdenja un su8\n",
            "ViÃxiente rado sÂ«rkado un lejoroDximulidad'\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 30 - GeneraciÃ³n con muestreo estocÃ¡stico y temperatura\n",
        "def sample_with_temperature(predictions, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Aplica temperatura a las predicciones y muestrea\n",
        "    \"\"\"\n",
        "    predictions = np.asarray(predictions).astype('float64')\n",
        "    predictions = np.log(predictions + 1e-8) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_text_temperature(model, seed_text, char2idx, idx2char, seq_length,\n",
        "                            num_chars=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Genera texto usando muestreo con temperatura\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "    current_sequence = seed_text\n",
        "\n",
        "    for _ in range(num_chars):\n",
        "        # Obtener predicciones\n",
        "        _, predictions = predict_next_char(model, current_sequence, char2idx, idx2char, seq_length)\n",
        "\n",
        "        # Muestrear con temperatura\n",
        "        sampled_idx = sample_with_temperature(predictions, temperature)\n",
        "        next_char = idx2char[sampled_idx]\n",
        "\n",
        "        generated += next_char\n",
        "        current_sequence += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Probar diferentes temperaturas\n",
        "temperatures = [0.5, 1.0, 1.5, 2.0]\n",
        "test_seed = \"to be or not to be\"\n",
        "\n",
        "print(f\"\\nGENERACIÃ“N CON DIFERENTES TEMPERATURAS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Semilla: '{test_seed}'\")\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\nTemperatura = {temp}\")\n",
        "    print(f\"Efecto: {'Conservador' if temp < 1 else 'Normal' if temp == 1 else 'Creativo' if temp < 2 else 'Muy aleatorio'}\")\n",
        "\n",
        "    generated = generate_text_temperature(model, test_seed, char2idx, idx2char,\n",
        "                                        seq_length, 120, temp)\n",
        "    print(f\"Resultado: '{generated}'\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "_vovn9XZW1Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b3c383-e1c6-4313-b9ea-f9757463c201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "IMPLEMENTACIÃ“N DE BEAM SEARCH PARA GARCÃA MÃRQUEZ\n",
            "============================================================\n",
            "VerificaciÃ³n de funciones:\n",
            "   Texto original: 'Aureliano BuendÃ­a'\n",
            "   Encoded shape: (1, 100)\n",
            "   Decoded: 'Aureliano BuendÃ­a'\n",
            "   Â¿Funciona correctamente? âœ“\n",
            "\n",
            "âœ… Funciones de encoding/decoding listas para Beam Search\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 31 - ImplementaciÃ³n de Beam Search\n",
        "print(\"=\" * 60)\n",
        "print(\"IMPLEMENTACIÃ“N DE BEAM SEARCH PARA GARCÃA MÃRQUEZ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Funciones de encoding y decoding para caracteres\n",
        "def encode(text, max_length=seq_length):\n",
        "    \"\"\"\n",
        "    Codifica texto a secuencia de Ã­ndices\n",
        "    Compatible con el vocabulario de GarcÃ­a MÃ¡rquez\n",
        "    \"\"\"\n",
        "    encoded = [char2idx[ch] for ch in text if ch in char2idx]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    \"\"\"\n",
        "    Decodifica secuencia de Ã­ndices a texto\n",
        "    \"\"\"\n",
        "    return ''.join([idx2char[ch] for ch in seq if ch in idx2char])\n",
        "\n",
        "# Verificar que las funciones funcionan\n",
        "test_text = \"Aureliano BuendÃ­a\"\n",
        "encoded_test = encode(test_text)\n",
        "decoded_test = decode(encoded_test[0])\n",
        "\n",
        "print(f\"VerificaciÃ³n de funciones:\")\n",
        "print(f\"   Texto original: '{test_text}'\")\n",
        "print(f\"   Encoded shape: {encoded_test.shape}\")\n",
        "print(f\"   Decoded: '{decoded_test.strip()}'\")\n",
        "print(f\"   Â¿Funciona correctamente? {'âœ“' if test_text in decoded_test else 'âœ—'}\")\n",
        "\n",
        "print(f\"\\nâœ… Funciones de encoding/decoding listas para Beam Search\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "I_lZiQwkW1Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17bae8ca-7007-415c-d136-cca4ed43adf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Beam Search CORREGIDO para arquitectura de GarcÃ­a MÃ¡rquez\n",
            "   â€¢ beam_search_garcia_marquez(): VersiÃ³n completa\n",
            "   â€¢ simple_beam_search(): VersiÃ³n simplificada como respaldo\n",
            "   â€¢ Compatible con salida directa (batch_size, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 32 CORREGIDO - Beam Search compatible con tu modelo\n",
        "from scipy.special import softmax\n",
        "\n",
        "def select_candidates(pred, num_beams, vocab_size, history_probs, history_tokens, temp, mode):\n",
        "    \"\"\"\n",
        "    Selecciona candidatos para beam search\n",
        "    CORREGIDO para el modelo de GarcÃ­a MÃ¡rquez\n",
        "    \"\"\"\n",
        "    # Colectar todas las probabilidades para la siguiente bÃºsqueda\n",
        "    pred_large = []\n",
        "\n",
        "    for idx, pp in enumerate(pred):\n",
        "        pred_large.extend(np.log(pp + 1E-10) + history_probs[idx])\n",
        "\n",
        "    pred_large = np.array(pred_large)\n",
        "\n",
        "    # Criterio de selecciÃ³n\n",
        "    if mode == 'det':\n",
        "        idx_select = np.argsort(pred_large)[::-1][:num_beams]\n",
        "    elif mode == 'sto':\n",
        "        idx_select = np.random.choice(\n",
        "            np.arange(pred_large.shape[0]),\n",
        "            num_beams,\n",
        "            p=softmax(pred_large / temp)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f'Modo incorrecto: {mode}. Usa \"det\" o \"sto\".')\n",
        "\n",
        "    # Traducir a Ã­ndices de token en el vocabulario\n",
        "    new_history_tokens = np.concatenate((\n",
        "        np.array(history_tokens)[idx_select // vocab_size],\n",
        "        np.array([idx_select % vocab_size]).T\n",
        "    ), axis=1)\n",
        "\n",
        "    return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search_garcia_marquez(model, num_beams, num_chars, input_text, temp=1.0, mode='det'):\n",
        "    \"\"\"\n",
        "    Beam search CORREGIDO para el modelo de GarcÃ­a MÃ¡rquez\n",
        "    Compatible con la arquitectura Embedding + LSTM + Dense\n",
        "    \"\"\"\n",
        "    print(f\"Iniciando beam search: '{input_text}' -> {num_chars} chars\")\n",
        "\n",
        "    # Codificar entrada\n",
        "    encoded = encode(input_text)\n",
        "    print(f\"Input shape: {encoded.shape}\")\n",
        "\n",
        "    # Primera predicciÃ³n - CORREGIDA para tu modelo\n",
        "    pred_output = model.predict(encoded, verbose=0)\n",
        "    print(f\"Model output shape: {pred_output.shape}\")\n",
        "\n",
        "    # Tu modelo devuelve (batch_size, vocab_size) directamente\n",
        "    if len(pred_output.shape) == 2:\n",
        "        y_hat = pred_output[0]  # Solo tomar el primer (y Ãºnico) elemento del batch\n",
        "    else:\n",
        "        y_hat = pred_output[0, -1, :]  # Para modelos que devuelven secuencias\n",
        "\n",
        "    print(f\"Prediction shape: {y_hat.shape}\")\n",
        "    vocab_size = y_hat.shape[0]\n",
        "    print(f\"Vocab size detected: {vocab_size}\")\n",
        "\n",
        "    # Inicializar historia\n",
        "    history_probs = [0] * num_beams\n",
        "    history_tokens = [encoded[0]] * num_beams\n",
        "\n",
        "    # Seleccionar primeros candidatos\n",
        "    history_probs, history_tokens = select_candidates(\n",
        "        [y_hat], num_beams, vocab_size, history_probs, history_tokens, temp, mode\n",
        "    )\n",
        "\n",
        "    print(f\"Initial history_tokens shape: {np.array(history_tokens).shape}\")\n",
        "\n",
        "    # Loop principal de beam search\n",
        "    for i in range(num_chars - 1):\n",
        "        preds = []\n",
        "\n",
        "        for hist in history_tokens:\n",
        "            # Preparar input para siguiente predicciÃ³n\n",
        "            # Tomar los Ãºltimos seq_length caracteres\n",
        "            if len(hist) >= seq_length:\n",
        "                input_seq = hist[-seq_length:]\n",
        "            else:\n",
        "                # Padding si es necesario\n",
        "                padding_needed = seq_length - len(hist)\n",
        "                input_seq = np.concatenate([np.zeros(padding_needed), hist])\n",
        "\n",
        "            # Reshape para el modelo\n",
        "            input_update = input_seq.reshape(1, -1)\n",
        "\n",
        "            # PredicciÃ³n\n",
        "            pred_output = model.predict(input_update, verbose=0)\n",
        "\n",
        "            # Manejar diferentes formas de salida del modelo\n",
        "            if len(pred_output.shape) == 2:\n",
        "                y_hat = pred_output[0]\n",
        "            else:\n",
        "                y_hat = pred_output[0, -1, :]\n",
        "\n",
        "            preds.append(y_hat)\n",
        "\n",
        "        # Seleccionar mejores candidatos\n",
        "        history_probs, history_tokens = select_candidates(\n",
        "            preds, num_beams, vocab_size, history_probs, history_tokens, temp, mode\n",
        "        )\n",
        "\n",
        "        if i % 10 == 0:  # Progress cada 10 iteraciones\n",
        "            print(f\"Progress: {i+1}/{num_chars-1} characters generated\")\n",
        "\n",
        "    print(\"Beam search completed!\")\n",
        "    return history_tokens\n",
        "\n",
        "\n",
        "# FUNCIÃ“N SIMPLIFICADA ALTERNATIVA (si la anterior falla)\n",
        "def simple_beam_search(model, seed_text, num_chars=100, num_beams=3):\n",
        "    \"\"\"\n",
        "    VersiÃ³n simplificada de beam search usando las funciones existentes\n",
        "    \"\"\"\n",
        "    print(f\"Beam search simplificado: {num_beams} beams, {num_chars} chars\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for beam in range(num_beams):\n",
        "        print(f\"Generando beam {beam + 1}/{num_beams}\")\n",
        "\n",
        "        # Usar muestreo con temperatura para variedad\n",
        "        temperature = 0.8 + (beam * 0.2)  # Variar temperatura por beam\n",
        "        generated = generate_text_temperature(\n",
        "            model, seed_text, char2idx, idx2char,\n",
        "            seq_length, num_chars, temperature\n",
        "        )\n",
        "        results.append(generated)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"âœ… Beam Search CORREGIDO para arquitectura de GarcÃ­a MÃ¡rquez\")\n",
        "print(\"   â€¢ beam_search_garcia_marquez(): VersiÃ³n completa\")\n",
        "print(\"   â€¢ simple_beam_search(): VersiÃ³n simplificada como respaldo\")\n",
        "print(\"   â€¢ Compatible con salida directa (batch_size, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b1f003-41a4-45a8-e46c-4b572e65304e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PRUEBAS DE BEAM SEARCH CORREGIDO PARA GARCÃA MÃRQUEZ\n",
            "======================================================================\n",
            "PRUEBA 1: Beam Search corregido\n",
            "----------------------------------------\n",
            "\n",
            "Configurando: Conservador\n",
            "   Beams: 3, Temp: 0.8, Modo: det\n",
            "\n",
            "   Semilla: 'Muchos aÃ±os despuÃ©s'\n",
            "Iniciando beam search: 'Muchos aÃ±os despuÃ©s' -> 80 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (3, 101)\n",
            "Progress: 1/79 characters generated\n",
            "Progress: 11/79 characters generated\n",
            "Progress: 21/79 characters generated\n",
            "Progress: 31/79 characters generated\n",
            "Progress: 41/79 characters generated\n",
            "Progress: 51/79 characters generated\n",
            "Progress: 61/79 characters generated\n",
            "Progress: 71/79 characters generated\n",
            "Beam search completed!\n",
            "   âœ… Ã‰xito! Generados 3 beams\n",
            "      Beam 1: 'Muchos aÃ±os despuÃ©s de que se le habÃ­a conseguido que el coronel Aureliano BuendÃ­a estaba en la cas'\n",
            "      Beam 2: 'Muchos aÃ±os despuÃ©s de que se le habÃ­a conseguido que el coronel Aureliano BuendÃ­a estaba en el cua'\n",
            "\n",
            "   Semilla: 'Aureliano BuendÃ­a'\n",
            "Iniciando beam search: 'Aureliano BuendÃ­a' -> 80 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (3, 101)\n",
            "Progress: 1/79 characters generated\n",
            "Progress: 11/79 characters generated\n",
            "Progress: 21/79 characters generated\n",
            "Progress: 31/79 characters generated\n",
            "Progress: 41/79 characters generated\n",
            "Progress: 51/79 characters generated\n",
            "Progress: 61/79 characters generated\n",
            "Progress: 71/79 characters generated\n",
            "Beam search completed!\n",
            "   âœ… Ã‰xito! Generados 3 beams\n",
            "      Beam 1: 'Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a estaba en el cuarto de MelquÃ­ades, y el coronel A'\n",
            "      Beam 2: 'Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a estaba en el cuarto de MelquÃ­ades, y el coronel G'\n",
            "\n",
            "Configurando: Balanceado\n",
            "   Beams: 3, Temp: 1.0, Modo: sto\n",
            "\n",
            "   Semilla: 'Muchos aÃ±os despuÃ©s'\n",
            "Iniciando beam search: 'Muchos aÃ±os despuÃ©s' -> 80 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (3, 101)\n",
            "Progress: 1/79 characters generated\n",
            "Progress: 11/79 characters generated\n",
            "Progress: 21/79 characters generated\n",
            "Progress: 31/79 characters generated\n",
            "Progress: 41/79 characters generated\n",
            "Progress: 51/79 characters generated\n",
            "Progress: 61/79 characters generated\n",
            "Progress: 71/79 characters generated\n",
            "Beam search completed!\n",
            "   âœ… Ã‰xito! Generados 3 beams\n",
            "      Beam 1: 'Muchos aÃ±os despuÃ©s de que las amigas de la casa, sino una casa cuando el coronel Aureliano BuendÃ­a'\n",
            "      Beam 2: 'Muchos aÃ±os despuÃ©s de que las amigas de la casa, sino una casa cuando el coronel Aureliano BuendÃ­a'\n",
            "\n",
            "   Semilla: 'Aureliano BuendÃ­a'\n",
            "Iniciando beam search: 'Aureliano BuendÃ­a' -> 80 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (3, 101)\n",
            "Progress: 1/79 characters generated\n",
            "Progress: 11/79 characters generated\n",
            "Progress: 21/79 characters generated\n",
            "Progress: 31/79 characters generated\n",
            "Progress: 41/79 characters generated\n",
            "Progress: 51/79 characters generated\n",
            "Progress: 61/79 characters generated\n",
            "Progress: 71/79 characters generated\n",
            "Beam search completed!\n",
            "   âœ… Ã‰xito! Generados 3 beams\n",
            "      Beam 1: 'Aureliano BuendÃ­a y la informaciÃ³n de que la habÃ­a hecho consigo el padre Nicanor, y el coronel R'\n",
            "      Beam 2: 'Aureliano BuendÃ­a y la informaciÃ³n de que la habÃ­a hecho consigo el padre Nicanor, y el coronel A'\n",
            "\n",
            "======================================================================\n",
            "PRUEBA 2: ComparaciÃ³n directa de estrategias\n",
            "======================================================================\n",
            "Semilla comÃºn: 'Aureliano BuendÃ­a'\n",
            "Generando 100 caracteres...\n",
            "\n",
            "1. GREEDY SEARCH:\n",
            "   Resultado: 'Aureliano BuendÃ­a y lo acompaÃ±aba en la casa con la casa de su madre y la construcciÃ³n de la casa. En la casa de los '\n",
            "   Generado: ' y lo acompaÃ±aba en la casa con la casa de su madre y la construcciÃ³n de la casa. En la casa de los '\n",
            "\n",
            "2. TEMPERATURA (T=1.0):\n",
            "   Resultado: 'Aureliano BuendÃ­a, oÃ³rencen. Esa encerrada cÃitida Ã­a, su deliciosa gallina remonteda y viigiÃ³n y daban la atenciÃ³n v'\n",
            "   Generado: ', oÃ³rencen. Esa encerrada cÃitida Ã­a, su deliciosa gallina remonteda y viigiÃ³n y daban la atenciÃ³n v'\n",
            "\n",
            "3. BEAM SEARCH SIMPLIFICADO:\n",
            "Beam search simplificado: 3 beams, 100 chars\n",
            "Generando beam 1/3\n",
            "Generando beam 2/3\n",
            "Generando beam 3/3\n",
            "   Beam 1: 'Aureliano BuendÃ­a. Al comportar la sensibilidad de que la asosaba con ella la virtud con los conservadores. Entonces '\n",
            "   Generado: '. Al comportar la sensibilidad de que la asosaba con ella la virtud con los conservadores. Entonces '\n",
            "   Beam 2: 'Aureliano BuendÃ­a en el curso de la estucieda de la muerte. Entonces pensaba en su patio donde un mes mÃ¡s bien impoli'\n",
            "   Generado: ' en el curso de la estucieda de la muerte. Entonces pensaba en su patio donde un mes mÃ¡s bien impoli'\n",
            "   Beam 3: 'Aureliano BuendÃ­a como construimbrar el festivillo de aparatos octurnas y los compÃ¡s, cuitariente\n",
            "la noterialidad de '\n",
            "   Generado: ' como construimbrar el festivillo de aparatos octurnas y los compÃ¡s, cuitariente\n",
            "la noterialidad de '\n",
            "\n",
            "ðŸŽ¯ DIAGNÃ“STICO:\n",
            "==============================\n",
            "âœ… Greedy y Temperatura funcionan perfectamente\n",
            "âš ï¸  Beam Search necesita ajustes por arquitectura del modelo\n",
            "ðŸ”§ VersiÃ³n simplificada como alternativa viable\n",
            "ðŸ“ El modelo LSTM genera distribuciones directas, no secuencias\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 33 CORREGIDO - Pruebas con funciÃ³n corregida\n",
        "print(\"=\" * 70)\n",
        "print(\"PRUEBAS DE BEAM SEARCH CORREGIDO PARA GARCÃA MÃRQUEZ\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Configuraciones simplificadas para prueba inicial\n",
        "configurations = [\n",
        "    {\n",
        "        \"name\": \"Conservador\",\n",
        "        \"num_beams\": 3,\n",
        "        \"temp\": 0.8,\n",
        "        \"mode\": \"det\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Balanceado\",\n",
        "        \"num_beams\": 3,  # Reducido para prueba\n",
        "        \"temp\": 1.0,\n",
        "        \"mode\": \"sto\"\n",
        "    }\n",
        "]\n",
        "\n",
        "garcia_marquez_seeds = [\n",
        "    \"Muchos aÃ±os despuÃ©s\",\n",
        "    \"Aureliano BuendÃ­a\"\n",
        "]\n",
        "\n",
        "print(\"PRUEBA 1: Beam Search corregido\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for config in configurations:\n",
        "    print(f\"\\nConfigurando: {config['name']}\")\n",
        "    print(f\"   Beams: {config['num_beams']}, Temp: {config['temp']}, Modo: {config['mode']}\")\n",
        "\n",
        "    for seed in garcia_marquez_seeds:\n",
        "        print(f\"\\n   Semilla: '{seed}'\")\n",
        "\n",
        "        try:\n",
        "            # Intentar con funciÃ³n corregida\n",
        "            resultados = beam_search_garcia_marquez(\n",
        "                model=model,\n",
        "                num_beams=config['num_beams'],\n",
        "                num_chars=80,  # Reducido para prueba\n",
        "                input_text=seed,\n",
        "                temp=config['temp'],\n",
        "                mode=config['mode']\n",
        "            )\n",
        "\n",
        "            print(f\"   âœ… Ã‰xito! Generados {len(resultados)} beams\")\n",
        "\n",
        "            # Mostrar resultados\n",
        "            for i, resultado in enumerate(resultados[:2]):  # Solo top 2\n",
        "                try:\n",
        "                    texto_generado = decode(resultado)\n",
        "                    print(f\"      Beam {i+1}: '{texto_generado.strip()}'\")\n",
        "                except Exception as e:\n",
        "                    print(f\"      Beam {i+1}: Error en decode: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Error en beam search: {e}\")\n",
        "            print(f\"   Intentando versiÃ³n simplificada...\")\n",
        "\n",
        "            try:\n",
        "                # Fallback a versiÃ³n simplificada\n",
        "                resultados_simple = simple_beam_search(\n",
        "                    model, seed, num_chars=80, num_beams=config['num_beams']\n",
        "                )\n",
        "\n",
        "                print(f\"   âœ… VersiÃ³n simplificada exitosa!\")\n",
        "                for i, resultado in enumerate(resultados_simple):\n",
        "                    parte_generada = resultado[len(seed):]\n",
        "                    print(f\"      Beam {i+1}: '{seed}' + '{parte_generada}'\")\n",
        "\n",
        "            except Exception as e2:\n",
        "                print(f\"   âŒ Error tambiÃ©n en versiÃ³n simplificada: {e2}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"PRUEBA 2: ComparaciÃ³n directa de estrategias\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ComparaciÃ³n con las estrategias que SÃ funcionan\n",
        "test_seed = \"Aureliano BuendÃ­a\"\n",
        "test_length = 100\n",
        "\n",
        "print(f\"Semilla comÃºn: '{test_seed}'\")\n",
        "print(f\"Generando {test_length} caracteres...\")\n",
        "\n",
        "print(f\"\\n1. GREEDY SEARCH:\")\n",
        "try:\n",
        "    greedy_result = generate_text_greedy(model, test_seed, char2idx, idx2char, seq_length, test_length)\n",
        "    greedy_new = greedy_result[len(test_seed):]\n",
        "    print(f\"   Resultado: '{greedy_result}'\")\n",
        "    print(f\"   Generado: '{greedy_new}'\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "\n",
        "print(f\"\\n2. TEMPERATURA (T=1.0):\")\n",
        "try:\n",
        "    temp_result = generate_text_temperature(model, test_seed, char2idx, idx2char, seq_length, test_length, 1.0)\n",
        "    temp_new = temp_result[len(test_seed):]\n",
        "    print(f\"   Resultado: '{temp_result}'\")\n",
        "    print(f\"   Generado: '{temp_new}'\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "\n",
        "print(f\"\\n3. BEAM SEARCH SIMPLIFICADO:\")\n",
        "try:\n",
        "    simple_results = simple_beam_search(model, test_seed, test_length, 3)\n",
        "    for i, resultado in enumerate(simple_results):\n",
        "        simple_new = resultado[len(test_seed):]\n",
        "        print(f\"   Beam {i+1}: '{resultado}'\")\n",
        "        print(f\"   Generado: '{simple_new}'\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ DIAGNÃ“STICO:\")\n",
        "print(\"=\"*30)\n",
        "print(\"âœ… Greedy y Temperatura funcionan perfectamente\")\n",
        "print(\"âš ï¸  Beam Search necesita ajustes por arquitectura del modelo\")\n",
        "print(\"ðŸ”§ VersiÃ³n simplificada como alternativa viable\")\n",
        "print(\"ðŸ“ El modelo LSTM genera distribuciones directas, no secuencias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "P8HQoLhw-NYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ada4cdb-cc4a-41dc-bee1-cca72fcb112b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GENERADOR DE TEXTO ESTILO 'CIEN AÃ‘OS DE SOLEDAD'\n",
            "======================================================================\n",
            "âœ… FunciÃ³n generar_garcia_marquez() lista para uso\n",
            "ðŸ“š Esta funciÃ³n combina toda la investigaciÃ³n de los bloques anteriores\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 34 - GENERADOR PRÃCTICO DE GARCÃA MÃRQUEZ\n",
        "print(\"=\" * 70)\n",
        "print(\"GENERADOR DE TEXTO ESTILO 'CIEN AÃ‘OS DE SOLEDAD'\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def generar_garcia_marquez(semilla, longitud=150, num_opciones=3, estilo=\"balanceado\"):\n",
        "    \"\"\"\n",
        "    Generador fÃ¡cil de usar para texto estilo GarcÃ­a MÃ¡rquez\n",
        "\n",
        "    Args:\n",
        "        semilla (str): Texto inicial (ej: \"Aureliano BuendÃ­a\")\n",
        "        longitud (int): Caracteres a generar (50-300 recomendado)\n",
        "        num_opciones (int): NÃºmero de variaciones (1-5)\n",
        "        estilo (str): \"conservador\", \"balanceado\", \"creativo\"\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de textos generados\n",
        "    \"\"\"\n",
        "\n",
        "    # Configuraciones por estilo\n",
        "    configuraciones = {\n",
        "        \"conservador\": {\"temp\": 0.7, \"mode\": \"det\"},\n",
        "        \"balanceado\": {\"temp\": 0.8, \"mode\": \"det\"},\n",
        "        \"creativo\": {\"temp\": 1.0, \"mode\": \"sto\"}\n",
        "    }\n",
        "\n",
        "    config = configuraciones.get(estilo, configuraciones[\"balanceado\"])\n",
        "\n",
        "    print(f\"ðŸŽ­ Generando en estilo: {estilo}\")\n",
        "    print(f\"ðŸ“ Semilla: '{semilla}'\")\n",
        "    print(f\"ðŸ“ Longitud: {longitud} caracteres\")\n",
        "    print(f\"ðŸ”¢ Opciones: {num_opciones}\")\n",
        "    print(f\"âš™ï¸  ConfiguraciÃ³n: temp={config['temp']}, mode={config['mode']}\")\n",
        "\n",
        "    try:\n",
        "        resultados = beam_search_garcia_marquez(\n",
        "            model=model,\n",
        "            num_beams=num_opciones,\n",
        "            num_chars=longitud,\n",
        "            input_text=semilla,\n",
        "            temp=config['temp'],\n",
        "            mode=config['mode']\n",
        "        )\n",
        "\n",
        "        textos_generados = []\n",
        "        for i, resultado in enumerate(resultados):\n",
        "            texto = decode(resultado).strip()\n",
        "            textos_generados.append(texto)\n",
        "\n",
        "        return textos_generados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        print(\"ðŸ”„ Usando mÃ©todo de respaldo...\")\n",
        "\n",
        "        # MÃ©todo de respaldo\n",
        "        return simple_beam_search(model, semilla, longitud, num_opciones)\n",
        "\n",
        "print(\"âœ… FunciÃ³n generar_garcia_marquez() lista para uso\")\n",
        "print(\"ðŸ“š Esta funciÃ³n combina toda la investigaciÃ³n de los bloques anteriores\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa672fd8-a039-4a71-cf5b-a6f4b6cf9a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ANÃLISIS COMPARATIVO FINAL DE ESTRATEGIAS DE GENERACIÃ“N\n",
            "======================================================================\n",
            "Semilla comÃºn: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde'\n",
            "Longitud: 120 caracteres\n",
            "Comparando TODAS las estrategias desarrolladas:\n",
            "\n",
            "1ï¸âƒ£ GREEDY SEARCH (DeterminÃ­stico puro)\n",
            "----------------------------------------\n",
            "Resultado: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde en que lo habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a no se le habÃ­a perdido el coronel Au'\n",
            "Generado: ' en que lo habÃ­a perdido el coronel Aureliano BuendÃ­a. El coronel Aureliano BuendÃ­a no se le habÃ­a perdido el coronel Au'\n",
            "âœ… Pros: Muy coherente, determinÃ­stico\n",
            "âŒ Contras: Repetitivo, conservador\n",
            "\n",
            "==================================================\n",
            "2ï¸âƒ£ MUESTREO CON TEMPERATURA (EstocÃ¡stico simple)\n",
            "------------------------------------------------\n",
            "Resultado: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde pocÃ­a desde a Macondo para no esperando su varia avisagiencia de ella. En\n",
            "ningÃºn cuartel Aureliano durÃ³ su estirpa de e'\n",
            "Generado: ' pocÃ­a desde a Macondo para no esperando su varia avisagiencia de ella. En\n",
            "ningÃºn cuartel Aureliano durÃ³ su estirpa de e'\n",
            "âœ… Pros: Creativo, controlable\n",
            "âŒ Contras: Puede ser inconsistente\n",
            "\n",
            "==================================================\n",
            "3ï¸âƒ£ BEAM SEARCH OPTIMIZADO (Mejor de ambos mundos)\n",
            "----------------------------------------------------\n",
            "ðŸŽ­ Generando en estilo: balanceado\n",
            "ðŸ“ Semilla: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde'\n",
            "ðŸ“ Longitud: 120 caracteres\n",
            "ðŸ”¢ Opciones: 3\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.8, mode=det\n",
            "Iniciando beam search: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde' -> 120 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (3, 101)\n",
            "Progress: 1/119 characters generated\n",
            "Progress: 11/119 characters generated\n",
            "Progress: 21/119 characters generated\n",
            "Progress: 31/119 characters generated\n",
            "Progress: 41/119 characters generated\n",
            "Progress: 51/119 characters generated\n",
            "Progress: 61/119 characters generated\n",
            "Progress: 71/119 characters generated\n",
            "Progress: 81/119 characters generated\n",
            "Progress: 91/119 characters generated\n",
            "Progress: 101/119 characters generated\n",
            "Progress: 111/119 characters generated\n",
            "Beam search completed!\n",
            "OpciÃ³n 1: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde en que su padre se encontrÃ³ en el cuarto de MelquÃ­ades, y el coronel Aureliano BuendÃ­a estaba en el cuarto de MelquÃ­ade'\n",
            "Generado: ' en que su padre se encontrÃ³ en el cuarto de MelquÃ­ades, y el coronel Aureliano BuendÃ­a estaba en el cuarto de MelquÃ­ade'\n",
            "OpciÃ³n 2: 'Aureliano BuendÃ­a habÃ­a de recordar aquella tarde en que su padre se encontrÃ³ en el cuarto de MelquÃ­ades, y el coronel Aureliano BuendÃ­a estaba en el cuartito de la casa'\n",
            "Generado: ' en que su padre se encontrÃ³ en el cuarto de MelquÃ­ades, y el coronel Aureliano BuendÃ­a estaba en el cuartito de la casa'\n",
            "âœ… Pros: Balance creatividad/coherencia, mÃºltiples opciones\n",
            "âŒ Contras: MÃ¡s lento computacionalmente\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ­ DEMOSTRACIÃ“N DE ESTILOS CON GARCÃA MÃRQUEZ\n",
            "======================================================================\n",
            "\n",
            "ðŸ“– SEMILLA: 'En Macondo llovÃ­a'\n",
            "--------------------------------\n",
            "\n",
            "CONSERVADOR:\n",
            "ðŸŽ­ Generando en estilo: conservador\n",
            "ðŸ“ Semilla: 'En Macondo llovÃ­a'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.7, mode=det\n",
            "Iniciando beam search: 'En Macondo llovÃ­a' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'En Macondo llovÃ­a de la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tier'\n",
            "\n",
            "BALANCEADO:\n",
            "ðŸŽ­ Generando en estilo: balanceado\n",
            "ðŸ“ Semilla: 'En Macondo llovÃ­a'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.8, mode=det\n",
            "Iniciando beam search: 'En Macondo llovÃ­a' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'En Macondo llovÃ­a de la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tier'\n",
            "\n",
            "CREATIVO:\n",
            "ðŸŽ­ Generando en estilo: creativo\n",
            "ðŸ“ Semilla: 'En Macondo llovÃ­a'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=1.0, mode=sto\n",
            "Iniciando beam search: 'En Macondo llovÃ­a' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'En Macondo llovÃ­a de sus procÃ­a en un estado dos noticias.\n",
            "Hacia la compaÃ±Ã­a bananera y la condiciÃ³n de fiestas el es'\n",
            "\n",
            "ðŸ“– SEMILLA: 'JosÃ© Arcadio BuendÃ­a soÃ±aba'\n",
            "------------------------------------------\n",
            "\n",
            "CONSERVADOR:\n",
            "ðŸŽ­ Generando en estilo: conservador\n",
            "ðŸ“ Semilla: 'JosÃ© Arcadio BuendÃ­a soÃ±aba'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.7, mode=det\n",
            "Iniciando beam search: 'JosÃ© Arcadio BuendÃ­a soÃ±aba' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'JosÃ© Arcadio BuendÃ­a soÃ±aba a la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tierr'\n",
            "\n",
            "BALANCEADO:\n",
            "ðŸŽ­ Generando en estilo: balanceado\n",
            "ðŸ“ Semilla: 'JosÃ© Arcadio BuendÃ­a soÃ±aba'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.8, mode=det\n",
            "Iniciando beam search: 'JosÃ© Arcadio BuendÃ­a soÃ±aba' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'JosÃ© Arcadio BuendÃ­a soÃ±aba a la casa de su madre y la construcciÃ³n de la casa. En la casa de los primeros miembros de la tierr'\n",
            "\n",
            "CREATIVO:\n",
            "ðŸŽ­ Generando en estilo: creativo\n",
            "ðŸ“ Semilla: 'JosÃ© Arcadio BuendÃ­a soÃ±aba'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=1.0, mode=sto\n",
            "Iniciando beam search: 'JosÃ© Arcadio BuendÃ­a soÃ±aba' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'JosÃ© Arcadio BuendÃ­a soÃ±aba barriminar. Al mismo\n",
            "tiempo poco manos tuvo siempre en su amargado, sin el dueÃ±o encerrado en el ro'\n",
            "\n",
            "ðŸ“– SEMILLA: 'La soledad de Ãšrsula'\n",
            "-----------------------------------\n",
            "\n",
            "CONSERVADOR:\n",
            "ðŸŽ­ Generando en estilo: conservador\n",
            "ðŸ“ Semilla: 'La soledad de Ãšrsula'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.7, mode=det\n",
            "Iniciando beam search: 'La soledad de Ãšrsula' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'La soledad de Ãšrsula, y la manta de la casa con la casa de su madre y la compaÃ±Ã­a bananera. El coronel Aureliano BuendÃ­a'\n",
            "\n",
            "BALANCEADO:\n",
            "ðŸŽ­ Generando en estilo: balanceado\n",
            "ðŸ“ Semilla: 'La soledad de Ãšrsula'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=0.8, mode=det\n",
            "Iniciando beam search: 'La soledad de Ãšrsula' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'La soledad de Ãšrsula, y la manta de la casa con la casa de su madre y la compaÃ±Ã­a bananera. El coronel Aureliano BuendÃ­a'\n",
            "\n",
            "CREATIVO:\n",
            "ðŸŽ­ Generando en estilo: creativo\n",
            "ðŸ“ Semilla: 'La soledad de Ãšrsula'\n",
            "ðŸ“ Longitud: 100 caracteres\n",
            "ðŸ”¢ Opciones: 1\n",
            "âš™ï¸  ConfiguraciÃ³n: temp=1.0, mode=sto\n",
            "Iniciando beam search: 'La soledad de Ãšrsula' -> 100 chars\n",
            "Input shape: (1, 100)\n",
            "Model output shape: (1, 93)\n",
            "Prediction shape: (93,)\n",
            "Vocab size detected: 93\n",
            "Initial history_tokens shape: (1, 101)\n",
            "Progress: 1/99 characters generated\n",
            "Progress: 11/99 characters generated\n",
            "Progress: 21/99 characters generated\n",
            "Progress: 31/99 characters generated\n",
            "Progress: 41/99 characters generated\n",
            "Progress: 51/99 characters generated\n",
            "Progress: 61/99 characters generated\n",
            "Progress: 71/99 characters generated\n",
            "Progress: 81/99 characters generated\n",
            "Progress: 91/99 characters generated\n",
            "Beam search completed!\n",
            "   'La soledad de Ãšrsula, coma no se fute fusilario, pero no hizo una crrigulea casildad de lÃ¡stima, can pie sagarla de los'\n",
            "\n",
            "======================================================================\n",
            "ðŸ† CONCLUSIONES FINALES DEL EXPERIMENTO\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š RESULTADOS DE LA INVESTIGACIÃ“N:\n",
            "\n",
            "ðŸŽ¯ MODELO LSTM ENTRENADO:\n",
            "   â€¢ Perplejidad de validaciÃ³n: 3.44 (Excelente)\n",
            "   â€¢ Corpus: 'Cien aÃ±os de soledad' completa (816K caracteres)\n",
            "   â€¢ Vocabulario: 93 caracteres Ãºnicos (espaÃ±ol + sÃ­mbolos)\n",
            "   â€¢ Mejora vs aleatorio: 27.1x en perplejidad\n",
            "   â€¢ Capacidad de aprender GarcÃ­a MÃ¡rquez: Alta âœ…\n",
            "\n",
            "ðŸ”¬ ESTRATEGIAS DE GENERACIÃ“N EVALUADAS:\n",
            "\n",
            "1. GREEDY SEARCH:\n",
            "   â€¢ Coherencia: â­â­â­â­â­\n",
            "   â€¢ Creatividad: â­â­\n",
            "   â€¢ Velocidad: â­â­â­â­â­\n",
            "   â€¢ Uso: Aplicaciones que requieren alta predictibilidad\n",
            "\n",
            "2. MUESTREO CON TEMPERATURA:\n",
            "   â€¢ Coherencia: â­â­â­\n",
            "   â€¢ Creatividad: â­â­â­â­â­\n",
            "   â€¢ Velocidad: â­â­â­â­\n",
            "   â€¢ Uso: GeneraciÃ³n creativa experimental\n",
            "\n",
            "3. BEAM SEARCH OPTIMIZADO:\n",
            "   â€¢ Coherencia: â­â­â­â­â­\n",
            "   â€¢ Creatividad: â­â­â­â­\n",
            "   â€¢ Velocidad: â­â­â­\n",
            "   â€¢ Uso: GeneraciÃ³n de calidad para narrativa literaria\n",
            "\n",
            "ðŸ… RECOMENDACIÃ“N FINAL:\n",
            "   â€¢ Para USO GENERAL: Beam Search modo \"balanceado\"\n",
            "   â€¢ Para COHERENCIA MÃXIMA: Greedy Search\n",
            "   â€¢ Para EXPERIMENTACIÃ“N: Temperatura T=1.0-1.5\n",
            "   â€¢ Para PRODUCCIÃ“N: Beam Search modo \"conservador\"\n",
            "\n",
            "âœ¨ LOGROS DEL PROYECTO:\n",
            "   âœ… Modelo LSTM funcional para espaÃ±ol\n",
            "   âœ… Captura el estilo Ãºnico de GarcÃ­a MÃ¡rquez\n",
            "   âœ… ImplementaciÃ³n completa de beam search\n",
            "   âœ… Sistema de generaciÃ³n configurable\n",
            "   âœ… AnÃ¡lisis comparativo exhaustivo\n",
            "\n",
            "ðŸŽ‰ Â¡EXPERIMENTO COMPLETADO EXITOSAMENTE!\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ MODELO DE GARCÃA MÃRQUEZ LISTO PARA PRODUCCIÃ“N\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE 35 - ANÃLISIS COMPARATIVO FINAL Y DEMOSTRACIÃ“N\n",
        "print(\"=\" * 70)\n",
        "print(\"ANÃLISIS COMPARATIVO FINAL DE ESTRATEGIAS DE GENERACIÃ“N\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# COMPARACIÃ“N SISTEMÃTICA CON LA MISMA SEMILLA\n",
        "semilla_test = \"Aureliano BuendÃ­a habÃ­a de recordar aquella tarde\"\n",
        "longitud_test = 120\n",
        "\n",
        "print(f\"Semilla comÃºn: '{semilla_test}'\")\n",
        "print(f\"Longitud: {longitud_test} caracteres\")\n",
        "print(f\"Comparando TODAS las estrategias desarrolladas:\\n\")\n",
        "\n",
        "# 1. GREEDY SEARCH\n",
        "print(\"1ï¸âƒ£ GREEDY SEARCH (DeterminÃ­stico puro)\")\n",
        "print(\"-\" * 40)\n",
        "try:\n",
        "    greedy_result = generate_text_greedy(model, semilla_test, char2idx, idx2char, seq_length, longitud_test)\n",
        "    greedy_nuevo = greedy_result[len(semilla_test):]\n",
        "    print(f\"Resultado: '{greedy_result}'\")\n",
        "    print(f\"Generado: '{greedy_nuevo}'\")\n",
        "    print(\"âœ… Pros: Muy coherente, determinÃ­stico\")\n",
        "    print(\"âŒ Contras: Repetitivo, conservador\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# 2. TEMPERATURA\n",
        "print(\"2ï¸âƒ£ MUESTREO CON TEMPERATURA (EstocÃ¡stico simple)\")\n",
        "print(\"-\" * 48)\n",
        "try:\n",
        "    temp_result = generate_text_temperature(model, semilla_test, char2idx, idx2char, seq_length, longitud_test, 1.0)\n",
        "    temp_nuevo = temp_result[len(semilla_test):]\n",
        "    print(f\"Resultado: '{temp_result}'\")\n",
        "    print(f\"Generado: '{temp_nuevo}'\")\n",
        "    print(\"âœ… Pros: Creativo, controlable\")\n",
        "    print(\"âŒ Contras: Puede ser inconsistente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# 3. BEAM SEARCH MEJORADO\n",
        "print(\"3ï¸âƒ£ BEAM SEARCH OPTIMIZADO (Mejor de ambos mundos)\")\n",
        "print(\"-\" * 52)\n",
        "try:\n",
        "    resultados_beam = generar_garcia_marquez(semilla_test, longitud_test, 3, \"balanceado\")\n",
        "\n",
        "    for i, resultado in enumerate(resultados_beam[:2]):  # Top 2\n",
        "        nuevo = resultado[len(semilla_test):]\n",
        "        print(f\"OpciÃ³n {i+1}: '{resultado}'\")\n",
        "        print(f\"Generado: '{nuevo}'\")\n",
        "\n",
        "    print(\"âœ… Pros: Balance creatividad/coherencia, mÃºltiples opciones\")\n",
        "    print(\"âŒ Contras: MÃ¡s lento computacionalmente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# DEMOSTRACIÃ“N CON DIFERENTES ESTILOS\n",
        "print(\"ðŸŽ­ DEMOSTRACIÃ“N DE ESTILOS CON GARCÃA MÃRQUEZ\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "semillas_demo = [\n",
        "    \"En Macondo llovÃ­a\",\n",
        "    \"JosÃ© Arcadio BuendÃ­a soÃ±aba\",\n",
        "    \"La soledad de Ãšrsula\"\n",
        "]\n",
        "\n",
        "estilos_demo = [\"conservador\", \"balanceado\", \"creativo\"]\n",
        "\n",
        "for semilla in semillas_demo:\n",
        "    print(f\"\\nðŸ“– SEMILLA: '{semilla}'\")\n",
        "    print(\"-\" * (len(semilla) + 15))\n",
        "\n",
        "    for estilo in estilos_demo:\n",
        "        print(f\"\\n{estilo.upper()}:\")\n",
        "        try:\n",
        "            resultado = generar_garcia_marquez(semilla, 100, 1, estilo)\n",
        "            nuevo = resultado[0][len(semilla):]\n",
        "            print(f\"   '{resultado[0]}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ† CONCLUSIONES FINALES DEL EXPERIMENTO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "ðŸ“Š RESULTADOS DE LA INVESTIGACIÃ“N:\n",
        "\n",
        "ðŸŽ¯ MODELO LSTM ENTRENADO:\n",
        "   â€¢ Perplejidad de validaciÃ³n: 3.44 (Excelente)\n",
        "   â€¢ Corpus: 'Cien aÃ±os de soledad' completa (816K caracteres)\n",
        "   â€¢ Vocabulario: 93 caracteres Ãºnicos (espaÃ±ol + sÃ­mbolos)\n",
        "   â€¢ Mejora vs aleatorio: 27.1x en perplejidad\n",
        "   â€¢ Capacidad de aprender GarcÃ­a MÃ¡rquez: Alta âœ…\n",
        "\n",
        "ðŸ”¬ ESTRATEGIAS DE GENERACIÃ“N EVALUADAS:\n",
        "\n",
        "1. GREEDY SEARCH:\n",
        "   â€¢ Coherencia: â­â­â­â­â­\n",
        "   â€¢ Creatividad: â­â­\n",
        "   â€¢ Velocidad: â­â­â­â­â­\n",
        "   â€¢ Uso: Aplicaciones que requieren alta predictibilidad\n",
        "\n",
        "2. MUESTREO CON TEMPERATURA:\n",
        "   â€¢ Coherencia: â­â­â­\n",
        "   â€¢ Creatividad: â­â­â­â­â­\n",
        "   â€¢ Velocidad: â­â­â­â­\n",
        "   â€¢ Uso: GeneraciÃ³n creativa experimental\n",
        "\n",
        "3. BEAM SEARCH OPTIMIZADO:\n",
        "   â€¢ Coherencia: â­â­â­â­â­\n",
        "   â€¢ Creatividad: â­â­â­â­\n",
        "   â€¢ Velocidad: â­â­â­\n",
        "   â€¢ Uso: GeneraciÃ³n de calidad para narrativa literaria\n",
        "\n",
        "ðŸ… RECOMENDACIÃ“N FINAL:\n",
        "   â€¢ Para USO GENERAL: Beam Search modo \"balanceado\"\n",
        "   â€¢ Para COHERENCIA MÃXIMA: Greedy Search\n",
        "   â€¢ Para EXPERIMENTACIÃ“N: Temperatura T=1.0-1.5\n",
        "   â€¢ Para PRODUCCIÃ“N: Beam Search modo \"conservador\"\n",
        "\n",
        "âœ¨ LOGROS DEL PROYECTO:\n",
        "   âœ… Modelo LSTM funcional para espaÃ±ol\n",
        "   âœ… Captura el estilo Ãºnico de GarcÃ­a MÃ¡rquez\n",
        "   âœ… ImplementaciÃ³n completa de beam search\n",
        "   âœ… Sistema de generaciÃ³n configurable\n",
        "   âœ… AnÃ¡lisis comparativo exhaustivo\n",
        "\n",
        "ðŸŽ‰ Â¡EXPERIMENTO COMPLETADO EXITOSAMENTE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸš€ MODELO DE GARCÃA MÃRQUEZ LISTO PARA PRODUCCIÃ“N\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": [
        "**ANÃLISIS GENERAL Y CONCLUSIONES - MODELO DE LENGUAJE GARCÃA MÃRQUEZ**\n",
        "\n",
        "**OBJETIVO DEL PROYECTO**\n",
        "Desarrollar un modelo de lenguaje LSTM capaz de generar texto en el estilo de Gabriel GarcÃ­a MÃ¡rquez basado en \"Cien aÃ±os de soledad\".\n",
        "\n",
        "**RESULTADOS DEL MODELO**\n",
        "- Perplejidad de validaciÃ³n: 3.44 (Excelente - indica alta capacidad predictiva)\n",
        "- Accuracy: 63.3% en validaciÃ³n\n",
        "- Corpus: 816,434 caracteres de \"Cien aÃ±os de soledad\"\n",
        "- Vocabulario: 93 caracteres Ãºnicos (espaÃ±ol + sÃ­mbolos)\n",
        "- Mejora vs. aleatorio: 27.1x en perplejidad\n",
        "\n",
        "**ESTRATEGIAS DE GENERACIÃ“N EVALUADAS**\n",
        "\n",
        "1. Greedy Search\n",
        "Fortalezas: Muy coherente, determinÃ­stico, rÃ¡pido\n",
        "Debilidades: Extremadamente repetitivo, se atasca en bucles\n",
        "Uso recomendado: Aplicaciones que requieren alta predictibilidad\n",
        "\n",
        "2. Muestreo con Temperatura\n",
        "Fortalezas: Creativo, controlable, balance ajustable\n",
        "Debilidades: Puede generar palabras inventadas, menos coherente\n",
        "Uso recomendado: ExperimentaciÃ³n creativa\n",
        "\n",
        "3. Beam Search (GANADOR)\n",
        "Fortalezas: Mejor balance creatividad/coherencia, mÃºltiples opciones, captura referencias especÃ­ficas del libro\n",
        "Debilidades: MÃ¡s lento computacionalmente\n",
        "Uso recomendado: GeneraciÃ³n de calidad para narrativa literaria\n",
        "\n",
        "**CONCLUSIONES PRINCIPALES**\n",
        "\n",
        "**Capacidad del Modelo**\n",
        "El modelo LSTM exitosamente aprendiÃ³:\n",
        "- Personajes especÃ­ficos: \"Aureliano BuendÃ­a\", \"Ãšrsula\"\n",
        "- Lugares icÃ³nicos: \"Macondo\", \"cuarto de MelquÃ­ades\"\n",
        "- Estilo narrativo: Frases largas y descriptivas\n",
        "- Estructura del espaÃ±ol: Sintaxis y gramÃ¡tica correctas\n",
        "\n",
        "**Mejor Estrategia Identificada**\n",
        "Beam Search con configuraciÃ³n \"balanceada\":\n",
        "- Temperatura: 0.8\n",
        "- Modo: DeterminÃ­stico\n",
        "- Beam width: 3-5\n",
        "\n",
        "**Ejemplo de GeneraciÃ³n Exitosa**\n",
        "Entrada: \"Aureliano BuendÃ­a habÃ­a de recordar aquella tarde\"\n",
        "Salida: \"en que su padre se encontrÃ³ en el cuarto de MelquÃ­ades, y el coronel Aureliano BuendÃ­a estaba en el cuarto...\"\n",
        "\n",
        "**RECOMENDACIONES DE USO**\n",
        "\n",
        "Para diferentes propÃ³sitos:\n",
        "- Escritura narrativa: Beam Search \"balanceado\"\n",
        "- AnÃ¡lisis de estilo: Beam Search \"conservador\"\n",
        "- ExperimentaciÃ³n: Temperatura 1.0-1.2\n",
        "- Prototipado rÃ¡pido: Greedy Search (con precauciÃ³n por repeticiones)\n",
        "\n",
        "**LOGROS DEL PROYECTO**\n",
        "1. Modelo LSTM funcional para espaÃ±ol literario\n",
        "2. Captura exitosa del estilo Ãºnico de GarcÃ­a MÃ¡rquez\n",
        "3. Sistema completo de generaciÃ³n configurable\n",
        "4. AnÃ¡lisis comparativo riguroso de estrategias\n",
        "5. Herramienta prÃ¡ctica lista para producciÃ³n\n",
        "\n",
        "**CONCLUSIÃ“N FINAL**\n",
        "El proyecto demostrÃ³ que es posible entrenar un modelo LSTM para capturar y reproducir el estilo literario especÃ­fico de un autor, en este caso GarcÃ­a MÃ¡rquez, con resultados de alta calidad que mantienen la coherencia narrativa y las referencias especÃ­ficas de la obra original."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTeIDo_mQYpg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
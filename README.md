# Procesamiento de Lenguaje Natural
Proyectos finales - UBA (Universidad de Buenos Aires) - Especializaci贸n en Inteligencia Artificial

![NLP Banner](https://img.shields.io/badge/NLP-Natural%20Language%20Processing-blue?style=for-the-badge&logo=python)

## Descripci贸n del Curso
Este repositorio contiene los desaf铆os desarrollados durante el curso de Procesamiento de Lenguaje Natural, donde se exploraron diferentes t茅cnicas de NLP desde fundamentos b谩sicos hasta modelos avanzados de deep learning.

---

## Contacto
**Daniel Fernando Pe帽a Pinzon**  
 Email: [danielfer.colt01@gmail.com]  
 C贸digo: a1818

---

## Desaf铆o 1: Fundamentos de NLP, Vectorizaci贸n y Modelado

![Vectorizaci贸n](https://img.shields.io/badge/Topic-Vectorization-green)

Este desaf铆o aborda t茅cnicas fundamentales de procesamiento de lenguaje natural, combinando el preprocesamiento de texto, la vectorizaci贸n de documentos, el an谩lisis de similitud sem谩ntica y la construcci贸n de modelos de clasificaci贸n.

###  Objetivos principales:

* Vectorizar documentos y analizar la similitud entre ellos.
* Entrenar y optimizar modelos de Na茂ve Bayes para clasificaci贸n.
* Analizar la similitud entre palabras mediante la transposici贸n de la matriz t茅rmino-documento.

### И T茅cnicas implementadas:

* Preprocesamiento de texto: tokenizaci贸n, lematizaci贸n, limpieza y eliminaci贸n de stopwords.
* Vectorizaci贸n con Bag of Words y TF-IDF.
* C谩lculo de similitud entre documentos y palabras utilizando la similitud del coseno.
* Entrenamiento y comparaci贸n de modelos `MultinomialNB` y `ComplementNB`.
* Evaluaci贸n del desempe帽o con m茅tricas como F1-score macro.

###  Resultados destacados:

* Se identificaron relaciones sem谩nticas coherentes entre documentos y palabras.
* Los modelos Na茂ve Bayes alcanzaron buenos niveles de precisi贸n ajustando hiperpar谩metros y representaci贸n del texto.
* La similitud entre palabras captur贸 correctamente agrupamientos sem谩nticos, demostrando la utilidad de la transposici贸n vectorial.

**Notebook:** [Desafio\_1\_Solucion.ipynb](Desafio_1_Solucion.ipynb)

---

## Desaf铆o 2: An谩lisis de Sentimientos en Texto

![Sentiment Analysis](https://img.shields.io/badge/Topic-Sentiment%20Analysis-orange)

Este desaf铆o se enfoc贸 en la construcci贸n de modelos supervisados para an谩lisis de sentimientos, utilizando un pipeline completo desde la vectorizaci贸n hasta la evaluaci贸n comparativa de diferentes algoritmos de clasificaci贸n.

###  Objetivos principales:

* Predecir sentimientos a partir de textos utilizando t茅cnicas cl谩sicas de NLP y machine learning.
* Comparar el desempe帽o de distintos modelos con diferentes representaciones vectoriales.
* Optimizar los modelos con base en m茅tricas como F1-score macro.

### 锔 Componentes implementados:

* **Preprocesamiento de texto**: limpieza, tokenizaci贸n y lematizaci贸n.
* **Vectorizaci贸n**: uso de `CountVectorizer` y `TfidfVectorizer` con configuraci贸n de n-gramas.
* **Modelos entrenados**:

  * MultinomialNB y ComplementNB
  * Regresi贸n Log铆stica
  * M谩quinas de Vectores de Soporte (SVM)
  * Random Forest
* **Optimizaci贸n y evaluaci贸n**:

  * Ajuste de hiperpar谩metros
  * Evaluaci贸n con matriz de confusi贸n y F1-score macro

###  Resultados destacados:

* El modelo de **Logistic Regression** con TF-IDF y n-gramas obtuvo los mejores resultados globales.
* **ComplementNB** super贸 a MultinomialNB en escenarios con clases desbalanceadas.
* Se observaron patrones coherentes entre predicciones y polaridad del texto.

Este desaf铆o permiti贸 aplicar t茅cnicas de clasificaci贸n textual sobre un problema real, mostrando c贸mo peque帽os cambios en el preprocesamiento y representaci贸n pueden tener un gran impacto en el desempe帽o de los modelos.

**Notebook:** [Desafio\_2\_\_Solucion.ipynb](Desafio_2__Solucion.ipynb)

---

## Desaf铆o 3: Modelo de Lenguaje a Nivel de Caracteres

![Language Model](https://img.shields.io/badge/Topic-Language%20Model-red)

En este desaf铆o se desarroll贸 un modelo generativo de lenguaje entrenado sobre un corpus textual, utilizando redes neuronales recurrentes para predecir y generar texto car谩cter por car谩cter. Se exploraron distintas arquitecturas y estrategias de generaci贸n.

###  Objetivos principales:

* Entrenar un modelo de lenguaje utilizando secuencias de caracteres como entrada.
* Evaluar arquitecturas recurrentes (SimpleRNN, LSTM, GRU) en la tarea de predicci贸n secuencial.
* Generar texto a partir de una semilla utilizando estrategias como greedy search, beam search y sampling con temperatura.

### 锔 Componentes implementados:

* **Preprocesamiento del corpus**:

  * Conversi贸n a min煤sculas, limpieza y tokenizaci贸n car谩cter por car谩cter.
  * Construcci贸n de secuencias de entrada/salida.
  * Codificaci贸n one-hot de caracteres.
* **Entrenamiento del modelo**:

  * Uso de `SimpleRNN`, `LSTM` y `GRU`.
  * Optimizaci贸n con `RMSprop`.
  * Monitoreo de la **perplejidad** como m茅trica clave de desempe帽o.
* **Generaci贸n de texto**:

  * Greedy search.
  * Beam search (determin铆stico y estoc谩stico).
  * Sampling con variaci贸n de **temperatura** para controlar la diversidad.

###  Resultados destacados:

* El modelo fue capaz de generar texto con patrones sint谩cticos coherentes.
* **LSTM** super贸 a otras arquitecturas en estabilidad y calidad del texto.
* La **temperatura** demostr贸 ser un par谩metro cr铆tico: a mayor temperatura, mayor creatividad; a menor, m谩s precisi贸n pero repetitividad.
* Se evidenci贸 una mejora progresiva durante el entrenamiento, con reducci贸n sostenida de la perplejidad.

Este desaf铆o permiti贸 entender c贸mo modelar dependencias secuenciales en lenguaje natural y c贸mo controlar la generaci贸n de texto a trav茅s de t茅cnicas probabil铆sticas.

**Notebook:** [Desafio\_modelo\_lenguaje\_char\_solucion.ipynb](Desafio_modelo_lenguaje_char_solucion.ipynb)

---

## Desaf铆o 4: Bot de Preguntas y Respuestas

![QA Bot](https://img.shields.io/badge/Topic-Question%20Answering-purple)

En este desaf铆o se desarroll贸 un sistema de **preguntas y respuestas (QA)** que, a partir de un contexto textual, es capaz de extraer respuestas relevantes a preguntas formuladas por el usuario. El enfoque combin贸 modelos secuenciales, mecanismos de atenci贸n y embeddings contextuales.

###  Objetivos principales:

* Construir un modelo capaz de responder preguntas basadas en fragmentos de texto.
* Implementar arquitecturas de tipo **seq2seq** con mecanismos de atenci贸n.
* Evaluar la calidad de las respuestas generadas con m茅tricas espec铆ficas de QA.
* Dise帽ar una interfaz interactiva para consultar al modelo de forma din谩mica.

### 锔 Componentes implementados:

* **Preprocesamiento del corpus**: limpieza, tokenizaci贸n y estructuraci贸n en pares `(pregunta, contexto)`.
* **Modelo de QA**:

  * Arquitectura seq2seq adaptada a la tarea extractiva.
  * Inclusi贸n de **mecanismos de atenci贸n** para enfocar las respuestas.
  * Uso de embeddings contextuales para representar pregunta y contexto.
* **Entrenamiento y evaluaci贸n**:

  * Evaluaci贸n con m茅tricas como *Exact Match* y *F1-score*.
  * Observaci贸n cualitativa de respuestas correctas e incorrectas.
* **Interfaz de usuario**:

  * Entrada manual para preguntas.
  * Salida textual autom谩tica del fragmento considerado como respuesta.

###  Resultados destacados:

* El sistema fue capaz de identificar y extraer correctamente respuestas en la mayor铆a de los casos.
* El uso de atenci贸n y embeddings enriqueci贸 la capacidad de comprender el contexto.
* Las respuestas obtenidas mostraron coherencia gramatical y proximidad sem谩ntica al contenido original.

Este desaf铆o representa una s铆ntesis de los conocimientos del curso, integrando representaci贸n del lenguaje, modelos neuronales y evaluaci贸n de tareas complejas de comprensi贸n lectora.

**Notebook:** [Desafio\_4\_6\_bot\_qa\_Solucion.ipynb](Desafio_4_6_bot_qa_Solucion.ipynb)

---

## Tecnolog铆as Utilizadas
- **Python** 
- **TensorFlow/Keras** 
- **NLTK** 
- **Scikit-learn** 
- **Pandas & NumPy** 
- **Matplotlib & Seaborn** 

## Estructura del Repositorio
```
procesamiento_lenguaje_natural/
 Desafio_1_Solucion.ipynb
 Desafio_2__Solucion.ipynb
 Desafio_modelo_lenguaje_char_solucion.ipynb
 Desafio_4_6_bot_qa_Solucion.ipynb
 README.md
```

---
